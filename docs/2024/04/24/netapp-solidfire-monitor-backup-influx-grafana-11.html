<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Metrics for NetApp SolidFire backup-to-S3 in InfluxDB and Grafana | Acting Technologist
      
    </title>
    <meta name="description" content="
     Send NetApp SolidFire backup-to-S3 metrics and logs to InfluxDB and visualize in Grafana 11
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Metrics for NetApp SolidFire backup-to-S3 in InfluxDB and Grafana | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Metrics for NetApp SolidFire backup-to-S3 in InfluxDB and Grafana" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Send NetApp SolidFire backup-to-S3 metrics and logs to InfluxDB and visualize in Grafana 11" />
<meta property="og:description" content="Send NetApp SolidFire backup-to-S3 metrics and logs to InfluxDB and visualize in Grafana 11" />
<link rel="canonical" href="https://scaleoutsean.github.io/2024/04/24/netapp-solidfire-monitor-backup-influx-grafana-11.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2024/04/24/netapp-solidfire-monitor-backup-influx-grafana-11.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:image" content="https://scaleoutsean.github.io/assets/images/solidfire-backup-job-monitoring-influxdb-03-influx-backup-metric.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-04-24T00:00:00+08:00" />
<script type="application/ld+json">
{"image":"https://scaleoutsean.github.io/assets/images/solidfire-backup-job-monitoring-influxdb-03-influx-backup-metric.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2024/04/24/netapp-solidfire-monitor-backup-influx-grafana-11.html"},"author":{"@type":"Person","name":"scaleoutSean"},"description":"Send NetApp SolidFire backup-to-S3 metrics and logs to InfluxDB and visualize in Grafana 11","@type":"BlogPosting","url":"https://scaleoutsean.github.io/2024/04/24/netapp-solidfire-monitor-backup-influx-grafana-11.html","headline":"Metrics for NetApp SolidFire backup-to-S3 in InfluxDB and Grafana","dateModified":"2024-04-24T00:00:00+08:00","datePublished":"2024-04-24T00:00:00+08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Metrics for NetApp SolidFire backup-to-S3 in InfluxDB and Grafana</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>24 Apr 2024</span> - <i class="far fa-clock"></i> 


  
  
    15 minute read
  

    </span>
  </div>
  
        <ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#initiating-and-monitoring-solidfire-backup-to-s3-jobs">Initiating and monitoring SolidFire backup-to-S3 jobs</a>
    <ul>
      <li><a href="#initiation">Initiation</a></li>
      <li><a href="#status">Status</a></li>
      <li><a href="#progress">Progress</a></li>
      <li><a href="#completion-and-result">Completion and result</a></li>
    </ul>
  </li>
  <li><a href="#sending-metrics-to-influxdb-v1">Sending metrics to InfluxDB v1</a></li>
  <li><a href="#the-little-db-that-could">The little DB that could</a></li>
  <li><a href="#kubernetes-jobs">Kubernetes jobs</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
  <li><a href="#appendix-a---gauge-visualization">Appendix A - Gauge visualization</a></li>
  <li><a href="#appendix-b---grafana-alerts">Appendix B - Grafana alerts</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>In the previous post I wrote about Grafana 11 (Preview), with which good old SolidFire Collector and Graphite work like a charm.</p>

<p>On that occasion I also tested InfluxDB v1 Data Source in Grafana 11 - that also worked great.</p>

<p>Once I had SolidFire Collector, InfluxDB, and Grafana all running, I thought how I should also look at the next steps.</p>

<p>Some two years ago I mentioned how moving SolidFire Collector to InfluxDB would be a good idea, because it’s more widely used (and I use it in E-Series Performance Analyzer as well).</p>

<p>While I still don’t have enough time to embark on SolidFire Collector integration with InfluxDB, there’s an easier target - my PowerShell <a href="https://github.com/scaleoutsean/awesome-solidfire/tree/master/scripts">script</a> for parallel SolidFire backup to S3. Why?</p>

<ul>
  <li>SolidFire Collector doesn’t do any monitoring related to backup to S3</li>
  <li>Backups are long-running jobs and none of the scripts I’ve written so far had integration with logging or monitoring (although I blogged about 3rd party integrations such as Velero and Kopia, which do have metrics, but I’m now talking about my own scripts)</li>
</ul>

<p>An opportunity I couldn’t miss!</p>

<h2 id="initiating-and-monitoring-solidfire-backup-to-s3-jobs">Initiating and monitoring SolidFire backup-to-S3 jobs</h2>

<p>I’ve blogged about SolidFire’s backup-to-S3 in many posts (<a href="/2021/04/21/solidfire-backup-to-s3.html">example</a>), so I’ll just skip that and focus on task at hand.</p>

<p>First, we need to create a backup job. Then we want to monitor it and finally we want to know whether it was or wasn’t successful. Simple!</p>

<p>But we need to stick to the maximum number of job slots per node, so it’s not like one giant “for each” loop, which is why I wrote those scripts.</p>

<h3 id="initiation">Initiation</h3>

<p>We’re after <a href="https://docs.netapp.com/us-en/element-software/api/reference_element_api_startbulkvolumeread.html">StartBulkVolumeRead</a>.</p>

<p>Let’s backup volume ID 139.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Invoke-SFApi</span><span class="w"> </span><span class="nt">-Method</span><span class="w"> </span><span class="nx">StartBulkVolumeRead</span><span class="w"> </span><span class="nt">-Params</span><span class="w"> </span><span class="p">@{</span><span class="w"> </span><span class="err">`</span><span class="w">
  </span><span class="s2">"volumeID"</span><span class="o">=</span><span class="w"> </span><span class="s2">"139"</span><span class="p">;</span><span class="w"> </span><span class="err">`</span><span class="w">
  </span><span class="s2">"format"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"native"</span><span class="p">;</span><span class="w"> </span><span class="err">`</span><span class="w">
  </span><span class="s2">"script"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"bv_internal.py"</span><span class="p">;</span><span class="w"> </span><span class="err">`</span><span class="w">
  </span><span class="s2">"scriptParameters"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w"> </span><span class="err">`</span><span class="w">
    </span><span class="s2">"write"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w"> </span><span class="err">`</span><span class="w">
      </span><span class="s2">"awsAccessKeyID"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">""</span><span class="p">;</span><span class="w"> </span><span class="s2">"awsSecretAccessKey"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">""</span><span class="p">;</span><span class="w"> </span><span class="err">`</span><span class="w">
      </span><span class="s2">"bucket"</span><span class="o">=</span><span class="w"> </span><span class="s2">"solidfire-backup"</span><span class="p">;</span><span class="w"> </span><span class="err">`</span><span class="w">
      </span><span class="s2">"prefix"</span><span class="o">=</span><span class="w"> </span><span class="s2">"PROD-wcwb/pvc-d793176f-2484-48ea-9255-f70215a7c5f7"</span><span class="p">;</span><span class="w"> </span><span class="err">`</span><span class="w">
      </span><span class="s2">"endpoint"</span><span class="o">=</span><span class="w"> </span><span class="s2">"s3"</span><span class="p">;</span><span class="w"> </span><span class="err">`</span><span class="w">
      </span><span class="s2">"hostname"</span><span class="o">=</span><span class="w"> </span><span class="s2">"a.b.c.d"</span><span class="w"> </span><span class="p">}}}</span><span class="w"> 
</span></code></pre></div></div>

<p>We get back an async job ID handle (176) and a key that appears in the output of other API calls that we’ll see later.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Name</span><span class="w">                           </span><span class="nx">Value</span><span class="w">
</span><span class="o">----</span><span class="w">                           </span><span class="o">-----</span><span class="w">
</span><span class="n">key</span><span class="w">                            </span><span class="nx">88d5819d96dfda7190b16a1426fcded0</span><span class="w">
</span><span class="n">url</span><span class="w">                            </span><span class="nx">https://192.168.105.29:8443/</span><span class="w">
</span><span class="n">asyncHandle</span><span class="w">                    </span><span class="nx">176</span><span class="w">
</span></code></pre></div></div>

<h3 id="status">Status</h3>

<p>Once a job has been submitted, its job handle can be queried for progress and outcome.</p>

<p>We use “<code class="language-plaintext highlighter-rouge">-KeepResult:$True</code>” in the first query so that the API retains this result a longer (and won’t disappear before the job is over).</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-SFASyncResult</span><span class="w"> </span><span class="nt">-ASyncResultID</span><span class="w"> </span><span class="nx">176</span><span class="w"> </span><span class="nt">-KeepResult</span><span class="p">:</span><span class="nv">$True</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">ConvertTo-Json</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="s2">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"running"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"details"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"volumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">139</span><span class="p">,</span><span class="w">
    </span><span class="s2">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w">
    </span><span class="s2">"bvID"</span><span class="p">:</span><span class="w"> </span><span class="mi">101</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="s2">"resultType"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BulkVolume"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"lastUpdateTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-04-24T06:44:32Z"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"createTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-04-24T06:44:32Z"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>We can run this in a loop every few minutes until the job is complete.</p>

<p>During that time we’d see something like this in Running Tasks tab of the SolidFire UI:</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-01-submit.png" alt="" /></p>

<p>All images here can be opened in a new tab, by the way.</p>

<h3 id="progress">Progress</h3>

<p>As far as job progress monitoring is concerned, use Get-SFBulkVolumeJob for that. Notice “<code class="language-plaintext highlighter-rouge">bvID: 101</code>” in the output above, by the way. We have that ID here, too!</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-SFBulkVolumeJob</span><span class="w"> </span><span class="nt">-VolumeId</span><span class="w"> </span><span class="nx">139</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">ConvertTo-Json</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="s2">"BulkVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">101</span><span class="p">,</span><span class="w">
  </span><span class="s2">"CreateTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-04-24T06:44:32Z"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"ElapsedTime"</span><span class="p">:</span><span class="w"> </span><span class="mi">40</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Format"</span><span class="p">:</span><span class="w"> </span><span class="s2">"native"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Key"</span><span class="p">:</span><span class="w"> </span><span class="s2">"88d5819d96dfda7190b16a1426fcded0"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"PercentComplete"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
  </span><span class="s2">"RemainingTime"</span><span class="p">:</span><span class="w"> </span><span class="mi">3960</span><span class="p">,</span><span class="w">
  </span><span class="s2">"SrcVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">139</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"running"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Script"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bv_internal.py"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"SnapshotID"</span><span class="p">:</span><span class="w"> </span><span class="n">null</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"read"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Attributes"</span><span class="p">:</span><span class="w"> </span><span class="p">{}</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-SFBulkVolumeJob</span><span class="w"> </span><span class="nt">-VolumeId</span><span class="w"> </span><span class="nx">139</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">ConvertTo-Json</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="s2">"BulkVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">101</span><span class="p">,</span><span class="w">
  </span><span class="s2">"CreateTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-04-24T06:44:32Z"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"ElapsedTime"</span><span class="p">:</span><span class="w"> </span><span class="mi">152</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Format"</span><span class="p">:</span><span class="w"> </span><span class="s2">"native"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Key"</span><span class="p">:</span><span class="w"> </span><span class="s2">"88d5819d96dfda7190b16a1426fcded0"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"PercentComplete"</span><span class="p">:</span><span class="w"> </span><span class="mi">48</span><span class="p">,</span><span class="w">
  </span><span class="s2">"RemainingTime"</span><span class="p">:</span><span class="w"> </span><span class="mi">164</span><span class="p">,</span><span class="w">
  </span><span class="s2">"SrcVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">139</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"running"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Script"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bv_internal.py"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"SnapshotID"</span><span class="p">:</span><span class="w"> </span><span class="n">null</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"read"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"Attributes"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"nextLba"</span><span class="p">:</span><span class="w"> </span><span class="mi">128000</span><span class="p">,</span><span class="w">
    </span><span class="s2">"firstPendingLba"</span><span class="p">:</span><span class="w"> </span><span class="mi">118784</span><span class="p">,</span><span class="w">
    </span><span class="s2">"startLba"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
    </span><span class="s2">"blocksPerTransfer"</span><span class="p">:</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span><span class="w">
    </span><span class="s2">"pendingLbas"</span><span class="p">:</span><span class="w"> </span><span class="s2">"[122880, 123904, 124928, 118784, 119808, 125952, 120832, 126976, 121856]"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"nLbas"</span><span class="p">:</span><span class="w"> </span><span class="mi">244140</span><span class="p">,</span><span class="w">
    </span><span class="s2">"percentComplete"</span><span class="p">:</span><span class="w"> </span><span class="mi">48</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>

<p>BulkVolumeID 101 maps to bvID 101 from async job handle but only two concurrent bulk volume jobs are supported on the volume in the first place, so it’s unlikely that you’d get confused in any case - you wouldn’t have more than one backup job at the same time.</p>

<p>Either way, cross-referencing by using bvID is possible, so we know which is which.</p>

<p>Couple of important points here:</p>

<ul>
  <li>BulkVolumeID and Key reference async job we submitted</li>
  <li>RemainingTime can go up as well as down (beware if doing own math on current and previous values)</li>
  <li>percentComplete never hits 100%. For example, you may get 95% as the last reading before job exits; so “<code class="language-plaintext highlighter-rouge">($res -eq $null)</code>” tells you you’re done (job is done). Don’t expect you’ll see a 100% here!</li>
  <li>SnapshotID value will be non-zero if we specify one. In the script I mentioned I have a switch that can automatically use the latest snapshot for the volume, if available.</li>
</ul>

<p>One reminder: we don’t necessarily have to obsess over job progress: we can simply reference that bulk job ID (bv101) and check for its logs in SolidFire Event Log later to see if it succeeded or not!</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-02-completed.png" alt="" /></p>

<p>The reason we <em>can</em> obsess over it is that it’s inexpensive to get and send those backup progress metrics to InfluxDB. But it’s not mandatory for knowing whether a job succeeded.</p>

<p>I suppose users with fewer smaller volumes wouldn’t care about progress of backup jobs, but users with many large (10TB, for example) volumes would.</p>

<h3 id="completion-and-result">Completion and result</h3>

<p>Eventually, jobs complete and their outcome is either success or error.</p>

<p>Get-SFBulkVolumeJob tells us nothing about the job outcome. It monitors bulk volume jobs, not backups. Once a backup job is finished, you get nothing back.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-SFBulkVolumeJob</span><span class="w"> </span><span class="nt">-VolumeId</span><span class="w"> </span><span class="nx">139</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">ConvertTo-Json</span><span class="w">
</span><span class="nx">PS</span><span class="err">&gt;</span><span class="w">
</span></code></pre></div></div>

<p>Get-SFASyncResult is how we learn of outcome. Here’s an example of a successful job (notice it references an async job handle, not a volume ID):</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-SFASyncResult</span><span class="w"> </span><span class="nt">-ASyncResultID</span><span class="w"> </span><span class="nx">176</span><span class="w"> </span><span class="nt">-KeepResult</span><span class="p">:</span><span class="nv">$True</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">ConvertTo-Json</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="s2">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"resultType"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BulkVolume"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"lastUpdateTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-04-24T06:49:14Z"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"result"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"volumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">139</span><span class="p">,</span><span class="w">
    </span><span class="s2">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Bulk volume job succeeded"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"bvID"</span><span class="p">:</span><span class="w"> </span><span class="mi">101</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="s2">"createTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-04-24T06:44:32Z"</span><span class="w">
</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>

<p>And an example of a failed job:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-SFASyncResult</span><span class="w"> </span><span class="nt">-ASyncResultID</span><span class="w"> </span><span class="nx">173</span><span class="w"> </span><span class="nt">-KeepResult</span><span class="p">:</span><span class="nv">$True</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">ConvertTo-Json</span><span class="w">
</span><span class="p">{</span><span class="w">
  </span><span class="s2">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"complete"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"resultType"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BulkVolume"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"lastUpdateTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-04-24T06:22:43Z"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"error"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"xBulkVolumeScriptFailure"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"message"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Bulk volume job failed"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"volumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">139</span><span class="p">,</span><span class="w">
    </span><span class="s2">"bvID"</span><span class="p">:</span><span class="w"> </span><span class="mi">98</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="s2">"createTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-04-24T06:20:57Z"</span><span class="w">
</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>

<p>My backup-to-S3 script v2 in Awesome SolidFire already checks these things. We just need to send that output to InfluxDB v1 and then visualize it with Grafana 11.</p>

<h2 id="sending-metrics-to-influxdb-v1">Sending metrics to InfluxDB v1</h2>

<p>While you may send to InfluxDB whatever you want, I’d start with just two metrics: backup job and backup progress.</p>

<p>I haven’t thought about it a lot - this post is in my investigation, in fact - but I’d start with something simple.</p>

<p>Backup job:</p>

<ul>
  <li>Tags: cluster name, volume name, volume ID, bulk volume job ID (maybe more, e.g. K8s PVC, namespace)</li>
  <li>One data field: status (one of: submitted, running, complete)</li>
</ul>

<p>Backup progress:</p>

<ul>
  <li>Tags: similar tags as for backup job</li>
  <li>Two data fields: percentDone (int), status</li>
</ul>

<p>We can simulate that by manually inserting data to InfluxDB.</p>

<p>For backup jobs:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Write-Influx</span><span class="w"> </span><span class="nt">-Measure</span><span class="w"> </span><span class="nx">backup</span><span class="w"> </span><span class="nt">-Tags</span><span class="w"> </span><span class="p">@{</span><span class="nx">cluster</span><span class="o">=</span><span class="s2">"PROD"</span><span class="p">;</span><span class="nx">volName</span><span class="o">=</span><span class="s2">"pvc-d793176f-2484-48ea-9255-f70215a7c5f7"</span><span class="p">;</span><span class="nx">volId</span><span class="o">=</span><span class="mi">139</span><span class="p">,</span><span class="nx">bvId</span><span class="o">=</span><span class="mi">101</span><span class="p">}</span><span class="w"> </span><span class="nt">-Metrics</span><span class="w"> </span><span class="p">@{</span><span class="nx">status</span><span class="o">=</span><span class="s2">"submitted"</span><span class="p">}</span><span class="w"> </span><span class="nt">-Database</span><span class="w"> </span><span class="nx">example</span><span class="w"> </span><span class="nt">-Server</span><span class="w"> </span><span class="nx">http://192.168.50.184:32290</span><span class="w"> </span><span class="nt">-Verbose</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Write-Influx</span><span class="w"> </span><span class="nt">-Measure</span><span class="w"> </span><span class="nx">backup</span><span class="w"> </span><span class="nt">-Tags</span><span class="w"> </span><span class="p">@{</span><span class="nx">cluster</span><span class="o">=</span><span class="s2">"PROD"</span><span class="p">;</span><span class="nx">volName</span><span class="o">=</span><span class="s2">"pvc-d793176f-2484-48ea-9255-f70215a7c5f7"</span><span class="p">;</span><span class="nx">volId</span><span class="o">=</span><span class="mi">139</span><span class="p">,</span><span class="nx">bvId</span><span class="o">=</span><span class="mi">101</span><span class="p">}</span><span class="w"> </span><span class="nt">-Metrics</span><span class="w"> </span><span class="p">@{</span><span class="nx">status</span><span class="o">=</span><span class="s2">"running"</span><span class="p">}</span><span class="w"> </span><span class="nt">-Database</span><span class="w"> </span><span class="nx">example</span><span class="w"> </span><span class="nt">-Server</span><span class="w"> </span><span class="nx">http://192.168.50.184:32290</span><span class="w"> </span><span class="nt">-Verbose</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Write-Influx</span><span class="w"> </span><span class="nt">-Measure</span><span class="w"> </span><span class="nx">backup</span><span class="w"> </span><span class="nt">-Tags</span><span class="w"> </span><span class="p">@{</span><span class="nx">cluster</span><span class="o">=</span><span class="s2">"PROD"</span><span class="p">;</span><span class="nx">volName</span><span class="o">=</span><span class="s2">"pvc-d793176f-2484-48ea-9255-f70215a7c5f7"</span><span class="p">;</span><span class="nx">volId</span><span class="o">=</span><span class="mi">139</span><span class="p">,</span><span class="nx">bvId</span><span class="o">=</span><span class="mi">101</span><span class="p">}</span><span class="w"> </span><span class="nt">-Metrics</span><span class="w"> </span><span class="p">@{</span><span class="nx">status</span><span class="o">=</span><span class="s2">"running"</span><span class="p">}</span><span class="w"> </span><span class="nt">-Database</span><span class="w"> </span><span class="nx">example</span><span class="w"> </span><span class="nt">-Server</span><span class="w"> </span><span class="nx">http://192.168.50.184:32290</span><span class="w"> </span><span class="nt">-Verbose</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Write-Influx</span><span class="w"> </span><span class="nt">-Measure</span><span class="w"> </span><span class="nx">backup</span><span class="w"> </span><span class="nt">-Tags</span><span class="w"> </span><span class="p">@{</span><span class="nx">cluster</span><span class="o">=</span><span class="s2">"PROD"</span><span class="p">;</span><span class="nx">volName</span><span class="o">=</span><span class="s2">"pvc-d793176f-2484-48ea-9255-f70215a7c5f7"</span><span class="p">;</span><span class="nx">volId</span><span class="o">=</span><span class="mi">139</span><span class="p">,</span><span class="nx">bvId</span><span class="o">=</span><span class="mi">101</span><span class="p">;</span><span class="nx">result</span><span class="o">=</span><span class="s2">"ok"</span><span class="p">}</span><span class="w"> </span><span class="nt">-Metrics</span><span class="w"> </span><span class="p">@{</span><span class="nx">status</span><span class="o">=</span><span class="s2">"complete"</span><span class="p">,}</span><span class="w"> </span><span class="nt">-Database</span><span class="w"> </span><span class="nx">example</span><span class="w"> </span><span class="nt">-Server</span><span class="w"> </span><span class="nx">http://192.168.50.184:32290</span><span class="w"> </span><span class="nt">-Verbose</span><span class="w">

</span></code></pre></div></div>

<p>How you want to visualize or show that in Grafana is up to you.</p>

<p>If we backup volumes every 24 hours, that query can be something as simple as a table that shows last 24 hours of records (which would show submitted, running, complete) for all volumes we care about.</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-03-influx-backup-metric.png" alt="" /></p>

<p>Grafana 11 can conditionally format table rows, so we can show a bunch of these on a page and emphasize only those that failed (i.e. “result=”ng”) or create Grafana alerts for that.</p>

<p>For backup progress:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Write-Influx</span><span class="w"> </span><span class="nt">-Measure</span><span class="w"> </span><span class="nx">backupprogress</span><span class="w"> </span><span class="nt">-Tags</span><span class="w"> </span><span class="p">@{</span><span class="nx">cluster</span><span class="o">=</span><span class="s2">"PROD"</span><span class="p">;</span><span class="nx">srcVolId</span><span class="o">=</span><span class="mi">139</span><span class="p">;</span><span class="nx">snapId</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="nx">bvId</span><span class="o">=</span><span class="mi">101</span><span class="p">}</span><span class="w"> </span><span class="nt">-Metrics</span><span class="w"> </span><span class="p">@{</span><span class="nx">pctDone</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="nx">status</span><span class="o">=</span><span class="s2">"running"</span><span class="p">}</span><span class="w"> </span><span class="nt">-Database</span><span class="w"> </span><span class="nx">example</span><span class="w"> </span><span class="nt">-Server</span><span class="w"> </span><span class="nx">http://192.168.50.184:32290</span><span class="w"> </span><span class="nt">-Verbose</span><span class="w">
</span><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Write-Influx</span><span class="w"> </span><span class="nt">-Measure</span><span class="w"> </span><span class="nx">backupprogress</span><span class="w"> </span><span class="nt">-Tags</span><span class="w"> </span><span class="p">@{</span><span class="nx">cluster</span><span class="o">=</span><span class="s2">"PROD"</span><span class="p">;</span><span class="nx">srcVolId</span><span class="o">=</span><span class="mi">139</span><span class="p">;</span><span class="nx">snapId</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="nx">bvId</span><span class="o">=</span><span class="mi">101</span><span class="p">}</span><span class="w"> </span><span class="nt">-Metrics</span><span class="w"> </span><span class="p">@{</span><span class="nx">pctDone</span><span class="o">=</span><span class="mi">50</span><span class="p">;</span><span class="nx">status</span><span class="o">=</span><span class="s2">"running"</span><span class="p">}</span><span class="w"> </span><span class="nt">-Database</span><span class="w"> </span><span class="nx">example</span><span class="w"> </span><span class="nt">-Server</span><span class="w"> </span><span class="nx">http://192.168.50.184:32290</span><span class="w"> </span><span class="nt">-Verbose</span><span class="w">
</span></code></pre></div></div>

<p>Regarding percentComplete (which is unlikely to ever be 100%) - nothing prevents us from creating our own final data point with “<code class="language-plaintext highlighter-rouge">pctDone=100; status="complete"</code>” - if we’ve got <code class="language-plaintext highlighter-rouge">status="complete"</code> and <code class="language-plaintext highlighter-rouge">result="ok"</code> from the async job for the same bvId, it’s fair to assume its progress is 100%.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Write-Influx</span><span class="w"> </span><span class="nt">-Measure</span><span class="w"> </span><span class="nx">backupprogress</span><span class="w"> </span><span class="nt">-Tags</span><span class="w"> </span><span class="p">@{</span><span class="nx">cluster</span><span class="o">=</span><span class="s2">"PROD"</span><span class="p">;</span><span class="nx">srcVolId</span><span class="o">=</span><span class="mi">139</span><span class="p">;</span><span class="nx">snapId</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="nx">bvId</span><span class="o">=</span><span class="mi">101</span><span class="p">}</span><span class="w"> </span><span class="nt">-Metrics</span><span class="w"> </span><span class="p">@{</span><span class="nx">pctDone</span><span class="o">=</span><span class="mi">100</span><span class="p">;</span><span class="nx">status</span><span class="o">=</span><span class="s2">"complete"</span><span class="p">}</span><span class="w"> </span><span class="nt">-Database</span><span class="w"> </span><span class="nx">example</span><span class="w"> </span><span class="nt">-Server</span><span class="w"> </span><span class="nx">http://192.168.50.184:32290</span><span class="w"> </span><span class="nt">-Verbose</span><span class="w">
</span></code></pre></div></div>

<p>Again, if we backup to S3 once a day, we wouldn’t see a bunch of jobs for each volume. We’d query last 24 hours and maybe just show results (failed = red, success = green), as we would presumably have a lot of volumes and watch them in a table potentially focusing just on those with “successful backups in last 24 hours = 0”.</p>

<p>But, let’s say we have one “pet” volume which we like to watch because it often fails to backup to the public cloud.</p>

<p>In that case we may want to watch its progress over time, like this (where we see two recent backups). It starts at close to zero percent complete and moves up to 100% (I insert the last value on my own once I know job completed successfully, as explained above).</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-04-influx-backupprogress-metric.png" alt="" /></p>

<p>Data points representing backup job progress are red at the beginning, change to orange and yellow as they go up, and become green at over 50%. That way I can visualize progress of jobs from different volumes.</p>

<p>If query shows data points from multiple backups over time, I can see the newer backup was smoother while the one on the left looks like it almost got stuck at one point.</p>

<p>We can also use other visualization types such as gauge (see Appendix) which may be neat for folks with 10-50 volumes. Maybe try heatmap for more?</p>

<p>To submit data to InfluxDB v1 I used <a href="https://github.com/markwragg/PowerShell-Influx">this community module</a> (GPL <strong>3.0</strong> alert!), but you can use another (there are several; <a href="https://github.com/micelshima/InfluxDB-Powershell-Module/blob/master/InfluxDB-Powershell-Module/InfluxDB-Powershell-Module.psm1">this one</a> uses MIT license) or simply write your own. Or use Python for all of the above.</p>

<h2 id="the-little-db-that-could">The little DB that could</h2>

<p>Under this very light load, my InfluxDB v1 container used 105 MiB of RAM. View from my Kubernetes worker:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code> PID USER      PR  NI    VIRT    RES  %CPU  %MEM     TIME+ S COMMAND  
 161292 root      20   0 2588.6m 230.8m   0.0   2.9   0:22.96 S pwsh                                                                            
 318616 472       20   0 1463.7m 148.8m   0.0   1.9   0:33.72 S grafana server <span class="nt">--homepath</span><span class="o">=</span>/usr/share/grafana <span class="nt">--config</span><span class="o">=</span>/etc/grafana/grafana.ini+ 
  67599 root      20   0 1004.7m 104.5m   0.0   1.3   0:44.48 S influxd 

</code></pre></div></div>

<p><a href="https://hub.docker.com/r/scaleoutsean/solidshell">solidshell</a> (PowerShell + SolidFire Core) container where I ran SolidFire and InfluxDB client is at the top and uses more than 2x more RAM.</p>

<h2 id="kubernetes-jobs">Kubernetes jobs</h2>

<p>solidshell reminds me that my jobs were dispatched from a Kubernetes pod. I should mention I put it in the same namespace as InfluxDB.</p>

<p>You don’t have to backup Kubernetes volumes (PVs) - any volumes can be backed up as backup is done on SolidFire which knows nothing about volume contents - but I mention this because you don’t have to stand up a VM just to run PowerShell.</p>

<p>Also, securing your SolidFire administrator credentials may be easier on Kubernetes than in a VM.</p>

<p>But if you want to run that script from some Windows workstation, that will work as well as long as you can reach both SolidFire MVIP and InfluxDB API endpoint.</p>

<h2 id="conclusion">Conclusion</h2>

<p>If you don’t have a bureaucratic IT environment and if your cluster has up to 100 volumes, maybe you want to use SolidFire’s backup-to-S3.</p>

<p>While most packaged backup solutions - including Velero - have job monitoring built in, SolidFire’s backup-to-S3 needs some extra effort, but can be monitored just as effectively (in fact, it can be monitored even better as Velero currently still has some bugs in the area of monitoring and metrics).</p>

<p>InfluxDB v1 is far from dead, it can run in just 128 MiB RAM and it’s easier to use and work with than most other DBs. There are Python and PowerShell clients, which makes integration easy.</p>

<p>Having backup job details in a cloud-based VM with InfluxDB makes it very easy to find backups in no time, which can be useful for DR as well.</p>

<p>You’ll be better off with a commercial solution but if you don’t have one or want to take an independent backup to public cloud S3 once a week, now it’s easy to automate and monitor that workload. If you start with that script I wrote, logging to InfluxDB may take just 2-3 hours of work.</p>

<h2 id="appendix-a---gauge-visualization">Appendix A - Gauge visualization</h2>

<p>Simply switching to gauge will work, but it may be hard to identify the struggling volumes.</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-05-influx-backupprogress-gauges-small.png" alt="" /></p>

<p>With custom threshold formatting, it’s easier to spot which ones are far from being complete.</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-06-influx-backupprogress-gauge-thresholds.png" alt="" /></p>

<p>For some reason even though I had srcVolId in my data, I couldn’t show volume ID on the gauges (instead the best I could do was bvId tag), but I didn’t want to spend more time on this. The point is that with proper visualization it’s easy to monitor dozens of volumes this way.</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-07-influx-backupprogress-gauge-100pct-complete.png" alt="" /></p>

<h2 id="appendix-b---grafana-alerts">Appendix B - Grafana alerts</h2>

<p>After some fooling around I created several versions of panels that show failed jobs.</p>

<ul>
  <li>Example Grafana payload: <code class="language-plaintext highlighter-rouge">'backup,cluster=PROD,bvId=4444,snapId=4444 volId=44,volName="bigvol2",status="error"'</code></li>
  <li>Example queries:
    <ul>
      <li>(top panel in screenshot below) <code class="language-plaintext highlighter-rouge">SELECT "status" FROM "backup" WHERE ("cluster"::tag = 'PROD') AND $timeFilter</code></li>
      <li>(bottom panel) <code class="language-plaintext highlighter-rouge">SELECT "volId" FROM "backup" WHERE ("cluster"::tag = 'PROD' AND "status"::field = 'error') AND $timeFilter GROUP BY "bvId"::tag ORDER BY time DESC</code></li>
    </ul>
  </li>
</ul>

<p>One thing I realized Grafana is very complex to use for multi-column queries (one has to use Transformations, etc - it’s a nightmare). Table at the bottom was the easiest way to create alerts because it simply looks for errors and nothing else.</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-09-backup-errors.png" alt="" /></p>

<p>Then we can create alert (email, Slack, etc.), such as “when number of errors in the last 24 hours is &gt; 0”.</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-08-grafana-alert-green.png" alt="" /></p>

<p>When such a condition occurs, that alert enters Pending state (not really necessary for backups unless you set Pending Timeout to say 2 hours and have retry logic in the backup job script).</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-10-grafana-alert-pending.png" alt="" /></p>

<p>After Pending timeout expires, alert starts firing at which point it can be acted upon, silenced, etc.</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-11-grafana-alert-firing.png" alt="" /></p>

<p>I’d be careful with automated rescheduling of failed backup-to-S3 jobs because each could create TBs of extra network traffic.</p>

<p>My preferred way of dealing with such alerts would be to manually kick off individual backups that should be retried or even do nothing, if you backup daily and can wait until the same jobs runs the next day.</p>

<p>Depending on one’s objective, it may be easier to just combine several tags into one and eliminate Grafana Transformations. For example, something like this:</p>

<ul>
  <li>Before: <code class="language-plaintext highlighter-rouge">'backup, cluster=PROD,bvId=222,snapId=2222 volId=22, volName="bigvol2",status="error"'</code></li>
  <li>After: <code class="language-plaintext highlighter-rouge">'backup, cluster=PROD,jobId=v22-s2222-b222 volId=22,status="error"'</code> (v=VolumeID, s=SnapshotID, b=bvID)</li>
</ul>

<p>This isn’t a best practice in InfluxDB world and while it bloats indexes, it works. In this particular case we’re recording backup jobs, so even if you add 1000 entries a day, that’s hardly going to matter. It’s not like we’re running a massive IoT monitoring site.</p>

<p>Then:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="nv">"volId"</span> <span class="k">FROM</span> <span class="nv">"backup"</span> 
<span class="k">WHERE</span> <span class="p">(</span><span class="nv">"cluster"</span><span class="p">::</span><span class="n">tag</span> <span class="o">=</span> <span class="s1">'PROD'</span> <span class="k">AND</span> <span class="nv">"status"</span><span class="p">::</span><span class="n">field</span> <span class="o">=</span> <span class="s1">'error'</span><span class="p">)</span> 
<span class="k">AND</span> <span class="err">$</span><span class="n">timeFilter</span> 
<span class="k">GROUP</span> <span class="k">BY</span> <span class="nv">"jobId"</span><span class="p">::</span><span class="n">tag</span> 
<span class="k">ORDER</span> <span class="k">BY</span> <span class="nb">time</span> <span class="k">DESC</span>
</code></pre></div></div>

<p>With that one query we’d see everything we need to know in the column jobId: <code class="language-plaintext highlighter-rouge">v22-s2222-b222</code>.</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-12-grafana-combined-tags.png" alt="" /></p>

<p>Combining tags may be convenient, but “by tag” search then becomes impossible without Transformations, so it’s just a tradeoff.</p>

<p>I also tried another approach, with backup status as 0 (started or running) or 1 (failed):</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">'backup, volId=11,cluster=PROD stage=complete status=1'</code></li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="nv">"status"</span> <span class="k">FROM</span> <span class="nv">"backup"</span> 
<span class="k">WHERE</span> <span class="p">(</span><span class="nv">"cluster"</span><span class="p">::</span><span class="n">tag</span> <span class="o">=</span> <span class="s1">'PROD'</span><span class="p">)</span> <span class="k">AND</span> <span class="err">$</span><span class="n">timeFilter</span> 
<span class="k">GROUP</span> <span class="k">BY</span> <span class="nv">"volId"</span><span class="p">::</span><span class="n">tag</span> 
<span class="k">ORDER</span> <span class="k">BY</span> <span class="nb">time</span> <span class="k">DESC</span>
</code></pre></div></div>

<p>Something like that may make it easier to watch a bunch of volumes and jobs at the same time.</p>

<p>After trial and error, I settled for this approach regarding status values:</p>

<ul>
  <li>job running = 1</li>
  <li>success = 2</li>
  <li>fail = 3</li>
</ul>

<p>Then in Grafana I just map these values to colors, with 1 mapped to “transparent” (no color).</p>

<p><img src="/assets/images/solidfire-backup-job-monitoring-influxdb-13-grafana-backup-binary-field-values.png" alt="" /></p>

<p>Now I can see when jobs are running, when they’re not, which succeeded and which failed.</p>

<p>If I zoom out timeline-wise or zoom in Volume ID-wise (drop-down selector), I can recognize problematic patterns and implement corrective action, such as adding QoS exceptions to large volumes or scheduling fewer backup jobs in parallel.</p>

<p>I’ll probably use something like this if I add “send-to-InfluxDB” to that backup script of mine.</p>

<p>To be honest, it seems <em>much easier</em> to send logs and jobs to Elasticsearch and hook Grafana into Elasticsearch instead so that Grafana only does visualization and alerting, if you don’t want to use <a href="https://www.elastic.co/guide/en/kibana/current/alerting-getting-started.html">Kibana</a> for that. <a href="/2021/10/18/solidfire-syslog-filebeat-logstash-elk-stack.html#get-events-and-faults-completely-from-api-logs">Here</a> you can see how we can forward SolidFire events to Elasticsearch and get structured logs, backup job reporting, and alerts all done in minutes. If we choose that route, there’s very little we need to send to InfluxDB using our backup script.</p>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#storage">storage</a>
      &nbsp; 
    
      <a href="
      /categories/#analytics">analytics</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2024/05/03/netapp-solidfire-collector-next.html">Towards next SolidFire Collector (SFC)</a></li>
      
        <li><a href="/2024/05/29/sfc-v2.html">SolidFire Collector v2.0.0 is ready</a></li>
      
        <li><a href="/2024/04/23/grafana-11-netapp-solidfire-sfc.html">NetApp SolidFire Collector with Grafana 11</a></li>
      
        <li><a href="/2024/05/20/netapp-solidfire-input-for-telegraf.html">Use Telegraf to send NetApp SolidFire metrics to InfluxDB</a></li>
      
        <li><a href="/2023/01/14/eseries-performance-analyzer-container-orchestrator-kubernetes.html">NetApp E-Series Performance Analyzer in orchestrated container environments</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2025-06-05 03:25 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
