<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Windows Server 2025 with NetApp SolidFire 12 iSCSI | Acting Technologist
      
    </title>
    <meta name="description" content="
     Notes on using Windows Server 2025 with NetApp SolidFire iSCSI storage
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Windows Server 2025 with NetApp SolidFire 12 iSCSI | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Windows Server 2025 with NetApp SolidFire 12 iSCSI" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en" />
<meta name="description" content="Notes on using Windows Server 2025 with NetApp SolidFire iSCSI storage" />
<meta property="og:description" content="Notes on using Windows Server 2025 with NetApp SolidFire iSCSI storage" />
<link rel="canonical" href="https://scaleoutsean.github.io/2024/03/31/windows-server-2025-with-solidfire-part-one.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2024/03/31/windows-server-2025-with-solidfire-part-one.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:image" content="https://scaleoutsean.github.io/assets/images/windows-server-2025-hyper-v-solidfire-15-windows-iscsi-initiator-report-confusion.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-03-31T00:00:00+08:00" />
<script type="application/ld+json">
{"headline":"Windows Server 2025 with NetApp SolidFire 12 iSCSI","dateModified":"2024-03-31T00:00:00+08:00","datePublished":"2024-03-31T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2024/03/31/windows-server-2025-with-solidfire-part-one.html"},"image":"https://scaleoutsean.github.io/assets/images/windows-server-2025-hyper-v-solidfire-15-windows-iscsi-initiator-report-confusion.png","author":{"@type":"Person","name":"scaleoutSean"},"@type":"BlogPosting","url":"https://scaleoutsean.github.io/2024/03/31/windows-server-2025-with-solidfire-part-one.html","description":"Notes on using Windows Server 2025 with NetApp SolidFire iSCSI storage","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Windows Server 2025 with NetApp SolidFire 12 iSCSI</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>31 Mar 2024</span> - <i class="far fa-clock"></i> 


  
  
    15 minute read
  

    </span>
  </div>
  
        <p>This is the first of possibly several posts on Microsoft Windows Server 2025 and NetApp SolidFire.</p>

<ul>
  <li>(you’re here) <strong>Part One: Windows Server 2025 with NetApp SolidFire</strong> - getting started</li>
  <li><a href="/2024/04/01/windows-server-2025-with-solidfire-part-two-sql-server-2022.html">Part Two: Windows Server 2025 with NetApp SolidFire 12 iSCSI</a> - snapshots and SQL Server 2022</li>
  <li><a href="/2024/04/01/windows-server-2025-with-solidfire-part-three-hyper-v.html">Part Three: Windows Server 2025 with NetApp SolidFire 12 iSCSI</a> - notes related to Hyper-V</li>
</ul>

<p>In this post you can find the following:</p>

<ul>
  <li><a href="#connect-to-solidfire-iscsi-targets">Connect to SolidFire iSCSI targets</a></li>
  <li><a href="#sql-server-t-sql-snapshots-and-solidfire-volume-snapshots">SQL Server T-SQL snapshots and SolidFire volume snapshots</a>
    <ul>
      <li><a href="#sql-backup-and-solidfire">SQL Backup and SolidFire</a></li>
    </ul>
  </li>
  <li><a href="#single-and-multi-site-solidfire-clusters-and-disaster-recovery">Single and multi-site SolidFire clusters and Disaster Recovery</a></li>
  <li><a href="#windows-to-storage-mapping-approaches">Windows-to-Storage mapping approaches</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
  <li><a href="#appendix-a---cmdlets">Appendix A - cmdlets</a></li>
</ul>

<h2 id="connect-to-solidfire-iscsi-targets">Connect to SolidFire iSCSI targets</h2>

<p>My <a href="https://github.com/scaleoutsean/solidfire-windows/">solidfire-windows</a> repository has the details of the workflow I used when setting up Windows with SolidFire iSCSI. Please check out that README for the details.</p>

<p>This post will only add some new or very detailed comments and observations specific to Windows Server 2025 (currently in Preview).</p>

<p>First, I used just one NIC for both services and iSCSI. Of course, that’s a bad idea, normally we’d have 4 NICs, and maybe use one pair for front-end services, and another pair (LACP or not) for iSCSI. But this (192.168.1.199 is a route to my iSCSI L2 network) worked for me.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-01-iscsi-routing.png" alt="" /></p>

<p>One of the nice enhancements in Windows Server 2025 is that it now takes a single click (in Local Server Properties) to enable SSH server. That’s it!</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-02-ssh-server.png" alt="" /></p>

<p>With a <em>properly configured firewall</em> and SSH server enabled, it’s possible to easily and securely access it remotely from any modern client.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-03-iscsi-target-discovery.png" alt="" /></p>

<p>This also makes it possible to edit your PowerShell or other scripts remotely with VS Code over SSH. (I haven’t tried that specifically, though.)</p>

<p>When creating a SolidFire tenant account for Windows, we can use Volume Access Groups (VAG) or CHAP. For Hyper-V clusters, it’s easier to use VAG, but iSCSI Control Panel (Configuration tab) allows you to specify a CHAP secret for the initiator - just remember to enter it on all cluster members if dealing with HA clusters.</p>

<p>Once we add our SolidFire target (Storage VIP), we should be able discover disks. This is where fun begins…</p>

<p>At first I created 2 disks on SolidFire:</p>

<ul>
  <li>1G volume with 512b emulation</li>
  <li>2G volume with native 4kB addressing</li>
</ul>

<p>But the second target got discovered first (Disk 0 - OS; Disk 1 - 2G, Disk 2 - 1G)</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-04-physical-volumes-list-filter.png" alt="" /></p>

<p>At this point it becomes clear this won’t be simple… Time to use that SSH access and get in!</p>

<p>I installed PowerShell 7. It’s weird that this Preview shows it in the menu, but then when you start that PowerShell 7, it’s actually version 5.1!</p>

<p>I wanted to install SolidFire Core (for PS 7) so I downloaded the latest preview release from Github.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-05-powershell-solidfire.png" alt="" /></p>

<ul>
  <li>Step 1 - start PowerShell 7 from CMD (in SSH session)</li>
  <li>Step 2 - Install SolidFire Core</li>
  <li>Step 3 - Import SolidFire Core module</li>
  <li>Step 4 - create credential for SolidFire</li>
  <li>Step 5 - connect to SolidFire cluster</li>
</ul>

<p>Now below my Windows tenant account is 13, and I got a list of volumes for this tenant.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-06-powershell-solidfire-account-volumes.png" alt="" /></p>

<p>I also installed <a href="https://www.vim.org/download.php">Vim for Windows</a> because I prefer it to fiddling around with VS Code.</p>

<h2 id="sql-server-t-sql-snapshots-and-solidfire-volume-snapshots">SQL Server T-SQL snapshots and SolidFire volume snapshots</h2>

<p>I didn’t need to use snapshots, but if you run SQL Server, you may.</p>

<p>I came across this part in the <a href="https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/create-a-transact-sql-snapshot-backup?view=sql-server-ver16">SQL Server documentation</a> related to Transact-SQL snapshot backups.</p>

<blockquote>
  <p>Because we must freeze I/O for the duration of the snapshot operation, it is essential that the snapshot happens quickly, so that the workload on the server isn’t interrupted for an extended period.</p>
</blockquote>

<p>Quickly? No problem!</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-07-powershell-solidfire-snapshot-duration-retention.png" alt="" /></p>

<p>Point 1 shows it takes 0.2 seconds to snapshot a volume.</p>

<p>Admittedly this was on an idle volume, but SQL is idled in the pre-snapshot action with <code class="language-plaintext highlighter-rouge">SUSPEND_FOR_SNAPSHOT_BACKP</code> executed by SQL Server, and after that we need to take a snapshot quickly on SolidFire. 0.2 seconds ought to be enough for everyone. Why should we care about this niche stuff? See at the link:</p>

<blockquote>
  <p>In the past, users have relied on third-party solutions that were built on top of the SQL Writer service to complete snapshot backups. The SQL Writer service depends on Windows VSS (Volume Shadow Service) along with SQL Server VDI (Virtual Device Interface) to perform the orchestration between SQL Server and the disk-level snapshot. Backup clients based on the SQL Writer service tend to be complex, and they only work on Windows. With T-SQL snapshot backups, the SQL Server side of the orchestration can be handled with a series of T-SQL commands.</p>
</blockquote>

<p>This means you <em>no longer need</em> SolidFire VSS Hardware Provider to take application-consistent SQL Server 2022 backups (as long as this approach works).</p>

<p>Point 2 shows snapshot retention. Notice there’s the parameter <code class="language-plaintext highlighter-rouge">Retention</code> in the SolidFire snapshot cmdlet in the screenshot above. I set that to <code class="language-plaintext highlighter-rouge">"00:01:00"</code> meaning 1 minute, because I wanted to see how SolidFire clears snapshots with a very short retention.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-08-solidfire-snapshot-retention.png" alt="" /></p>

<p>It turned out it works fine, but garbage collection doesn’t seem to run <em>that</em> frequently, so snapshots with such short retention usually get deleted a bit later than specified.</p>

<p>They do get deleted within minutes, but beyond the 1 minute we specified (marked with 1). Five minute retention time seems reasonable and those deleted on time (marked with 2).</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-09-solidfire-snapshot-retention-5m.png" alt="" /></p>

<p>That shouldn’t matter to you unless you take extremely frequent T-SQL snapshots - given SolidFire snapshot limit of 32 snapshots per volume, if you were to take them once a minute expire in 1 minute, you may hit the limit if the volume already has other snapshots from another schedule. Every five minutes with 5 minute retention could be practical.</p>

<p>On SolidFire itself, (storage) snapshot doesn’t have to be retained for a very short time and then deleted. It can be cloned for backup, replicated to another site, or cloned for testing by another tenant. You may want to retain every Nth snapshot for 24 hours, which could be done in various ways, but the simplest is two T-SQL snapshot schedules - for example one every 15 min with 30 min retention (this would use half a dozen) and one every 24 hours with 24 hour retention.</p>

<h3 id="sql-backup-and-solidfire">SQL Backup and SolidFire</h3>

<p>Because SolidFire’s VSS hardware provider hasn’t been developed for a while, that was a problem for some SQL Servers, from what I’ve heard second-hand. I didn’t understand in what business or technical circumstances the lack of a VSS hardware provider present problems when SolidFire is so easy to automate.</p>

<p>One problem area that I recognized is the lack of proper RBAC, so some users hesitate to make the API accessible to server admins. But even so, there are <a href="https://scaleoutsean.github.io/2023/12/07/solidfire-rbac-for-json-rpc-api.html">ways to mitigate the lack of rich RBAC</a> which most enterprises know how to securely implement (or better, most already have such infrastructure in place and just need to add a virtual host for SolidFire API endpoint).</p>

<p>Another “recent” (not really) SQL Server feature is the ability to backup SQL Server to <a href="https://scaleoutsean.github.io/2023/08/28/sql-server-polybase-s3.html#backup-use-case">an object store</a>. It takes minutes to configure and for small and medium databases that may be the easiest way to backup SQL Server and achieve ransomware-resistant (if your object store has Object Lock) backups with just a handful of SQL Server CLI commands.</p>

<h2 id="single-and-multi-site-solidfire-clusters-and-disaster-recovery">Single and multi-site SolidFire clusters and Disaster Recovery</h2>

<p>A SolidFire cluster can be deployed on one site or across (low latency) sites. For Disaster Recovery, replication (sync and async) are available and is purely storage based.</p>

<ul>
  <li>Single site, single SolidFire cluster: this worked fine before, including with Hyper-V,</li>
  <li>Multi-site, single SolidFire cluster: technically one can stretch a SolidFire cluster across 3 racks or low-latency sites. See about <a href="/2021/06/08/solidfire-availability-zones.html">protection domains</a>, but I doubt there will be any official work done on this. Technically there’s no difference between 9 1U chassis, 3 2U chassis, 3 racks or 3 data centers - it always works the same way, on a stretched Layer 2 network with properly configured MTU so that packets don’t get fragmented or sent out of order.</li>
  <li>Disaster recovery (two SolidFire clusters): just use volume replication which can be setup in 5 minutes. Snapshots can be replicated as well - but need to be tagged on creation to make them available for replication - and snapshot retention on the remote site may be configured differently from the source site.</li>
</ul>

<p>One note about snapshots replication: <a href="/2021/04/20/solidfire-12.3.html">make sure</a> they don’t expire before they can get replicated.</p>

<p>To restore data from a remote site, just reverse the direction of replication. You can see <a href="/2021/03/20/kubernetes-solidfire-failover-failback.html#video-demo">here</a> how a site can be failed over <em>and back</em> in less than 10 minutes. Failover and failback work symmetrically and it’s trivial to execute.</p>

<p>As I mentioned elsewhere, the difference in IQN targets is the cluster Unique ID, which can be obtained like so:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">C:\Users\Administrator</span><span class="err">&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">Get-SFClusterInfo</span><span class="p">)</span><span class="o">.</span><span class="nf">UniqueID</span><span class="w">
</span><span class="n">wcwb</span><span class="w">

</span></code></pre></div></div>

<p>The difference between <em>two</em> clusters:</p>

<ul>
  <li>Management and Storage virtual IP (as well as nodes’ IP’s)</li>
  <li>Cluster Name (<code class="language-plaintext highlighter-rouge">DC1</code>, <code class="language-plaintext highlighter-rouge">DC2</code>) and UniqueID (used in SolidFire IQN)</li>
  <li>Volume names may be different or consistent; in practice I found it hard to ensure consistency because each site may need to do various things like cloning and so on, especially when containers are used</li>
  <li>Volume IDs are unique and not controllable, so there’s no way to “guess” them</li>
</ul>

<p>If you keep track of your configuration or automate it like I did in that demo, it’s easy to swap configuration details and reconfigure iSCSI initiators: swap <code class="language-plaintext highlighter-rouge">iqn.2010-01.com.solidfire:wcwb.sqldb.136</code> for <code class="language-plaintext highlighter-rouge">iqn.2010-01.com.solidfire:aaaa.sqldata.49</code>, change iSCSI Target Portal to new Storage Virtual IP, re-scan, and that should let you see the replicated volumes. You would have to stop replication from DC1 to DC2, flip DC2 volumes to read-write mode, and then reverse the direction of replication so that DC2 starts replicating to DC1.</p>

<h2 id="windows-to-storage-mapping-approaches">Windows-to-Storage mapping approaches</h2>

<p>Earlier we saw how the “second” SolidFire volume for Windows got discovered and accessed first, so one has to watch out for device slippage and mapping consistency. I don’t say “worry” but “watch out” because I haven’t heard that it’s a problem - we just need to be careful.</p>

<p>So, how to map Windows volumes to SolidFire devices? Can we do it with <code class="language-plaintext highlighter-rouge">Get-Disk</code> and <code class="language-plaintext highlighter-rouge">Get-SFVolume</code>?</p>

<ul>
  <li>Point 1: Windows serial numbers look promising! But if we look carefully, they are <em>not</em> the same.</li>
  <li>Point 2: maybe we should consider using disk volume labels that reflect a SolidFire volume’s property? But VolumeID may change (say, if we restore it from a backup), so perhaps we should configure Windows with the Volume Name (which is <em>not</em> done in this screenshot)</li>
</ul>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-10-windows-to-solidfire-mapping-approaches.png" alt="" /></p>

<p>The second approach seems better, so let’s do that.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-11-windows-filesystemlabel-solidfire-volume-name.png" alt="" /></p>

<p>Now the third volume has a volume label that’s identical to the SolidFire volume name. Obviously, we should now avoid creating volumes with duplicate names.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-12-windows-filesystemlabel-done.png" alt="" /></p>

<p>With that in place, it is possible to match Windows volume labels with SolidFire volume names and create a report that maps Windows volumes to SolidFire volumes.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-13-windows-to-solidfire.png" alt="" /></p>

<p>Windows Disks are still “out of order” (or rather, in order of discovery), as you can see above. I think it’s probably futile trying to ensure consistent ordering of order of Windows Disks and SolidFire Volume IDs.</p>

<p>It could be done like so:</p>

<ul>
  <li>Create the first SolidFire volume, scan iSCSI, login to Physical Disk 1, create volume mounted at E:</li>
  <li>Create the second SolidFire volume, etc. get volume F:</li>
  <li>etc.</li>
</ul>

<p>But I don’t know if such an ordering could be <em>preserved</em>, so I didn’t try to do it. Also, what to do if you need to add a new volume “in between” E: and F:?</p>

<p>I didn’t notice this before (in older versions of Windows), but iSCSI Control Panel lets you create volume binding to iSCSI devices, which adds E:, F: and G: to the panel when you click on Auto Configure. You can also use Add/Remove, but even as you add a single mount point (e.g. E:), Windows won’t let you specify <em>which</em> SolidFire volume would be bound to E:.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-14-windows-iscsi-fix-volume-mountpoints.png" alt="" /></p>

<p>Volume List is merely a “reservation” of letters which perhaps makes Windows skip an enumeration/scan of available mount points.</p>

<p>It’s just a <em>list</em> of drive letters, not a map of drive-to-disk pairing, so I wonder if device slippage can still happen if (say) device binding E or F disappear. We’d want fixed device names, but I haven’t found a way to do it with Windows Server 2025 Preview.</p>

<p>Another confusing detail is that even iSCSI Report (in Configuration tab) is helpless.</p>

<p><img src="/assets/images/windows-server-2025-hyper-v-solidfire-15-windows-iscsi-initiator-report-confusion.png" alt="" /></p>

<ul>
  <li>SolidFire Volume 134 was created first and 135 immediately after that (before Windows storage scan)</li>
  <li>Windows iSCSI Report says SolidFire volume ID 135 is Target #0 (yay!)</li>
  <li>Windows iSCSI Report also says Target #0 is Disk 2, which is in fact iSCSI Target 1 in Disk Manager (huh?)</li>
</ul>

<p>Where’s Target 0, then? It’s SolidFire volume ID 135 which is shown in iSCSI report (green rectangles), as Target #1 (iSCSI Target 0 to Disk Manager).</p>

<p>Imagine having to deal with that for 8 or 16 volumes!!! “iSCSI Target #7 is Target 4 which is Disk 2”.</p>

<p>This seems hard to control as well, so I figure the best one can do is create some sort of a report that relies on unique SolidFire volume names (this volume naming policy administrator must be responsible for) and the consistent consistency of those names with Windows volume labels.</p>

<p>With that - however you get this done - you can reasonably easily confirm this alignment and potentially automate storage replication and BC/DR.</p>

<p>Example below shows I have consistent filesystem labels and SolidFire volume names, as well as respective drive letters (or paths, if you use those).</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">C:\</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$win2sf</span><span class="w">

</span><span class="n">Name</span><span class="w">                           </span><span class="nx">Value</span><span class="w">
</span><span class="o">----</span><span class="w">                           </span><span class="o">-----</span><span class="w">
</span><span class="n">win1</span><span class="w">                           </span><span class="p">{[</span><span class="n">SfIqn</span><span class="p">,</span><span class="w"> </span><span class="n">iqn.</span><span class="mi">2010</span><span class="nt">-01</span><span class="o">.</span><span class="nf">com</span><span class="o">.</span><span class="nf">solidfire</span><span class="p">:</span><span class="n">wcwb.win1.</span><span class="mi">134</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">DriveLetter</span><span class="p">,</span><span class="w"> </span><span class="n">F</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">SfVolID</span><span class="p">,</span><span class="w"> </span><span class="mi">134</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">FileSystem</span><span class="p">,</span><span class="w"> </span><span class="n">NTFS</span><span class="p">]</span><span class="err">…</span><span class="p">}</span><span class="w">
</span><span class="n">win2</span><span class="w">                           </span><span class="p">{[</span><span class="n">SfIqn</span><span class="p">,</span><span class="w"> </span><span class="n">iqn.</span><span class="mi">2010</span><span class="nt">-01</span><span class="o">.</span><span class="nf">com</span><span class="o">.</span><span class="nf">solidfire</span><span class="p">:</span><span class="n">wcwb.win2.</span><span class="mi">135</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">DriveLetter</span><span class="p">,</span><span class="w"> </span><span class="n">G</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">SfVolID</span><span class="p">,</span><span class="w"> </span><span class="mi">135</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">FileSystem</span><span class="p">,</span><span class="w"> </span><span class="n">NTFS</span><span class="p">]</span><span class="err">…</span><span class="p">}</span><span class="w">
</span><span class="n">sqldb</span><span class="w">                          </span><span class="p">{[</span><span class="n">SfIqn</span><span class="p">,</span><span class="w"> </span><span class="n">iqn.</span><span class="mi">2010</span><span class="nt">-01</span><span class="o">.</span><span class="nf">com</span><span class="o">.</span><span class="nf">solidfire</span><span class="p">:</span><span class="n">wcwb.sqldb.</span><span class="mi">136</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">DriveLetter</span><span class="p">,</span><span class="w"> </span><span class="n">E</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">SfVolID</span><span class="p">,</span><span class="w"> </span><span class="mi">136</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">FileSystem</span><span class="p">,</span><span class="w"> </span><span class="n">NTFS</span><span class="p">]</span><span class="err">…</span><span class="p">}</span><span class="w">


</span><span class="n">PS</span><span class="w"> </span><span class="n">C:\</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$win2sf</span><span class="o">.</span><span class="nf">win1</span><span class="w">

</span><span class="n">Name</span><span class="w">                           </span><span class="n">Value</span><span class="w">
</span><span class="o">----</span><span class="w">                           </span><span class="o">-----</span><span class="w">
</span><span class="n">SfIqn</span><span class="w">                          </span><span class="n">iqn.</span><span class="mi">2010</span><span class="nt">-01</span><span class="o">.</span><span class="nf">com</span><span class="o">.</span><span class="nf">solidfire</span><span class="p">:</span><span class="n">wcwb.win1.</span><span class="mi">134</span><span class="w">
</span><span class="n">DriveLetter</span><span class="w">                    </span><span class="n">F</span><span class="w">
</span><span class="nx">SfVolID</span><span class="w">                        </span><span class="nx">134</span><span class="w">
</span><span class="n">FileSystem</span><span class="w">                     </span><span class="n">NTFS</span><span class="w">
</span><span class="n">FileSystemLabel</span><span class="w">                </span><span class="n">win1</span><span class="w">
</span><span class="n">SfVolName</span><span class="w">                      </span><span class="n">win1</span><span class="w">

</span><span class="n">PS</span><span class="w"> </span><span class="n">C:\</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$win2sf</span><span class="o">.</span><span class="nf">win2</span><span class="w">

</span><span class="n">Name</span><span class="w">                           </span><span class="n">Value</span><span class="w">
</span><span class="o">----</span><span class="w">                           </span><span class="o">-----</span><span class="w">
</span><span class="n">SfIqn</span><span class="w">                          </span><span class="n">iqn.</span><span class="mi">2010</span><span class="nt">-01</span><span class="o">.</span><span class="nf">com</span><span class="o">.</span><span class="nf">solidfire</span><span class="p">:</span><span class="n">wcwb.win2.</span><span class="mi">135</span><span class="w">
</span><span class="n">DriveLetter</span><span class="w">                    </span><span class="n">G</span><span class="w">
</span><span class="nx">SfVolID</span><span class="w">                        </span><span class="nx">135</span><span class="w">
</span><span class="n">FileSystem</span><span class="w">                     </span><span class="n">NTFS</span><span class="w">
</span><span class="n">FileSystemLabel</span><span class="w">                </span><span class="n">win2</span><span class="w">
</span><span class="n">SfVolName</span><span class="w">                      </span><span class="n">win2</span><span class="w">

</span><span class="n">PS</span><span class="w"> </span><span class="n">C:\</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$win2sf</span><span class="o">.</span><span class="nf">sqldb</span><span class="w">

</span><span class="n">Name</span><span class="w">                           </span><span class="n">Value</span><span class="w">
</span><span class="o">----</span><span class="w">                           </span><span class="o">-----</span><span class="w">
</span><span class="n">SfIqn</span><span class="w">                          </span><span class="n">iqn.</span><span class="mi">2010</span><span class="nt">-01</span><span class="o">.</span><span class="nf">com</span><span class="o">.</span><span class="nf">solidfire</span><span class="p">:</span><span class="n">wcwb.sqldb.</span><span class="mi">136</span><span class="w">
</span><span class="n">DriveLetter</span><span class="w">                    </span><span class="n">E</span><span class="w">
</span><span class="nx">SfVolID</span><span class="w">                        </span><span class="nx">136</span><span class="w">
</span><span class="n">FileSystem</span><span class="w">                     </span><span class="n">NTFS</span><span class="w">
</span><span class="n">FileSystemLabel</span><span class="w">                </span><span class="n">sqldb</span><span class="w">
</span><span class="n">SfVolName</span><span class="w">                      </span><span class="n">sqldb</span><span class="w">

</span></code></pre></div></div>

<p>It’s not cluster-aware (it doesn’t gather host names), but it could be modified to gather data from different hosts for a cluster-wide view.</p>

<p>Another way to create a (Windows) cluster-wide or (SolidFire) storage-wide view would be to include server names and key SolidFire volumes on volume.Iqn, and send reports to Elasticsearch or other database. Then it would be easy to get a big picture from a custom table.</p>

<p><strong>NOTE:</strong> I noticed that the original (first) Windows volume label remains buried in deep in volume properties. That seems fine, as changing the label does work as expected (the label does get changed), but you need to be careful not to use some obscure parameter values if you’ve changed labels. An easy fix for that is to stick one one volume label for the lifetime of a volume.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Both 512b and 4kB sectors worked, and iSCSI-wise it seems not much has changed.</p>

<p>The ability to do easy remoting with SSH is a big improvement.</p>

<p>Drive-to-storage mapping is still not as good in VMware where it’s easy to figure that out by comparing ESXi and the SolidFire volume’s ScsiNAADeviceID. For that reason, I’d just focus on volume labels and SolidFire volume names when managing SolidFire in Windows environments.</p>

<p>The rest of Windows-related configuration details, considerations and best practices can be found in my Github repo.</p>

<h2 id="appendix-a---cmdlets">Appendix A - cmdlets</h2>

<p>Here are some examples to get you started.</p>

<p>Windows volume information can be gathered for the labels (and SolidFire volume names) to exclude OS boot disk, for example.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">C:\</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$win_vol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-Volume</span><span class="w"> </span><span class="nt">-FileSystemLabel</span><span class="w"> </span><span class="nx">sqldb</span><span class="p">,</span><span class="nx">win1</span><span class="p">,</span><span class="nx">win2</span><span class="w">
</span></code></pre></div></div>

<p>Windows iSCSI sessions that connect to SolidFire. Note that <code class="language-plaintext highlighter-rouge">iqn.2010-01.com.solidfire:wcwb.sqldb.136</code> contains a cluster Unique ID (<code class="language-plaintext highlighter-rouge">wcwb</code>), so you could add that if connected to multiple SolidFire clusters from the same Windows iSCSI client.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PS C:\&gt; $iscsi_session = Get-IscsiSession  | Where-Object -Property TargetNodeAddress -CMatch "iqn.2010-01.com.solidfire"

</code></pre></div></div>

<p>To get SolidFire volumes used by a storage tenant account, specify their account ID.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">C:\</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$sf_vol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">Get-SFVolume</span><span class="w"> </span><span class="nt">-AccountID</span><span class="w"> </span><span class="nx">13</span><span class="p">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Select-Object</span><span class="w"> </span><span class="nt">-Property</span><span class="w"> </span><span class="nx">Name</span><span class="p">,</span><span class="nx">Iqn</span><span class="p">,</span><span class="nx">VolumeID</span><span class="w">

</span></code></pre></div></div>

<p>When looking for filesystem type, drive letter or filesystem label, you may need to get it from CIM Object Properties (returned by Get-Volume, if you store the object in a variable).</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">C:\</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-Volume</span><span class="w"> </span><span class="nt">-DriveLetter</span><span class="w"> </span><span class="nx">F</span><span class="w">

</span><span class="n">DriveLetter</span><span class="w"> </span><span class="nx">FriendlyName</span><span class="w"> </span><span class="nx">FileSystemType</span><span class="w"> </span><span class="nx">DriveType</span><span class="w"> </span><span class="nx">HealthStatus</span><span class="w"> </span><span class="nx">OperationalStatus</span><span class="w"> </span><span class="nx">SizeRemaining</span><span class="w">    </span><span class="nx">Size</span><span class="w">
</span><span class="o">-----------</span><span class="w"> </span><span class="o">------------</span><span class="w"> </span><span class="o">--------------</span><span class="w"> </span><span class="o">---------</span><span class="w"> </span><span class="o">------------</span><span class="w"> </span><span class="o">-----------------</span><span class="w"> </span><span class="o">-------------</span><span class="w">    </span><span class="o">----</span><span class="w">
</span><span class="n">F</span><span class="w">           </span><span class="nx">win1</span><span class="w">         </span><span class="nx">NTFS</span><span class="w">           </span><span class="nx">Fixed</span><span class="w">     </span><span class="nx">Healthy</span><span class="w">      </span><span class="nx">OK</span><span class="w">                      </span><span class="nx">1.83</span><span class="w"> </span><span class="nx">GB</span><span class="w"> </span><span class="nx">1.85</span><span class="w"> </span><span class="nx">GB</span><span class="w">

</span><span class="n">PS</span><span class="w"> </span><span class="nx">C:\</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$win_vol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-Volume</span><span class="w"> </span><span class="nt">-DriveLetter</span><span class="w"> </span><span class="nx">F</span><span class="w">

</span></code></pre></div></div>

<p>Then loop through the volumes and inspect the properties “FileSystem”, “DriveLetter”, “FileSystemLabel”.</p>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#storage">storage</a>
      &nbsp; 
    
      <a href="
      /categories/#solidfire">solidfire</a>
      &nbsp; 
    
      <a href="
      /categories/#automation">automation</a>
       
    
  </span>
</div>
    

    
      <div class="related" data-pagefind-ignore>

    <h4>Possibly related - use live search at the top to find other content</h4>
    
    
    
    
    
    
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/11/netapp-eseries-containerized-beegfs-nfs-s3-all-in-one.html">• NetApp E-Series with containerized BeeGFS, NFS, S3</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/09/solidbackup-velero-backup-non-k8s-volumes-netapp-solidfire-to-s3.html">• Backup NetApp SolidFire's non-Kubernetes volumes with Velero</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/02/storagegrid-networking.html">• NetApp StorageGRID networks</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/01/windows-server-2025-with-solidfire-part-two-sql-server-2022.html">• Windows Server 2025 with NetApp SolidFire 12 iSCSI Part Two</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/01/windows-server-2025-with-solidfire-part-three-hyper-v.html">• Windows Server 2025 with NetApp SolidFire 12 iSCSI Part Three</a></h5>
          </div>
          
          
            
    
    </div>

    

    
  </div><footer class= "footer">
    <p>2024-04-12 19:27 </p>
    <p>Copyright © 2024 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
