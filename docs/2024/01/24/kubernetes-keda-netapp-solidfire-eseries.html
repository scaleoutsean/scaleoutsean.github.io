<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Kubernetes KEDA with NetApp SolidFire and E-Series | Acting Technologist
      
    </title>
    <meta name="description" content="
     Notes on autoscaling Kubernetes workloads backed by E-Series or SolidFire using KEDA
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Kubernetes KEDA with NetApp SolidFire and E-Series | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Kubernetes KEDA with NetApp SolidFire and E-Series" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notes on autoscaling Kubernetes workloads backed by E-Series or SolidFire using KEDA" />
<meta property="og:description" content="Notes on autoscaling Kubernetes workloads backed by E-Series or SolidFire using KEDA" />
<link rel="canonical" href="https://scaleoutsean.github.io/2024/01/24/kubernetes-keda-netapp-solidfire-eseries.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2024/01/24/kubernetes-keda-netapp-solidfire-eseries.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-24T00:00:00+08:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2024/01/24/kubernetes-keda-netapp-solidfire-eseries.html"},"author":{"@type":"Person","name":"scaleoutSean"},"description":"Notes on autoscaling Kubernetes workloads backed by E-Series or SolidFire using KEDA","@type":"BlogPosting","url":"https://scaleoutsean.github.io/2024/01/24/kubernetes-keda-netapp-solidfire-eseries.html","headline":"Kubernetes KEDA with NetApp SolidFire and E-Series","dateModified":"2024-01-24T00:00:00+08:00","datePublished":"2024-01-24T00:00:00+08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Kubernetes KEDA with NetApp SolidFire and E-Series</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>24 Jan 2024</span> - <i class="far fa-clock"></i> 


  
  
    13 minute read
  

    </span>
  </div>
  
        <ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#keda-concepts-and-components">KEDA concepts and components</a></li>
  <li><a href="#scalers">Scalers</a></li>
  <li><a href="#keda-and-persistent-storage">KEDA and persistent storage</a>
    <ul>
      <li><a href="#solidfire">SolidFire</a></li>
      <li><a href="#e-series">E-Series</a></li>
    </ul>
  </li>
  <li><a href="#storage-related-events">Storage-related events</a>
    <ul>
      <li><a href="#storage-logs">Storage logs</a></li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>WTF is KEDA? From <a href="https://keda.sh">their site</a>:</p>

<blockquote>
  <p>KEDA is a Kubernetes-based Event Driven Autoscaler. With KEDA, you can drive the scaling of any container in Kubernetes based on the number of events needing to be processed.</p>
</blockquote>

<p>The key word here is “event-driven”.</p>

<blockquote>
  <p>KEDA works alongside standard Kubernetes components like the Horizontal Pod Autoscaler and can extend functionality without overwriting or duplication. With KEDA you can explicitly map the apps you want to use event-driven scale, with other apps continuing to function.</p>
</blockquote>

<p>This post won’t deep dive into KEDA - at least not in its first version - since I haven’t gotten any questions about it yet.</p>

<p>But I’ll explore some angles related to two NetApp storage arrays, E-Series and SolidFire (NetApp HCI uses SolidFire, too).</p>

<p>The idea is to share some ideas about linking KEDA with these arrays, so that readers can see if there’s anything of interest that could help them in their environment.</p>

<p>I haven’t <em>actually</em> tried KEDA, which is another reason why I won’t (can’t, really) deep-dive into it.</p>

<h2 id="keda-concepts-and-components">KEDA concepts and components</h2>

<p>Once deployed KEDA has 3 components and can make use of “scalers”:</p>

<ul>
  <li>Agent — KEDA activates and deactivates Kubernetes Deployments to scale to and from zero on no events (keda-operator)</li>
  <li>Metrics — KEDA acts as a Kubernetes metrics server that exposes rich event data like queue length or stream lag to the Horizontal Pod Autoscaler to drive scale out (keda-operator-metrics-apiserver container)</li>
  <li>Admission Webhooks - API that automatically validates resource changes</li>
  <li>Scalers - these are KEDA “plugins” that two two things: (a) detect if a deployment should be (de)activated and (b) feed custom metrics for a specific event source</li>
</ul>

<h2 id="scalers">Scalers</h2>

<p>For v2.13 you can find a list of available scalers <a href="https://keda.sh/docs/2.13/scalers/">here</a>.</p>

<p>I won’t “recommend” any particular scaler because that always “depends”, but I’ll highlight two examples of scalers that are <em>not</em> application-specific.</p>

<p>That is to say, you insert a value (0 or 1) by yourself, and based on that “event” or metric, KEDA does its thing. That way we can use these scalers for storage-related stuff, among other things.</p>

<p>The first one is InfluxDB from that same page. The query triggers (or not) KEDA to do stuff if the result is over those threshold values.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">keda.sh/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ScaledObject</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">influxdb-scaledobject</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">my-project</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">scaleTargetRef</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">nginx-worker</span>
  <span class="na">triggers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">influxdb</span>
      <span class="na">metadata</span><span class="pi">:</span>
        <span class="na">serverURL</span><span class="pi">:</span> <span class="s">http://influxdb:8086</span>
        <span class="na">organizationNameFromEnv</span><span class="pi">:</span> <span class="s">INFLUXDB_ORG_NAME</span>
        <span class="na">thresholdValue</span><span class="pi">:</span> <span class="s1">'</span><span class="s">4'</span>
        <span class="na">activationThresholdValue</span><span class="pi">:</span> <span class="s1">'</span><span class="s">6'</span>
        <span class="na">query</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">from(bucket: "bucket-of-interest")</span>
          <span class="s">|&gt; range(start: -12h)</span>
          <span class="s">|&gt; filter(fn: (r) =&gt; r._measurement == "stat")          </span>
        <span class="na">authTokenFromEnv</span><span class="pi">:</span> <span class="s">INFLUXDB_AUTH_TOKEN</span>
</code></pre></div></div>

<p>My fork of E-Series Performance Analyzer (EPA) stores data in InfluxDB v1, and the above is for v2, so I’d have to modify “insert” queries to send to InfluxDB v2, and then compose a query based on my requirements.</p>

<p>I’ve also created a script for SolidFire (I’ve been slowly updating HCI Collector to change it to work with InfluxDB) and here’s an example of SolidFire volume efficiency metrics stored in InfluxDB v1.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">volume_efficiency</span><span class="p">;</span>
<span class="n">name</span><span class="p">:</span> <span class="n">volume_efficiency</span>
<span class="nb">time</span>                 <span class="n">account_id</span> <span class="n">cluster_name</span> <span class="n">cluster_uid</span> <span class="n">id</span>  <span class="n">volume_efficiency</span>
<span class="c1">----                 ---------- ------------ ----------- --  -----------------</span>
<span class="mi">2023</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">19</span><span class="n">T13</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">22</span><span class="n">Z</span> <span class="mi">1</span>          <span class="n">PROD</span>         <span class="n">wcwb</span>        <span class="mi">1</span>   <span class="mi">1</span>
<span class="mi">2023</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">19</span><span class="n">T13</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">22</span><span class="n">Z</span> <span class="mi">1</span>          <span class="n">PROD</span>         <span class="n">wcwb</span>        <span class="mi">2</span>   <span class="mi">1</span>
<span class="mi">2023</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">19</span><span class="n">T13</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">22</span><span class="n">Z</span> <span class="mi">10</span>         <span class="n">PROD</span>         <span class="n">wcwb</span>        <span class="mi">108</span> <span class="mi">1</span>
<span class="mi">2023</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">19</span><span class="n">T13</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">22</span><span class="n">Z</span> <span class="mi">6</span>          <span class="n">PROD</span>         <span class="n">wcwb</span>        <span class="mi">36</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">46</span>
</code></pre></div></div>

<p>For a specific volume we’d need to know which volume to query, so the query would have to use the right VolumeID such as <code class="language-plaintext highlighter-rouge">WHERE id='36'</code> and it would take some additional effort to figure that out.</p>

<p>We could create the PVC first and use a sidecar that queries Kubernetes to find the PVC and PV name and then SolidFire to find the volume ID. Or, if the application never scaled to less than 1, we could create the first PVC and use the fixed Volume ID by observing PV’s ID on SolidFire.</p>

<p>The second example is Elasticsearch scaler, which also lets you scale applications based on Elasticsearch query results.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">keda.sh/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ScaledObject</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">elasticsearch-scaledobject</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">scaleTargetRef</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">deployment-name"</span>
  <span class="na">triggers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">elasticsearch</span>
      <span class="na">metadata</span><span class="pi">:</span>
        <span class="na">addresses</span><span class="pi">:</span> <span class="s2">"</span><span class="s">http://localhost:9200"</span>
        <span class="na">username</span><span class="pi">:</span> <span class="s2">"</span><span class="s">elastic"</span>
        <span class="na">index</span><span class="pi">:</span> <span class="s2">"</span><span class="s">my-index"</span>
        <span class="na">searchTemplateName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">my-search-template"</span>
        <span class="na">valueLocation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">hits.total.value"</span>
        <span class="na">targetValue</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10"</span>
        <span class="na">parameters</span><span class="pi">:</span> <span class="s2">"</span><span class="s">dummy_value:1"</span>
      <span class="na">authenticationRef</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">keda-trigger-auth-elasticsearch-secret</span>
</code></pre></div></div>

<p>This <a href="/2021/10/18/solidfire-syslog-filebeat-logstash-elk-stack.html">post</a> explains how to get SolidFire metrics and/or logs into Elasticsearch.</p>

<p>So we already have all we need to gather storage metrics we need and configure KEDA to use them.</p>

<h2 id="keda-and-persistent-storage">KEDA and persistent storage</h2>

<p>KEDA’s connection to storage seems almost irrelevant because it’s “indirect” in the sense that if the storage is slow, the application will be slow, too.</p>

<p>Because of that, one may think that it’s simpler and “better” to watch service or application latency (for example), and ignore storage: as application scales out, storage performance increases as well.</p>

<p>As an <a href="https://keda.sh/docs/2.13/scalers/cpu/#example">example</a>, here’s a no-brainer approach for CPU based auto-scaling when CPU utilization hits 70%.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">keda.sh/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ScaledObject</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">cpu-scaledobject</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">default</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">scaleTargetRef</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">database-deployment</span>
  <span class="na">triggers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">cpu</span>
    <span class="na">metricType</span><span class="pi">:</span> <span class="s">Utilization</span> <span class="c1"># Allowed types are 'Utilization' or 'AverageValue'</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">70"</span>
      <span class="na">containerName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">mongodb"</span>
</code></pre></div></div>

<p>Now we just sit and watch. Right? Well, <em>probably</em> not. Why?</p>

<ul>
  <li>Remember the key word from the beginning (event-driven)?</li>
  <li>The other obvious property is auto-scaling, which sometimes may be the best way to auto-scale, but it’s not always the best answer</li>
</ul>

<p>A no-brainer approach may yield a no-brainer result.</p>

<p>This isn’t to say if you completely ignore the storage, KEDA may or may not work well.</p>

<p>In most cases you can ignore storage, watch the application or compute resources and you’ll be fine, but in other cases not ignoring storage features may make KEDA work even better, or more efficiently.</p>

<p>Let’s consider potential opportunities for storage that I got by RTFM and which I may explored in a future post or future versions of this post if I make updates.</p>

<p>Each of these arrays is quite different:</p>

<ul>
  <li>SolidFire has storage QoS and works NetApp Trident (CSI driver)</li>
  <li>E-Series does not have storage QoS and works with several non-HA drivers</li>
</ul>

<h3 id="solidfire">SolidFire</h3>

<p>As a quick reminder, NetApp Astra Trident CSI can create storage classes which specify the minimum, maximum and burst IOPS (and consequently MB/s) for SolidFire volumes.</p>

<p>SolidFire-aware scaling may be interesting when our custom approach outperforms more generic metrics (Web server’s latency or NoSQL cluster’s CPU utilization).</p>

<p>When would that be and how can SolidFire-influence scalers help?</p>

<p><strong>Storage performance</strong>: if your application is IO-intensive, and especially if you constrain it with a narrowly-defined QoS specification, it may be better for KEDA to be driven by storage than application events because it’s more likely that the application may be hitting Maximum QoS limit on a sustained basis.</p>

<p>This can happen in the situation where the storage is generally low on unused IOPS, so the admin tries to use a low Minimum IO limit, and a low Maximum IO limit. KEDA can rely on one of SolidFire performance metrics (such as volume <em>performance</em> utilization, queue depth, etc) to allow you to use a low-performance storage class but at the same time avoid situations where you have to “re-type” volumes because you misjudged application requirements.</p>

<p><strong>Storage capacity</strong>: SolidFire thin-provisions by default (and there’s no way to thick-provision), but some users like to right-size volumes.</p>

<p>When you right-size, it can also be dangerous if storage utilization becomes unexpectedly higher. Trident lets you resize volumes, but it can’t shrink them.</p>

<p>Sometimes it’s better to resize, other times it’s better to over-provision, but there are also times and situations where people like to right-size and KEDA could read disk fullness off SolidFire and scale out accordingly. This is not always the best (because full volumes can continue getting even fuller), but it may be best in certain situations.</p>

<p><strong>Storage efficiency</strong>: sometimes you may have large volumes which you may not want to recklessly scale-out because you could run out of space, but this depends on data - if data is highly efficient (volume storage efficiency factor &gt; 6), we could let the application scale out more. This indicator could also be used as one of components in an aggregate metric. (See that earlier InfluxDB query with SolidFire volume efficiency.)</p>

<p><strong>Aggregate metric</strong>: SolidFire caps iSCSI clients’ IO queue at 32 per connection; while this is normally enough for most small and medium applications, it may be insufficient for larger databases and such.</p>

<p>One common “workaround” is to create multiple iSCSI connections from the initiator, but if your application can scale out (e.g. MongoDB, NGINX…) you may prefer to watch for both fullness and queue depth and if both are critical, scale-out.</p>

<p>Normally auto-scaling MongoDB should decrease disk fullness due to data rebalancing, but it may not always work the way you want (see [1]). In the case of NGINX, auto-scaling won’t decrease content size of NGINX sites, but it may slow down the rate of increase in PVC fullness because the same logs would be spread across more volumes (if you log to disk).</p>

<p>[1] “If the disk fills too quickly, Atlas might not be able to expand the cluster’s storage space in time, even if Auto-Expand Storage is enabled.” (Source: <a href="https://www.mongodb.com/docs/atlas/reference/alert-resolutions/disk-space-used/#common-triggers">MongoDB</a>)</p>

<p>SolidFire metrics can be easily obtained (one <a href="/2021/03/08/hcicollector-v0.7.html">example</a>) and inserted into one of KEDA scalers for querying. See my Github <a href="https://github.com/scaleoutsean/awesome-solidfire/">repo Awesome SolidFire</a> for more on monitoring and metrics options for SolidFire, or search this blog.</p>

<h3 id="e-series">E-Series</h3>

<p>E-Series works with BeeGFS CSI (in a BeeGFS cluster file system environment only) and single-host CSI drivers about which I blogged <a href="/2022/12/09/directpv-topolvm-csi-lvm-das-k8s-with-eseries.html">here</a>: DirectPV, TopoLVM, etc.</p>

<p>You can check the archive or use search to find more about BeeGFS CSI. BeeGFS is a scale-out filesystem that can span across multiple arrays; even a single (sufficiently large) file can be chunked across multiple LUNs and arrays.</p>

<p>So if you got that kind of an environment, it’s easy to scale it out on compute side while “ignoring” storage (as far as KEDA is concerned).</p>

<p>Here I’ll focus on the single-host CSI approach because that that’s the more challenging and less popular situation which is insufficiently appreciated.</p>

<p>As I mentioned in that related post, single-host CSI drivers can work with E-Series LUNs (physical volumes) that are protected or <strong>un</strong>protected (JBOD-style).</p>

<p>Some people think nobody needs JBOD-style PVs, but I disagree.</p>

<p>You get decent performance, no overhead and if your application scales out <em>and</em> replicates data, there’s no reason to not consider non-RAID-ed disks for some PVCs, and RAID-protected (1/10, 5, 6) LUNs for other.</p>

<p>For example, you may run Elasticsearch with DirectPV on XFS-formatted JBOD disks using Elasticsearch to make three copies (2-replica)  and at the same time have a big RAID 6 with 5 volumes used by MinIO (EC:1) for tiering to S3 in the same array.</p>

<p>All right, where does KEDA come in? My initial thoughts:</p>

<p><strong>Disk fullness</strong>: even if the performance is fine, if disk is over 70% full, we may want to scale out and provision additional volumes for the application. This can probably be done by the application, but it may be harder.</p>

<p><strong>Performance</strong>: we could use KEDA’s InfluxDB scaler which lets us specify a query that triggers scaling events; <a href="https://github.com/scaleoutsean/eseries-perf-analyzer">EPA</a> can collect these metrics for you, or you can gather them yourself: maybe it’s total array IOPS, maybe controller CPU utilization, maybe something else.</p>

<p>If your workload bottleneck is disk performance, this could work better than application metrics.</p>

<p><strong>Aggregate storage metric</strong>: use weighted value comprised of several metrics to trigger (or not) scaling up/down.</p>

<p>Combine latency and queue depth, for example, and if their sum goes over or under a certain limit, trigger up- or down-scaling. Or combine capacity, performance and application metrics into one value. This may result in a better decision than just a single value.</p>

<h2 id="storage-related-events">Storage-related events</h2>

<p>This applies to both SolidFire and E-Series: we may want to scale-out your horizontally scalable application as long as it can perform faster, with the objective to minimize run time (time to result). This can be risky (scaling out as much as you can) but sometimes that’s the first priority.</p>

<p>On SolidFire you could calculate “Minimum IOPS allocated”, and as long as that value is below the total of the cluster, you could scale out: after all, it doesn’t cost you anything.</p>

<p>Let’s say your cluster guarantees 200,000 IOPS and there’s just one important workload (CI/CD build farm, for example). We could sum up all volumes’ Minimum IO value (MIN_IO_TOTAL) and if MIN_IO_TOTAL &gt; (200,000 x 80%), signal 0 (don’t scale out), or else 1 (auto scale-out).</p>

<p>On E-Series we could look at the controllers’ CPU utilization. If &lt; 80%, auto-scale out, if &gt; 80%, do nothing (in which case we’d drop to <code class="language-plaintext highlighter-rouge">minReplicaCount</code>, perhaps).</p>

<p>Another possibility is to look at storage throughput, especially with E-Series which often has just one-two applications per array. If the array performs faster than a single server then we can benefit from scaling that workload out, but also to 0 when there’s nothing to do so that other application(s) can consume storage performance.</p>

<p>We could even use storage indicators on filesystem level: determine how much data there is, and based on that configure KEDA’s auto-scaling before you run a parallel batch job, for example. For this we may need BeeGFS (and BeeGFS CSI), but if data is replicated to multiple volumes even single-host filesystem could benefit from this approach.</p>

<h3 id="storage-logs">Storage logs</h3>

<p>I have this as a separate category of storage-related events because of two reasons:</p>

<ul>
  <li>Storage array logs are usually gathered differently (for example, by forwarding them to a syslog server and pre-processing before it can be used)</li>
  <li>It’s not just numbers that can be massaged to produce desired outcomes, but text (error messages) and event IDs, that we’d have to use</li>
</ul>

<p>So this is more challenging, but can let us create unique events.</p>

<p>For example, we could auto-scale application down to minimum if a volume group is rebuilding, if one E-Series controller is down, or if SolidFire node count is below certain limit (i.e. a storage node went down).</p>

<p>I wouldn’t go too crazy on this approach as it can create unpredictable consequences, but advanced users may find it useful.</p>

<p>If your application will time-out or jobs fail, it may be better to automatically reduce the number of jobs than fail due to I/O timeouts, or cause timeouts on a whole bunch of more important applications using the same array.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Based on what I’ve seen in the documentation I came up with some scenarios that seem feasible.</p>

<p>Kubernetes is complicated enough so I wouldn’t encourage you to unnecessarily complicate your environment and introduce unpredictability to storage and/or application behavior, but I believe that KEDA can sometimes take advantage of disk array characteristics.</p>

<p>Again, I haven’t actually tried any of these scenarios, but maybe I will. I would also encourage you to come up with your own scenarios and evaluate them on your own.</p>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#storage">storage</a>
      &nbsp; 
    
      <a href="
      /categories/#kubernetes">kubernetes</a>
      &nbsp; 
    
      <a href="
      /categories/#automation">automation</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2024/04/11/netapp-eseries-containerized-beegfs-nfs-s3-all-in-one.html">NetApp E-Series with containerized BeeGFS, NFS, S3</a></li>
      
        <li><a href="/2023/09/01/kubernetes-solidfire-block-volumemode.html">Block volume mode in Kubernetes with SolidFire</a></li>
      
        <li><a href="/2023/04/15/cloudcasa-netapp-trident-solidfire.html">CloudCasa, Velero, NetApp Trident, and SolidFire</a></li>
      
        <li><a href="/2021/07/31/netapp-trident-v21.07.html">GA of NetApp Trident v21.07</a></li>
      
        <li><a href="/2023/09/08/beegfs-csi-driver-lives-on.html">ThinkParQ takes over NetApp-created BeeGFS CSI driver</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2025-05-18 06:22 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
