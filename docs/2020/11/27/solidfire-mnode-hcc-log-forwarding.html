<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            SolidFire mNode and HCC Log Fowarding | Acting Technologist
      
    </title>
    <meta name="description" content="
     syslog forwarding for SolidFire mNode and Hybrid Cloud Control
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>SolidFire mNode and HCC Log Fowarding | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="SolidFire mNode and HCC Log Fowarding" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="syslog forwarding for SolidFire mNode and Hybrid Cloud Control" />
<meta property="og:description" content="syslog forwarding for SolidFire mNode and Hybrid Cloud Control" />
<link rel="canonical" href="https://scaleoutsean.github.io/2020/11/27/solidfire-mnode-hcc-log-forwarding.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2020/11/27/solidfire-mnode-hcc-log-forwarding.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-27T00:00:00+08:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2020/11/27/solidfire-mnode-hcc-log-forwarding.html"},"author":{"@type":"Person","name":"scaleoutSean"},"description":"syslog forwarding for SolidFire mNode and Hybrid Cloud Control","@type":"BlogPosting","url":"https://scaleoutsean.github.io/2020/11/27/solidfire-mnode-hcc-log-forwarding.html","headline":"SolidFire mNode and HCC Log Fowarding","dateModified":"2020-11-27T00:00:00+08:00","datePublished":"2020-11-27T00:00:00+08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">SolidFire mNode and HCC Log Fowarding</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>27 Nov 2020</span> - <i class="far fa-clock"></i> 


  
  
    11 minute read
  

    </span>
  </div>
  
        <p>SolidFire Management Node (aka mNode) is a VM that runs Hybrid Cloud Services (various “management stuff”.) Let’s say we wanted to collect and analyze those logs.</p>

<p>How could we get the logs out the smart way?</p>

<p>Before we begin, we need to know what we’re dealing with. As of today, we have two groups of logs on mNode:</p>

<ul>
  <li>mNode system logs (the usual Linux stuff)</li>
  <li>HCC service logs (JBOC, just a bunch of containers)</li>
</ul>

<p>There are no local users so presumably everything that’s worthy of our attention is in system and HCC log(s).</p>

<p>Key software components:</p>

<ul>
  <li>NetApp SolidFire Management Node (mNode) v12.2
    <ul>
      <li>Docker v18.09.8</li>
      <li>rsyslogd 8.1904.0</li>
    </ul>
  </li>
  <li>NetApp Hybrid Cloud Control (HCC) v2.16.66</li>
</ul>

<h3 id="mnode">mNode</h3>

<p>Backup your /etc/rsyslog.conf and hack away! I added these three rows for my $DST server reachable at $DST_PORT (<code class="language-plaintext highlighter-rouge">$DST:$DST_PORT</code> such as 2.2.2.2:2514):</p>

<pre><code class="language-raw">*.* action(type="omfwd" target="$DST" port="$DST_PORT" protocol="tcp"
            action.resumeRetryCount="100"
            queue.type="linkedList" queue.size="10000")
</code></pre>

<p>There are fancy features in this module. You can compress the log, set a re-try interval (for the 100 tries mentioned above; see <code class="language-plaintext highlighter-rouge">ActionSendTCPRebindInterval</code> in the rsyslog documentation), or even use a specific network <code class="language-plaintext highlighter-rouge">device</code> (which may be useful if you have multiple NICs as users who use mNode with Persistent Volumes do, or want to use a secure network to forward your logs) and so on. RTFM!</p>

<p>With this set up, we can now monitor OS-level events:</p>

<pre><code class="language-raw">Nov 27 10:30:21 192.168.1.31 sshd[19710]: Postponed keyboard-interactive for admin from 192.168.1.12 port 58430 ssh2 [preauth]
Nov 27 10:30:23 192.168.1.31 sshd[19710]: Postponed keyboard-interactive/pam for admin from 192.168.1.12 port 58430 ssh2 [preauth]
Nov 27 10:30:23 192.168.1.31 sshd[19710]: Accepted keyboard-interactive/pam for admin from 192.168.1.12 port 58430 ssh2
</code></pre>

<p>I should note that there are all sorts of logs under /var/log, some of which are likely not captured by syslog, so additional modifications to rsyslog.conf would be required if we wanted to capture those logs.</p>

<h3 id="hcc">HCC</h3>

<p>This one seems easy. Backup <code class="language-plaintext highlighter-rouge">/etc/docker/daemon.json</code> and hack away, right? Wrong!</p>

<p>With log-related additions to daemon.json we can send Docker logs to <code class="language-plaintext highlighter-rouge">$DST:$DST_PORT</code>, also using TCP like we did with rsyslog.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"bip"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"169.254.100.1/22"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"log-driver"</span><span class="p">:</span><span class="w"> </span><span class="s2">"syslog"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"log-opts"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"syslog-address"</span><span class="p">:</span><span class="w"> </span><span class="s2">"tcp://$DST:$DST_PORT"</span><span class="p">,</span><span class="w">
           </span><span class="nl">"tag"</span><span class="p">:</span><span class="w"> </span><span class="s2">"solidfire"</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">bip</code> thing was there before - I only added the log-related entries.</p>

<p>The tag key may be useful for classification and grouping at the destination. I should probably have done something similar for the rsyslog above. With that tag Docker logs (below tagged with <code class="language-plaintext highlighter-rouge">hcc</code>) are easier to tell apart from mNode (OS) logs (<code class="language-plaintext highlighter-rouge">systemd</code>), although we could also use syslog at the destination to save each source to a different file:</p>

<pre><code class="language-raw">Nov 27 10:28:27 192.168.1.31 systemd[1]: Stopping Deploy Element Auth service...
Nov 27 10:28:27 192.168.1.31 systemd[1]: Stopping Login Service...
Nov 27 10:28:27 192.168.1.31 hcc[20264]: killing the spooler with pid 6
</code></pre>

<p>Once we’re done with changes to rsyslog.conf and Docker’s daemon.json, we can reboot mNode.</p>

<h3 id="wait-what-do-you-mean-reboot">Wait, what do you mean “reboot”</h3>

<p>Yep, I just rebooted mNode to see if my settings worked. What if we wanted to reload rather than reboot? Feel free to JFGI (I’m not too curious how to do that on Docker v18.09.8!)</p>

<p>At the destination syslog server, tail the forwarded log(s) to see a combined log from mNode’s rsyslog and Docker:</p>

<pre><code class="language-raw">Nov 27 08:16:01 192.168.1.31 CROND[30647]: (root) CMD (cd / &amp;&amp; /usr/bin/flock -x /var/lib/sftracing/lock -c 'logrotate --state=/var/lib/sftracing/status /var/lib/sftracing/logrotate.conf' &gt;/dev/null)
Nov 27 08:16:51 192.168.1.31 dockerd[20264]: time="2020-11-27T08:16:51.520518736Z" level=info msg="NetworkDB stats mnode(2e34102d1390) - netID:jsgguqh5mxhgjxxf1qkvlvs0t leaving:false netPeers:1 entries:43 Queue qLen:0 netMsg/s:0"
Nov 27 08:16:51 192.168.1.31 dockerd[20264]: time="2020-11-27T08:16:51.520610196Z" level=info msg="NetworkDB stats mnode(2e34102d1390) - netID:moxqzm0ca0yon5wgri3yyty94 leaving:false netPeers:1 entries:3 Queue qLen:0 netMsg/s:0"
Nov 27 08:16:51 192.168.1.31 dockerd[20264]: time="2020-11-27T08:16:51.520624912Z" level=info msg="NetworkDB stats mnode(2e34102d1390) - netID:lp5fpj7cqik3pqsqsg7o56xsi leaving:false netPeers:1 entries:8 Queue qLen:0 netMsg/s:0"
Nov 27 08:17:01 192.168.1.31 CROND[30752]: (root) CMD (cd / &amp;&amp; /usr/bin/flock -x /var/lib/sftracing/lock -c 'logrotate --state=/var/lib/sftracing/status /var/lib/sftracing/logrotate.conf' &gt;/dev/null)
Nov 27 08:17:06 192.168.1.31 lldpd[21648]: unable to bind to raw socket for interface veth20d4528: No such device
Nov 27 08:17:06 192.168.1.31 lldpd[21651]: unable to initialize veth20d4528
</code></pre>

<p>System and Docker service log are there, but wait - those docker logs seem very sparse, what’s up with that?</p>

<h4 id="logs-of-individual-containers">Logs of Individual Containers</h4>

<p>We need to do something about the container logs. What only 30 minutes ago seemed like a trivial exercise is becoming a way to waste an entire evening…</p>

<p>Container logs go to <code class="language-plaintext highlighter-rouge">/var/lib/docker/containers/${Id}/${Id}-json.log</code> (where ID is the container ID) as expected. These IDs change after each restart (for example, in the case of container image <code class="language-plaintext highlighter-rouge">logs-svc</code> , we’d get a different ID every time the OS or container are restarted.)</p>

<p>For now the important part is that the information we need is there:</p>

<pre><code class="language-raw">{"log":"[pid: 9|app: 0|req: 972/1678] 10.0.0.40 () {32 vars in 1303 bytes} [Fri Nov 27 08:33:13 2020] GET /1/assets/storage-clusters/5a6502a3-8bcb-4617-8cce-64127996545c =\u003e generated 735 bytes in 6 msecs (HTTP/1.1 200) 5 headers in 154 bytes (1 switches on core 0)\n","stream":"stderr","time":"2020-11-27T08:33:13.665314987Z"}
{"log":"[pid: 9|app: 0|req: 973/1679] 10.0.0.40 () {32 vars in 1303 bytes} [Fri Nov 27 08:33:23 2020] GET /1/assets/storage-clusters/5a6502a3-8bcb-4617-8cce-64127996545c =\u003e generated 735 bytes in 6 msecs (HTTP/1.1 200) 5 headers in 154 bytes (1 switches on core 0)\n","stream":"stderr","time":"2020-11-27T08:33:23.670857855Z"}
</code></pre>

<p>Next we need to figure out why that stuff isn’t being forwarded out. The problem is we may not be able to do much with that information: we can’t change HCC’s container startup parameters (not in a supported way anyway).</p>

<p>We don’t have to be worried about that scenario because we can always get to the container logs via the <a href="https://docs.netapp.com/us-en/hci/docs/task_hcc_collectlogs.html#use-the-rest-api-to-collect-logs">HCC API</a> which lets us poll the HCC API endpoint and those logs every $N seconds (or get last $M lines from particular container log). That functionality reflects the logs command of Docker:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>docker logs c43bcd1f0431 <span class="nt">--since</span> 2020-11-26
</code></pre></div></div>

<p>While we can poll the API for container logs this way, a better approach would be to run an agent that scans /var/lib/docker/containers/ and takes care of everything.</p>

<p>But <em>why</em> are the logs not sent together with Docker logs? The answer is under <code class="language-plaintext highlighter-rouge">/etc/rsyslog.d</code> - in the file named <code class="language-plaintext highlighter-rouge">30-docker.conf</code>, to be precise:</p>

<pre><code class="language-raw">:syslogtag, startswith, "docker" /var/log/docker.info
&amp; stop
</code></pre>

<p>We’d have to hack that file or come up with another file (<code class="language-plaintext highlighter-rouge">40-hcc.conf</code>, for example) where we’d ask rsyslog to find our logs in <code class="language-plaintext highlighter-rouge">/var/lib/docker/containers/*/*-json.log</code>. But - alas! - this version of rsyslog doesn’t do directory name wildcards so that’s out of the question as well.</p>

<p>We could write a new fancy rsyslog rule and dynamically reload rsyslog.conf, but that wouldn’t be pain-free either because interesting HCC container logs are all owned by <code class="language-plaintext highlighter-rouge">root:root</code> which wouldn’t work for rsyslog.conf (another can of worms.)</p>

<p>Time to take another look at that HCC API method…</p>

<h4 id="hcc-get-logs">HCC <code class="language-plaintext highlighter-rouge">GET /logs</code></h4>

<p>HCC logs seem to be rotated very slowly (weeks) so it appears quite safe to fetch them every X minutes or hours. We can use the <code class="language-plaintext highlighter-rouge">since</code> parameter to dynamically get log entries created in last X minutes or hours, and avoid fetching the logs of stopped containers named <code class="language-plaintext highlighter-rouge">logs-svc</code> (we only want the logs of a running <code class="language-plaintext highlighter-rouge">logs-svc</code> container).</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-X</span> GET <span class="s2">"https://</span><span class="k">${</span><span class="nv">mNode</span><span class="p">-IP</span><span class="k">}</span><span class="s2">/mnode/logs?since=2020-11-26T06%3A00%3A00Z&amp;service-name=logs-svc&amp;stopped=false ...
</span></code></pre></div></div>

<p>That would query mNode for the log of a running <code class="language-plaintext highlighter-rouge">logs-svc</code> container and return something like this:</p>

<pre><code class="language-raw">Response body
Download
=========================================================
    mnode_logs-svc.1.nxk8szxmjuuiyo30frxdltcel
=========================================================
[uWSGI] getting INI configuration from uwsgi_app.ini
*** Starting uWSGI 2.0.19.1 (64bit) on [Fri Nov 27 10:57:26 2020] ***
compiled with version: 9.3.0 on 08 October 2020 02:01:58
os: Linux-4.19.37-solidfire7 #1 SMP Wed Jun 24 20:10:57 UTC 2020
nodename: 42d366150c41
machine: x86_64
clock source: unix
detected number of CPU cores: 6
current working directory: /app
detected binary path: /usr/local/bin/uwsgi
</code></pre>

<p>This particular log isn’t structured, but some other services that deal with API calls have structured logs.</p>

<p>Another detail we should consider is if we want to get logs from particular service, or “all”. We should definitively gather logs one by one. If we look at all <code class="language-plaintext highlighter-rouge">Up</code> containers in the output of <code class="language-plaintext highlighter-rouge">docker ps -a</code>, our initial list may look like this:</p>

<pre><code class="language-raw">node-api-gateway
hcc-ui
credential-svc
vcp-sioc
mongo
redis
logs-svc
hci-monitor
mnode-api
mnode-svc-mon-grafana
package-svc
hardware-svc
vcenter-svc
telemetry-service
storage-service
mnode-svc-authz
inventory-service
mnode-svc-mon-prometheus
docker-proxy
mnode-svc-task-monitor
k8sdeployer
mnode-svc-aiq-collector
</code></pre>

<p>We could now look at the mNode and HCC documentation and decide which logs we’re not interested in. For example we may take a look at the logs of <code class="language-plaintext highlighter-rouge">mnode-svc-mon-prometheus</code> and decide we don’t want those.</p>

<p>With that information we should be able to prune the list to a more manageable length and create a script that loops through a list of container services and every N minutes fetches last (N+1) minutes of service logs.</p>

<h3 id="fowarding-to-multiple-destinations">Fowarding to Multiple Destinations</h3>

<p>For rsyslog I would assume one can simply repeat an rsyslog <code class="language-plaintext highlighter-rouge">action</code> twice.</p>

<p>For Docker, depending on the version and configuration, <code class="language-plaintext highlighter-rouge">docker logs</code> may <a href="https://docs.docker.com/config/containers/logging/dual-logging/">or may not</a> work the way you expect - and that also depends upon your expectations.)</p>

<p>As you can see at that page, Docker <em>cannot</em> log to multiple destinations. Oops! It also can’t retry like rsyslog can. So it appears for some folks it may be better to log to <code class="language-plaintext highlighter-rouge">local</code> and have a 3rd party agent (or just rsyslog) gather those logs and send them to multiple destinations.</p>

<h3 id="what-about-solidfire-storage-cluster-logs">What about SolidFire storage cluster logs</h3>

<p>Short version: you can set one or more syslog destinations with a simple CLI or API call to MVIP.</p>

<p>See my repo Awesome SolidFire and SolidFire logging-related videos on YouTube.</p>

<h2 id="conclusion">Conclusion</h2>

<p>mNode system and Docker service logs can be forwarded with ease, but at this time logs of individual containers should be gathered by using the HCC API.</p>

<p>While that is not very inconvenient, we should also investigate 3rd party log forwarding tools that could be deployed inside of mNode VM and eliminate the need to use the API.</p>

<p>If you make any changes on your production system, don’t work by these blog posts. Consult the documentation, read the KB articles and check with Support.</p>

<h3 id="follow-up-20201205">Follow-up (2020/12/05)</h3>

<p>As mentioned earlier, it’s not supported to add your own containers to mNode VM. Why? It doesn’t matter, what matters is it’s not supported. It likely has to do with VM capacity and resources, as well as unpredictable interactions with existing container and non-container workloads. But whatever it is, the point is there’s no need to create a how-to because the right how-to is “don’t do it” so I’ll just add some notes on how I made it work in a non-supported manner.</p>

<h4 id="input">Input</h4>

<p>Filebeat documentation for Docker isn’t great, but (h/t: logz.io) I used <code class="language-plaintext highlighter-rouge">prima/filebeat</code> and didn’t want to spend much time on making it look and work nice. My inputs were all Docker logs:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">filebeat.prospectors</span><span class="pi">:</span>
 <span class="pi">-</span> <span class="na">input_type</span><span class="pi">:</span> <span class="s">log</span>
  <span class="na">paths</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">/var/lib/docker/containers/*/*-json.log</span>
  <span class="s">...</span>
</code></pre></div></div>

<p>The above, once it starts churning through logs, can eat up 2 CPU cores <em>easily</em>. Similarly for RAM and disk space. In other words, if you don’t increase mNode VM resources or restrict this container’s resources, it can easily take down your mNode or individual HCC services.</p>

<p>What if you want to collect just some, rather than all, logs? The list of containers is in this post and what they do is in the documentation. Create multiple filebeat containers or create multiple definitions (YAML format), one per each individual container, and load them like so:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">filebeat.config.inputs</span><span class="pi">:</span>
  <span class="na">enabled</span><span class="pi">:</span> <span class="kc">true</span>
  <span class="na">path</span><span class="pi">:</span> <span class="s">hcc.d/*.yml</span>
</code></pre></div></div>

<p>You’d probably have to read <a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-configuration-reloading.html">the docs</a> to use this approach.</p>

<p>After a bit of googling and RTFM I also managed to capture individual container logs (hcc-ui, in this example) with this:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">filebeat.autodiscover</span><span class="pi">:</span>
  <span class="na">providers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">docker</span>
      <span class="na">templates</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">condition</span><span class="pi">:</span>
            <span class="na">contains</span><span class="pi">:</span>
              <span class="na">docker.container.image</span><span class="pi">:</span> <span class="s">hcc-ui</span>
          <span class="na">config</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">container</span>
              <span class="na">paths</span><span class="pi">:</span>
                <span class="pi">-</span> <span class="s">/var/lib/docker/containers/${data.docker.container.id}/*.log</span>
              <span class="na">exclude_lines</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">^</span><span class="se">\\</span><span class="s">s+[</span><span class="se">\\</span><span class="s">-`('.|_]"</span><span class="pi">]</span>
</code></pre></div></div>

<h4 id="output">Output</h4>

<p>Filebeat can send container logs to external recepients.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">output.elasticsearch</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">192.168.1.146:9200"</span><span class="pi">]</span>
</code></pre></div></div>

<p>If you want to send it to two destinations, run two filebeat containers with identical configuration.</p>

<p>Or, if you wanted to store logs locally, you could add this directory to rsyslog configuration and leave the forwarding to multiple destinations to rsyslog:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">output.file</span><span class="pi">:</span>
  <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/var/logs/docker/filebeat/"</span>
  <span class="na">filename</span><span class="pi">:</span> <span class="s">filebeat</span>
  <span class="na">rotate_every_kb</span><span class="pi">:</span> <span class="m">1000</span>
  <span class="na">number_of_files</span><span class="pi">:</span> <span class="m">7</span>
  <span class="na">permissions</span><span class="pi">:</span> <span class="m">0644</span>
</code></pre></div></div>

<p>In this example retain only 7 x 1 MiB files. That’s probably not what you want to do. Likewise, although you’re not supposed to have any local users on mNode, you’d probably want those permissions tighter (0640, for example).</p>

<h4 id="result">Result</h4>

<p>You’ll get some extra junk you may not want, but Filebeat has options and processors that let you strip that, and so does rsyslog. By the looks of it (see the values like <code class="language-plaintext highlighter-rouge">jit</code> in this JSON file) you may want to ensure that logs are either stripped of confidential info at the source, or sent to destination over encrypted connection.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
	</span><span class="nl">"@timestamp"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2020-12-04T17:06:02.511Z"</span><span class="p">,</span><span class="w">
	</span><span class="nl">"@metadata"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
		</span><span class="nl">"beat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"filebeat"</span><span class="p">,</span><span class="w">
		</span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"doc"</span><span class="p">,</span><span class="w">
		</span><span class="nl">"version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"6.2.3"</span><span class="w">
	</span><span class="p">},</span><span class="w">
	</span><span class="nl">"source"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/var/lib/docker/containers/f14f10d6aefccf3be511c259a79e1cdae46f6f1da24479704392e3852cd45aa8/f14f10d6aefccf3be511c259a79e1cdae46f6f1da24479704392e3852cd45aa8-json.log"</span><span class="p">,</span><span class="w">
	</span><span class="nl">"offset"</span><span class="p">:</span><span class="w"> </span><span class="mi">73282162</span><span class="p">,</span><span class="w">
	</span><span class="nl">"log"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2020-11-28T23:49:25.683922Z |     6 | 132721654 |    MainProcess-uWSGIWorker1Core0  |         flask_authtools:117  | DEBUG   | Authenticated user with claims: {'nbf': 1606607365, 'exp': 1606607485, 'iss': 'https://192.168.1.30/auth', 'aud': ['mnode_api', 'mnode_credential'], 'client_id': 'hci-monitor', 'iat': 1606607365, 'jti': 'YECZS3fkjxfpPx38gofKlg', 'scope': ['mnode_api:r', 'mnode_credential:r']}</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span><span class="w">
	</span><span class="nl">"stream"</span><span class="p">:</span><span class="w"> </span><span class="s2">"stderr"</span><span class="p">,</span><span class="w">
	</span><span class="nl">"time"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2020-11-28T23:49:25.684342722Z"</span><span class="p">,</span><span class="w">
	</span><span class="nl">"beat"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
		</span><span class="nl">"hostname"</span><span class="p">:</span><span class="w"> </span><span class="s2">"59e98457dadf"</span><span class="p">,</span><span class="w">
		</span><span class="nl">"version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"6.2.3"</span><span class="p">,</span><span class="w">
		</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"59e98457dadf"</span><span class="w">
	</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#solidfire">solidfire</a>
      &nbsp; 
    
      <a href="
      /categories/#automation">automation</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2022/03/06/elastic-elk-stack-on-netapp.html">Elasticsearch 8 with NetApp storage</a></li>
      
        <li><a href="/2022/03/11/solidfire-mnode-active-iq-connectivity.html">Check Active IQ connectivity from HCC on SolidFire mNode</a></li>
      
        <li><a href="/2021/12/21/netapp-solidfire-hci-hcc-powershell.html">Using NetApp SolidFire Hybrid Cloud Control (HCC) API from PowerShell</a></li>
      
        <li><a href="/2021/05/06/using-solidfire-maintenancemode.html">SolidFire Maintenance Mode</a></li>
      
        <li><a href="/2020/12/08/get-bearer-token-for-netapp-hci-hybrid-cloud-control-logs.html">Get NetApp Hybrid Cloud Control logs via the HCC API</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2025-05-18 04:16 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
