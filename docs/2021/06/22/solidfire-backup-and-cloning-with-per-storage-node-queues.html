<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Maximum parallelization of SolidFire Backup and Volume Copy/Clone jobs | Acting Technologist
      
    </title>
    <meta name="description" content="
     Safely maximize the number of backup and copy jobs on your SolidFire cluster
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Maximum parallelization of SolidFire Backup and Volume Copy/Clone jobs | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Maximum parallelization of SolidFire Backup and Volume Copy/Clone jobs" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Safely maximize the number of backup and copy jobs on your SolidFire cluster" />
<meta property="og:description" content="Safely maximize the number of backup and copy jobs on your SolidFire cluster" />
<link rel="canonical" href="https://scaleoutsean.github.io/2021/06/22/solidfire-backup-and-cloning-with-per-storage-node-queues.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2021/06/22/solidfire-backup-and-cloning-with-per-storage-node-queues.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-22T00:00:00+08:00" />
<script type="application/ld+json">
{"headline":"Maximum parallelization of SolidFire Backup and Volume Copy/Clone jobs","dateModified":"2021-06-22T00:00:00+08:00","datePublished":"2021-06-22T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2021/06/22/solidfire-backup-and-cloning-with-per-storage-node-queues.html"},"author":{"@type":"Person","name":"scaleoutSean"},"@type":"BlogPosting","url":"https://scaleoutsean.github.io/2021/06/22/solidfire-backup-and-cloning-with-per-storage-node-queues.html","description":"Safely maximize the number of backup and copy jobs on your SolidFire cluster","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Maximum parallelization of SolidFire Backup and Volume Copy/Clone jobs</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>22 Jun 2021</span> - <i class="far fa-clock"></i> 


  
  
    5 minute read
  

    </span>
  </div>
  
        <p>SolidFire can backup volumes to S3-compatible Object Storage. How to do it in parallel, I wrote about <a href="/2021/04/21/solidfire-backup-to-s3.html">here</a>.</p>

<p>Volume cloning and copying is a similar type of background job, and those can also be executed in parallel. We get to use this in automation, for example when you need to clone a volume 100 times, or perhaps start with three “template” volumes (Windows, Ubuntu, Red Hat) and make 32 copies of each. I use volume copying in <a href="/2021/05/08/revisiting-solidbackup.html">SolidBackup</a> scripts.</p>

<p>What’s common to both is there’s the maximum number of jobs that can be scheduled on a SolidFire storage node at the same time (you can find the limits in the SolidFire Release Notes or with the API (with PowerShell, they get displayed immediately after you connect to the cluster).</p>

<p>If that number is 8, if there’s 8 jobs running and you attempt to schedule another job that lands on that node, that job will immediately fail. It’s not a big deal - jobs can be resubmitted - but you unnecessarily consume API resources, pollute your SolidFire logs, have to handle job failures in your scripts, and still prevent anyone else from submitting their jobs while you occupy all the job slots available.</p>

<p>As we saw in the linked posts, we can deal with this by parallelizing job submission to a “safe” per-cluster level (say, 16 jobs on a 4-node cluster) that makes it unlikely that we’d hit “node queue full” errors and have to retry if any single node hits the job limit.</p>

<p>A script that does that for Backup can be found in my Awesome SolidFire repo on Github.</p>

<h2 id="maximizing-volume-backup-and-clone-jobs-per-node">Maximizing volume backup and clone jobs-per-node</h2>

<p>An even better way would be to queue up to desired number of jobs per node, so that we can say “dispatch up to 7 jobs per node” so that we run the node at a high utilization, but still have one empty slot available for on-demand activities.</p>

<p>Trouble is, there’s no API method to help you do that. Or even to easily find out where the jobs are running in the first place. Indirectly that is possible, but it’s also quite complicated. I tried the indirect way and realized it would have taken me weeks of tinkering, with the poor scripting skills I have.</p>

<p>In the end I had to find a shortcut which came in the form of a non-public API method, <code class="language-plaintext highlighter-rouge">GetReport</code>, which lets us indirectly obtain a volume’s location and tell us which SolidFire storage node hosts it.</p>

<p>This (being a non-public API method) can change in the next release, it may stop working etc., and it seems resource-intensive, so I run it just once, at the very beginning. If I had many jobs that run around the clock, I would run it every 60 minutes to get updates in the case SolidFire rebalances volumes. (A smarter way would be to watch the event log and only run it if/when such a rebalancing happens.)</p>

<p>Note that there are two separate limits - they happen to be 8 per node, but the way to query them is different - for bulk (backup) and volume (clone, copy) jobs. But that’s just an implementation detail.</p>

<p>So far I’ve used <code class="language-plaintext highlighter-rouge">GetReports</code> to improve SolidFire Backup to S3 which, as explained above, has a “concurrent backup jobs per cluster” setting. I may add this approach to SolidSync (from SolidBackup) later, to apply it to volume copy jobs as well.</p>

<h2 id="findings">Findings</h2>

<p>So, is this approach much better?</p>

<p>Well, it’s not that different. I kick off a bunch of jobs and instead of watching a “global” maximum, now I watch each node’s queue and schedule new jobs only when there are jobs for that node, and if the node’s queue is less full than the per-node limit I set in the script (e.g., 7).</p>

<p><img src="/assets/images/solidfire-backup-to-s3-v2-parallel-per-node.png" alt="Parallel SolidFire Backup to S3 with per-node queues" /></p>

<p>Whereas I used to run 20 parallel backup jobs on a 5 node cluster (that level seemed “safe”), here I can safely and easily hit 35 (5 nodes x 7 jobs per node) when I have enough volumes to fill all the nodes’ queues.</p>

<p>SolidFire schedules volume placement based on a number of factors (not just “volumes per storage node”), so in the screenshot above you can see that despite a fairly large number of volumes (50-ish), I could not fill all the queues - at most I got 32 backup jobs running in parallel.</p>

<p>Once no jobs are left in the script’s queue, it scans SolidFire Events for bulk job (i.e., backup) events and outputs a simple report. Because backup jobs can run for hours, it doesn’t attempt to wait it out - users are advised to watch SolidFire Events from Elastic, Splunk, etc.</p>

<p><img src="/assets/images/solidfire-backup-to-s3-v2-parallel-per-node-summary.png" alt="Parallel SolidFire Backup to S3 with per-node queues" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>32 vs. 20 jobs is still a nice improvement which eliminates the risk of failed jobs and still leaves a free slot per each storage node for on-demand backup and restore jobs. If you know your environment you can set parallelism to 8-per-node and run up to 40 jobs in parallel (5 nodes x 8 jobs), effectively doubling the number of jobs compared to the earlier approach.</p>

<p>If you also incorporate QoS pre-post adjustments for each volume before and after backup to S3 (I wrote a script for that, too), you should be able to read SolidFire at &gt; 1GB/s. Unfortunately, the upload performance of Backup to S3 is slow, but we can’t optimize that with a script (I think SolidBackup should be used by those who wish to improve that).</p>

<p>Backup jobs take longer to run, but clone jobs run faster and cutting a 10 minute mass cloning job down to less than 6 minutes would be nice, especially if your build job (or whatever you do after that) takes 15-20 minutes to complete - you could run up to 20% more build jobs per day.</p>

<h2 id="demo">Demo</h2>

<p>I demonstrated how Backup to S3 works in previous posts on this topic, so this one is very short and focuses on the difference in this approach vs the earlier parallel-jobs-per-cluster approach.</p>

<ul>
  <li><a href="https://youtu.be/5N62hhDrOO0">Parallel SolidFire Backup-to-S3 with per-node job queues</a> (1m40s)</li>
</ul>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#automation">automation</a>
      &nbsp; 
    
      <a href="
      /categories/#solidfire">solidfire</a>
       
    
  </span>
</div>
    

    
      <div class="related" data-pagefind-ignore>

    <h4>Possibly related - use live search at the top to find other content</h4>
    
    
    
    
    
    
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/26/swagger-files-netapp-eseries-arrays.html">• Swagger files for NetApp E-Series</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/09/solidbackup-velero-backup-non-k8s-volumes-netapp-solidfire-to-s3.html">• Backup NetApp SolidFire's non-Kubernetes volumes with Velero</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/01/windows-server-2025-with-solidfire-part-two-sql-server-2022.html">• Windows Server 2025 with NetApp SolidFire 12 iSCSI Part Two</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/04/01/windows-server-2025-with-solidfire-part-three-hyper-v.html">• Windows Server 2025 with NetApp SolidFire 12 iSCSI Part Three</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/03/31/windows-server-2025-with-solidfire-part-one.html">• Windows Server 2025 with NetApp SolidFire 12 iSCSI</a></h5>
          </div>
          
          
            
    
    </div>

    

    
  </div><footer class= "footer">
    <p>2024-04-26 12:47 </p>
    <p>Copyright © 2024 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
