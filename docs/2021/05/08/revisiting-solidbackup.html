<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            SolidBackup for data protection and workload mobility for SolidFire in Hybrid Cloud environments | Acting Technologist
      
    </title>
    <meta name="description" content="
     Revisiting the idea of SolidBackup for fun and non-profit
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>SolidBackup for data protection and workload mobility for SolidFire in Hybrid Cloud environments | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="SolidBackup for data protection and workload mobility for SolidFire in Hybrid Cloud environments" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Revisiting the idea of SolidBackup for fun and non-profit" />
<meta property="og:description" content="Revisiting the idea of SolidBackup for fun and non-profit" />
<link rel="canonical" href="https://scaleoutsean.github.io/2021/05/08/revisiting-solidbackup.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2021/05/08/revisiting-solidbackup.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-08T00:00:00+08:00" />
<script type="application/ld+json">
{"headline":"SolidBackup for data protection and workload mobility for SolidFire in Hybrid Cloud environments","dateModified":"2021-05-08T00:00:00+08:00","datePublished":"2021-05-08T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2021/05/08/revisiting-solidbackup.html"},"author":{"@type":"Person","name":"scaleoutSean"},"@type":"BlogPosting","url":"https://scaleoutsean.github.io/2021/05/08/revisiting-solidbackup.html","description":"Revisiting the idea of SolidBackup for fun and non-profit","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">SolidBackup for data protection and workload mobility for SolidFire in Hybrid Cloud environments</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>08 May 2021</span> - <i class="far fa-clock"></i> 


  
  
    23 minute read
  

    </span>
  </div>
  
        <p><strong>NOTICE</strong>: any and all credentials and tokens on this page are samples, not leaked.</p>

<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#first-attempt">First attempt</a>
    <ul>
      <li><a href="#backup-and-restore-in-kvm-environments">Backup and Restore in KVM environments</a></li>
      <li><a href="#data-migration">Data Migration</a></li>
      <li><a href="#do-we-really-want-diy-approaches-to-protect-our-data">Do we really want DIY approaches to protect our data</a></li>
    </ul>
  </li>
  <li><a href="#second-attempt">Second attempt</a>
    <ul>
      <li><a href="#create-configuration-and-keep-src--dst-clone-volumes-in-sync">Create configuration and keep Src &amp; Dst (Clone) volumes in sync</a></li>
      <li><a href="#backup-to-s3">Backup to S3</a></li>
      <li><a href="#restore-from-s3">Restore from S3</a></li>
    </ul>
  </li>
  <li><a href="#getting-there-aka-digital-transformation">Getting there (aka “Digital Transformation”)</a>
    <ul>
      <li><a href="#snapshot-but-on-solidfire"><code class="language-plaintext highlighter-rouge">.snapshot</code>, but on SolidFire</a></li>
    </ul>
  </li>
  <li><a href="#next-steps">Next Steps</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
  <li><a href="#update-may-30-2021">Update (May 30, 2021)</a>
    <ul>
      <li><a href="#solidsync-powershell-script-that-syncs-source-to-target-volumes">SolidSync: PowerShell script that syncs Source to Target volumes</a></li>
      <li><a href="#solidbackup-stand-alone-powershell-script-that-does-the-following">SolidBackup: stand-alone PowerShell script that does the following</a></li>
      <li><a href="#rinse--reapeat">Rinse &amp; reapeat</a></li>
      <li><a href="#why-not-one-big-script-that-does-it-all">Why not one big script that does it all</a></li>
    </ul>
  </li>
  <li><a href="#demo">Demo</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>Caution: this may be of interest to only “DevOpsy” SolidFire users out there…</p>

<p>This isn’t about a product, service or some Github project you can clone and deploy today - it’s merely something we <em>can</em> create now and on our own.</p>

<h2 id="first-attempt">First attempt</h2>

<p>In <a href="/2021/04/22/solidfire-kvm-duplicati-and-backup-to-s3.html">previous</a> posts I mentioned the idea for SolidBackup, a simple Backup &amp; Restore solution possibly needed by Docker/K8s administrators who wanted a basic way to protect their data on SolidFire systems.</p>

<p>I built a prototype in Python and SolidFire CLI, which was easy, but hard. I got a bit farther than this, but essentially it had a CRUD component for SolidFire/Trident (Kubernetes or Docker) volumes to protect. It’d create a volume clone if a Target (Clone) didn’t exist, and a schedule to take a snapshot of Source and re-sync Src to Tgt using the SolidFire API.</p>

<p><img src="/assets/images/solid-backup-prototype.gif" alt="SolidBackup Alpha in Python" /></p>

<p>(I have a “manual” walk-through (each step) <a href="https://www.youtube.com/watch?v=bvI7pgXKh6w">on YouTube</a>, but it’s 23 minutes long.)</p>

<p>Before I finished that utility I discovered there was an app for that exact use case (simple container volume backup) and that exact audience (DIY/DevOps) - Velero - which works with NetApp Trident and SolidFire (see my <a href="/2021/02/08/use-velero-with-netapp-solidfire-and-trident-csi">Velero-with-SolidFire post here</a>, so I stopped working on SolidBackup.</p>

<p>But recently I came to the conclusion that Skilled (or Poor?) Man’s backup/restore for containers isn’t the only use case for SolidBackup.</p>

<h3 id="backup-and-restore-in-kvm-environments">Backup and Restore in KVM environments</h3>

<p>Last year I worked with Trident in mind, but it turns out people use SolidFire in KVM and Hyper-V environments and sometimes they need a backup utility they can improve and integrate on their own.</p>

<p>In both of these cases, because we can mount SolidFire clone volumes on Linux or Windows, we can also backup and rstore them as either files or images. With VMware (VMFS 6+) it’s not easy to do it out of the box with generic Linux OS.</p>

<h3 id="data-migration">Data Migration</h3>

<p>If we can backup data at site A and restore at site B, that’s not only B&amp;R but also Data Migration (Nobel Prize incoming in 3…2…).</p>

<p>Seriously - everyone is aware that restore doesn’t have to occur the same SolidFire cluster where backup was taken, but like with KVM - no one has asked (in the context of DIY approaches).</p>

<p>But these days people ask about it - whether it’s because they are migrating to or from the Public Cloud, or because they use Hybrid Cloud and need to move their data back-and-forth between a SolidFire cluster located on-premises and Public Cloud.</p>

<p>Neither of these use cases were on my radar last year.</p>

<h3 id="do-we-really-want-diy-approaches-to-protect-our-data">Do we really want DIY approaches to protect our data</h3>

<p>I prefer that my SolidFire customers use enterprise-grade data protection solutions, because that almost always works better.</p>

<p>But sometimes that’s not possible and sometimes it’s not about replacing, but complementing what customers already have. I wrote about that in one of the recent posts.</p>

<p>Example: the SolidFire API lets you copy one volume to another (i.e. it can resync the original volume to a same-sized volume such as its clone created 24 hours ago), but I’m yet to meet a customer who knows of - let alone uses - this feature. Why? I don’t know. Maybe because the API method is not exposed in the UI.</p>

<p>I’m sure there are users out there who use it, but my point is quite a few customers clone volumes - and sometimes say they’d like that to work faster - but no one uses the feature that makes it (let’s say) 10x faster.</p>

<p>The first step in a daily SolidBackup workflow - once Source and Target pairs have been created, that is - is to perform a Src-to-Clone resync: for each volume pair, copy Source to Target (Clone). Even if no one pays attention to anything else but just discovers and starts using this feature, that would already be a decent step forward.</p>

<p>Lastly, the idea of SolidBackup isn’t prescriptive. It doesn’t even exist (yet), but anyone can make their own or take some ideas and adopt them in their environment. And if some of SolidFire users did that, they’d likely be better off which is another plus.</p>

<h2 id="second-attempt">Second attempt</h2>

<p>Last year I used SolidFire CLI (Python) and Duplicacy (which has a nice Web UI).</p>

<p>This year I evaluated two additional approaches:</p>

<ul>
  <li>SolidFire CLI (Python) + Duplicati (<a href="https://youtu.be/wP8nAgFo8og">8 min video of Duplicati + KVM + SolidFire</a> it was very similar to last year’s attempt with Duplicacy so I didn’t spend time on trying to automate it - I merely worked through the same steps</li>
  <li>SolidFire Tools for PowerShell and Restic. Unlike Duplicacy or Duplicati, Restic has no Web UI, so the ability to automate seemed more pressing</li>
</ul>

<h3 id="create-configuration-and-keep-src--dst-clone-volumes-in-sync">Create configuration and keep Src &amp; Dst (Clone) volumes in sync</h3>

<p>This CSV file has Src Volume ID, Tgt Volume ID (made by cloning Src Volume on the same SolidFire cluster), Partition number and filesystem Type:</p>

<pre><code class="language-raw">351,369,1,xfs
11,222,0,xfs
44,666,1,ext4
55,888,1,ntfs
</code></pre>

<p>When we start, we read this configuration file and copy Src to Dst/Tgt volume based on volume IDs. We just need columns 1 and 2.</p>

<p><img src="/assets/images/revisiting-solidbackup-01.png" alt="Step one in solidbackup - solidsync" /></p>

<p>Here one can get very fancy (and never finish this step) - take “before” snapshots, run “post” scripts, etc.</p>

<p>I keep it simple: on-demand (crash-consistent) snapshots are taken by SolidFire when CopyVolume (to Volume) is requested, so I don’t have to do anything. But if you want and can create application consistent snapshots before volume sync runs, they can be used (that is, volume sync will sync from a Source’s snapshot to Destination). That would give you a way to get application-consistent backups.</p>

<p>Another fancy detail is you can assign clone to a different storage account (which I do) because I don’t want other VMs to access clone volumes. I also adjust storage QoS on the clones, to use a fairly low Minimum (performance guarantee), but have a high Maximum (good for backup workload, if nothing else is keeping SolidFire busy).</p>

<p>This part already works quite well and can be used for anything - say, to quickly refresh build farm volumes for DevOps workflows.</p>

<h3 id="backup-to-s3">Backup to S3</h3>

<p>Next I mount each Dst (clone) volume) to <code class="language-plaintext highlighter-rouge">/mnt/$SrcId</code>. I don’t care about mounting clone volumes to /mmnt/$DstId because when we need to restore volume defined by SrcId, we look for /mnt/$SrcId as that’s where (a copy of) data we care about is. This way we don’t have to check Src-to-Dst mapping in SolidBackup configuration file.</p>

<p>Then we can use PowerShell or Ansible or something else to login to the clone volume iSCSI target and mount volume or a partition as necessary. We use columns 3 and 4 (Partition number (0 in a NetApp Trident environment), and FS type (usually xfs or ext4, but can be ntfs or other)).</p>

<p><img src="/assets/images/revisiting-solidbackup-02.png" alt="Step two - mount Clone volume" /></p>

<p>Once we can see data (files), we just run our a backup software or replication utility (it can be anything; Duplicacy, Duplicati, Restic, NetApp Cloud Sync, etc.).</p>

<p><img src="/assets/images/revisiting-solidbackup-03.png" alt="Step three - backup" /></p>

<p>You cannot see it in the screenshot above, but Restic copies data to a backup repository which doesn’t have to be S3, but it can (and indeed, in my demo it is - I used NetApp StorageGRID).</p>

<p>You could copy data to a VM running on StorageGRID on NetApp HCI server (ESXi) attached to E-Series as well. Or Google Object Storage (my nearest hyperscaler at this time), or a non-S3 target supported by your backup software.</p>

<p>Once backup is done, we can see it. Confusingly, Restic calls backups “snapshots” - these “snapshots” are Restic backups, not SolidFire snapshots.</p>

<p><img src="/assets/images/revisiting-solidbackup-04.png" alt="Restic backup in StorageGRID" /></p>

<p>But wait, what about that Src Volume ID 55, there some NTFS action going on in in that CSV configuration file above? That’s right. And that’s easy to deal with:</p>

<ul>
  <li>We can run Restic (and Duplicacy and Duplicati) on Windows. You’d tell PowerShell or Ansible to dispatch all login/mount jobs for rows with <code class="language-plaintext highlighter-rouge">ntfs</code> in Column 4 to a Windows VM or container</li>
  <li>Restic supports VSS on Windows and SolidFire has a VSS plugin, so DBAs who use Windows could use Restic independently of this workflow (“SolidBackup”) to backup their databases to S3</li>
  <li>We can choose to ignore the filesystem and simply backup the entire “raw” device the way SolidFire’s Backup to S3 feature does it! Let’s do that for a partition - partition 1, in this case:</li>
</ul>

<p><img src="/assets/images/revisiting-solidbackup-05.png" alt="Step three - raw device backup" /></p>

<p>But what about Windows Dynamic Volumes and LVM?</p>

<p>Take a group snapshot of Src Volume IDs and backup all block devices involved. Or - this would take some additional scripting in the - clone, reassemble and mount LVM. You’d need to gather LVM configuration prior to that, so you’d have to have LVM configuration files which wuld make everything more complicated (probably time to pay for enterprise backup software?).</p>

<p>In any and all cases, volume or partition backups can be compressed and deduplicated, so it’s all very efficient. You even get cross-volume deduplication (it’s much coarser than SolidFire’s 4kB granularity, of course).</p>

<p>To check space efficiency, I created a 1Gi partition with XFS that didn’t have any data in it - Restic backup was only 35kB. Even when using the device or partition approach, I can easily backup and/or migrate a 50 Gi database to or from GCP Taiwan in under 30 minutes. If it’s not the first time we backup, then backup is incremental and switch-over to or from GCP or other Public Cloud can be done in less than 10 minutes.</p>

<p>And all our SolidFire backups (or “snapshots”, as Restic calls them) - image- and file-based alike - are available to any client who can access our StorageGRID or GCP Object Storage.</p>

<h3 id="restore-from-s3">Restore from S3</h3>

<p>If you look at the hostname, you’ll see that now I am accessing this S3 bucket with Restic <strong>from a different host</strong>.</p>

<p>This VM instance is located in GCP Asia East 1 (Taiwan) and can restore data from “snapshots” on StorageGRID (on-premises) or Google Object Storage (if I were to use it). There’s nothing else to “download” or recover. The only thing I need is my S3 keys and Restic password used to decrypt backup data.</p>

<p><img src="/assets/images/revisiting-solidbackup-06.png" alt="solidbackup - view snapshots" /></p>

<p>That’s it! Your S3 bucket (Restic repository) is your backup database!</p>

<p>If this sounds or seems too abstract, Snapshot IDs that you see in the first column come from object names created by Restic:</p>

<p><img src="/assets/images/revisiting-solidbackup-07.png" alt="solidbackup - view snapshots" /></p>

<p>Object data and Snapshot IDs can be seen below. <code class="language-plaintext highlighter-rouge">68671c23</code> (in row 2) is (Restic) Snapshot ID of our Restic backup of Partition 1 of Vol ID 369 - you can find it in a shell screenshot above.</p>

<p><img src="/assets/images/revisiting-solidbackup-08.png" alt="solidbackup - view snapshots" /></p>

<p>Restic reads data that needs to be backed up and efficiently packages it in “snapshots”. It can restore, of course, but also “forget” (delete) backups and “prune” (“defrag”) backup repository space.</p>

<p>In order to restore data from a backup, I can restore an entire “snapshot” or any file(s) from it, or - in the case of a “raw” device/partition backup - a device or partition image.</p>

<p><img src="/assets/images/revisiting-solidbackup-09.png" alt="solidbackup - view snapshots" /></p>

<h2 id="getting-there-aka-digital-transformation">Getting there (aka “Digital Transformation”)</h2>

<p>If your data lives on VMFS or VVOLs, you can’t use this approach without using the vSphere API or running backup in each VM.</p>

<p>If you wanted to use a “centralized” or “semi-centralized” approach (where each Application or Team has its own SolidBackup-like VM) you could move data to filesystems native to your applications (NTFS, ext4, XFS) to make it possible to use the same automation on-premises and in the cloud, with generic VMs, hypervisor or container engines.</p>

<p>This may require significant efforts and at the same time you lose the benefits of VMFS or VVOLs (if you move data to OS-native filesystem on RDM/iSCSI), but you gain in flexibility and get some other advantages that can pay off your investment in time and effort.</p>

<p>Technically, there’s not much to it. Let’s say you have a SQL DB with OS on C drive, data on D, logs on L (3 VMDK files). Create two new SolidFire iSCSI volumes, expose them to the VM via iSCSI, mount them under E and F, stop SQL Server, copy SQL DB and logs over, swap the mountpoints D &amp; L with E &amp; F, start SQL Server, remove two unnecessary VMDKs. Next app, please!</p>

<p>Even better, you could use this opportunity to move some apps “one last time” (that is, move to Kubernetes).</p>

<p>In the case the above doesn’t ring a bell, here are some random ideas:</p>

<ul>
  <li>SolidFire SnapMirror cannot replicate data to GCP Cloud Volumes Service. The approach used by SolidBackup could restore SMB and NFS file servers from Windows and Linux VMs to Cloud Volumes Service. You can do things like restore Oracle files to NFS mounts (that live on Cloud Volume Service).</li>
  <li>SolidBackup could use S3 (and cheap public Internet) to securely and economically backup TBs of SolidFire data to Google Object Storage <em>before</em> you have Cloud Volumes ONTAP up and running in it. And once you need your data (test, DR), you can restore backup of raw SolidFire iSCSI devices to CVO iSCSI targets, or restore files from restic snapshots into VMs or containers attached to NetApp CVO in GCP (or other hyperscaler of your choice)</li>
  <li>SolidBackup could make your Hybrid Cloud back-and-forth data migration easy. You can start with data in the Public Cloud and return on-premises, or the other way around</li>
  <li>SolidBackup could work exactly like SolidFire built-in Backup feature (including Backup to S3), but <strong>at &gt;1 GB/s</strong> (and you can get that with StorageGRID or HCI+E-Series running on premises). And you can restore such (volume or partition) backups anywhere, to any block device (ONTAP, E-Series, and more).</li>
  <li>SolidBackup (or individual steps/components, when reused elsewhere) could let us seamlessly (I haven’t demonstrated that in these screenshots) integrate SolidFire with hybrid cloud data workflows, including batch jobs, testing, and more</li>
</ul>

<h4 id="snapshot-but-on-solidfire"><code class="language-plaintext highlighter-rouge">.snapshot</code>, but on SolidFire</h4>

<p>The idea of SolidBackup as a clone-focused backup to both make backup and restore run faster, and to increase the awareness of the SolidFire’s volume “re-sync” feature.</p>

<p>The SolidFire API allows 1,000 volumes per node, but officially supported limit is 400 active and 700 inactive (i.e. without iSCSI sessions), so the cost of having (say) 1,200 clone volumes lying around is mostly just the cost of their metadata capacity. We could keep only the important ones online and clone the rest on demand (and delete them after backup). Folks with active volumes close to the limit would have to batch backup jobs on clones (say,32 or 64 at once) to not mount hundreds of additional volumes at the same time.</p>

<p>If you have a way (and means, i.e. you’re not close to those maximums) to keep up-to-date clones online, when/if you want to restore file(s) from a snapshot you no longer need to wait until you finish creating a clone. You can copy the files from latest mounted clone as long as you can use WinSCP (or <code class="language-plaintext highlighter-rouge">scp</code>). So this is one immediate advantage that doesn’t involve backup or Hybrid Cloud use cases.</p>

<p>As I mentioned above, if you don’t like the idea of someone (like a K8s admin) having access to your files/data, you could use the same approach to have clone data mounted only in your namespace or your own volume. We’d just have to adjust your SolidBackup-like script to make clones and mount them in same (or on-demand) VMs or dev-test namespaces. This would work even for encrypted volumes. One common pattern seems to be “spin a temp VM + mount clone volume” which would be eaasy to automate with Ansible or Terraform.</p>

<p>Before we re-run volume sync we could scan clone volume for file names and put that data into an Elastic instance so that we can easily find files that are no longer present in the latest clone - but let’s not get too carried away now!</p>

<h2 id="next-steps">Next Steps</h2>

<p>Like in last year’s demo the process and each step in it work fine - it’s just a matter of putting it all together.</p>

<p>Or - just as good - using some of these ideas to do things better in your own SolidFire / Hybrid Cloud environment.</p>

<p>To those who contemplate automating some of their SolidFire workflows and are good at both PowerShell and Python, I would recommend to first consider <a href="https://pypi.org/project/solidfire-sdk-python/">SolidFire SDK for Python</a> and if that’s not an option then <a href="https://www.powershellgallery.com/packages/SolidFire.Core/12.3.0.81">SolidFire Tools for PowerShell</a>. The reason is there’s less concern when integrating with Linux iSCSI code and Ansible (PowerShell 7.1.3 on Ubuntu 18.04 is 90% “there”, but has some quirks).</p>

<p>I’m good at neither, but after doing the volume copy part in PowerShell, it does seem much easier than SolidFire CLI (Python) because there’s no need to wrap CLI commands in Python or other language (or write everything in one of old school Linux shells).</p>

<p>I got past the first hurdle - volume sync (as per below) and now need to work on Ansible (login/mount) and finally backup rules and schedules followed by logout/unmount (same Ansible scripts).</p>

<p><img src="/assets/images/revisiting-solidbackup-00.gif" alt="solidsync in action" /></p>

<p>Even if the rest of the steps remain unfinished (manual or semi-manual), I think this is a big improvement over SolidFire’s built-in <a href="/2021/04/21/solidfire-backup-to-s3">Backup to S3</a> feature and can complement commercial data protection software.</p>

<h2 id="conclusion">Conclusion</h2>

<p>When I think of a workflow like the one described in SolidBackup-related posts, three things come to my mind:</p>

<ul>
  <li>it’s embarrassing how many time I’ve blogged about something that doesn’t exist</li>
  <li>I can’t resist it - I really <em>love</em> this approach and think it’s a great way to connect SolidFire with the Public Cloud</li>
  <li>it’s already clear to me that some SolidFire customers are interested in using and automating some steps from SolidBackup workflow, and with small changes we should be able to reuse that to automate SolidFire backups in Kubernetes environments (Velero <a href="https://www.jamesmcleod.xyz/2020/12/09/velero-restic/">works with Restic</a>)</li>
</ul>

<p>On this last point, in one of earlier posts discussing DR for SolidFire in Kubernetes environments I played with PowerShell wrappers for the Trident CLI (<code class="language-plaintext highlighter-rouge">tridentctl</code>) which worked very well in PowerShell for Linux. Example of one such wrapper cmdlet:</p>

<p><img src="/assets/images/manage-netapp-trident-with-powershell-01.png" alt="PowerShell wrapper for Trident" /></p>

<p>Trident CLI is also used to import volumes to Kubernetes.</p>

<p>Which means a simple Import-TridentVolume wrapper cmdlet could import clone volumes to Kubernetes where Velero &amp; Restic - i.e. <em>the entirety of currently unfinished SolidBackup steps</em> - have been deployed according to the Velero documentation and ready to go! With namespaces, schedules, security, logging, auditing and more already built-in thanks to Kubernetes.</p>

<p>Sound good?</p>

<h2 id="update-may-30-2021">Update (May 30, 2021)</h2>

<p>I got something that resembles a working set of scripts.</p>

<h3 id="solidsync-powershell-script-that-syncs-source-to-target-volumes">SolidSync: PowerShell script that syncs Source to Target volumes</h3>

<p><img src="/assets/images/solidbackup-01-prepare.gif" alt="SolidSync Demo" /></p>

<p>As you can see there’s a config file with volume pairings, and the script copies Source to Target (Clone) volumes.</p>

<p>Here’s how one such “app” (pairing) is defined. All of the info is data protection-related; Src Id, Tgt Id, Partition, Filesystem Type, and Backup Type (which can be file or image).</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">      </span><span class="n">db</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w">
        </span><span class="nx">SrcId</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="mi">400</span><span class="w">
        </span><span class="nx">TgtId</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="mi">403</span><span class="w">
        </span><span class="nx">Part</span><span class="w">       </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> 
        </span><span class="nx">FsType</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s2">"ext4"</span><span class="w">
        </span><span class="nx">BkpType</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s2">"file"</span><span class="w">
      </span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>The reason I use this format is I’ve experimented with it for SolidFire cluster failover in a NetApp Trident (Kubernetes) environment and found it better than CSV or SQL, and I hope later I can use it for SolidFire cluster failover for K8s as well (“app definition” would have PVC name, Storage Class and few other details).</p>

<p>By then I should build a CRUD TUI for it, though, because editing it by hand is almost as bad as working with YAML.</p>

<p>Once SolidSync is done running, you get refreshed Target volumes (prefixed with <code class="language-plaintext highlighter-rouge">solidbackup-</code> or other prefix of your choosing) that belong to the SolidBackup account and have a dedicated QoS policy suitable for high Max/Burst throughput.</p>

<p><img src="/assets/images/solidsync-src-to-dst-w-qos-and-account-adjustment.png" alt="SolidSync Result with cloned volumes belonging to another Account and QoS policy" /></p>

<h3 id="solidbackup-stand-alone-powershell-script-that-does-the-following">SolidBackup: stand-alone PowerShell script that does the following</h3>

<ul>
  <li>For all Target volumes (whether their backup is Image or File type): log in to iSCSI targets (clones)</li>
  <li>For File-based backup: mount volumes under <code class="language-plaintext highlighter-rouge">/mnt/$SrcId</code> (so that it’s easy to know where original volume 127 would be mounted (/mnt/127) despite what the clone volume ID might be)</li>
  <li>Create configuration files for SolidBackup-independent execution of backup
    <ul>
      <li>Ansible iSCSI login</li>
      <li>Ansible filesystem mount (read-only)</li>
      <li>Backup script (one command per backup job i.e. volume)</li>
    </ul>
  </li>
</ul>

<p>Example output files:</p>

<ul>
  <li>iSCSI login for Target Volume Id 402:</li>
</ul>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"login"</span><span class="p">:</span><span class="w"> </span><span class="s2">"yes"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"target"</span><span class="p">:</span><span class="w"> </span><span class="s2">"iqn.2010-01.com.solidfire:mn4y.solidbackup-sb02.402"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<ul>
  <li>Filesystem Mount for Source Volume Id 400 cloned to Target Volume Id 403 (I mount these to <code class="language-plaintext highlighter-rouge">/mnt/$SrcId</code>, so when I need to restore files from Source Volume 400, it’s easy to know where to look (/mnt/400):</li>
</ul>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"opts"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ro"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"state"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mounted"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"src"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/dev/disk/by-path/ip-192.168.103.30:3260-iscsi-iqn.2010-01.com.solidfire:mn4y.solidbackup-sb03.403-lun-0"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"fstype"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ext4"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/mnt/400"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Note the <code class="language-plaintext highlighter-rouge">ro</code> (read-only) mount option.</p>

<ul>
  <li>Backup script <code class="language-plaintext highlighter-rouge">backup.sh</code> (in this case, for Restic, but in “alpha” and “beta” demos of Solidbackup you could see other utilities used). In this script below jobs would run sequentially, but you could parallelize them in PowerShell or Bash or otherwise, similar to what I did with <a href="/2021/04/21/solidfire-backup-to-s3.html#demo">SolidFire Backup to S3</a>. <code class="language-plaintext highlighter-rouge">M.env</code> contains my Restic repository configuration and credentials.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">source</span> /home/sean/M.env
/home/sean/bin/restic <span class="nt">--json</span> <span class="nt">--verbose</span> backup <span class="nt">--tag</span> src-id-400 <span class="nt">--tag</span> tgt-id-403 <span class="nt">-e</span> lost+found /mnt/400
<span class="nb">sudo dd </span><span class="k">if</span><span class="o">=</span>/dev/disk/by-path/ip-192.168.103.30:3260-iscsi-iqn.2010-01.com.solidfire:mn4y.solidbackup-sb02.402-lun-0 <span class="nv">bs</span><span class="o">=</span>256kB <span class="nv">status</span><span class="o">=</span>none | <span class="nb">gzip</span> | /home/sean/bin/restic <span class="nt">--json</span> <span class="nt">--verbose</span> backup <span class="nt">--tag</span> src-id-399 <span class="nt">--tag</span> tgt-id-402 <span class="nt">--stdin</span> <span class="nt">--stdin-filename</span> mn4y.solidbackup-sb02.402
<span class="nb">sudo dd </span><span class="k">if</span><span class="o">=</span>/dev/disk/by-path/ip-192.168.103.30:3260-iscsi-iqn.2010-01.com.solidfire:mn4y.solidbackup-sb01.401-lun-0 <span class="nv">bs</span><span class="o">=</span>256kB <span class="nv">status</span><span class="o">=</span>none | <span class="nb">gzip</span> | /home/sean/bin/restic <span class="nt">--json</span> <span class="nt">--verbose</span> backup <span class="nt">--tag</span> src-id-398 <span class="nt">--tag</span> tgt-id-401 <span class="nt">--stdin</span> <span class="nt">--stdin-filename</span> mn4y.solidbackup-sb01.401
</code></pre></div></div>

<p>This animated GIF below shows SolidBackup running for three pairs of volumes setup by SolidSync. Notably, we should use File backup for one of them. That one ends up mounted, while Image based backup targets do not.</p>

<p>Also notice in the animation how much more efficient file based backup is: we backup a 100 MB file, which is fastest to start and to finish. The other two jobs (image backups, with same amount of data (100MB in each 2GB volume)) need to read 2GB’s of raw data to backup 5% of the useful content). But those are bit-for-bit identical and the only practical way if you don’t understand the filesystem format.</p>

<p><img src="/assets/images/solidbackup-02-execute.gif" alt="SolidBackup Demo" /></p>

<p>Once it’s all done, you can see your backup snapshots (last three, <code class="language-plaintext highlighter-rouge">d6892a3f</code> is the File based job). We also got the tags added to the scripts so it’s very easy to find backups by either Source or Target Volume ID!</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>restic snapshots
repository 9f88ba35 opened successfully, password is correct
ID        Time                 Host        Tags                   Paths
<span class="nt">--------------------------------------------------------------------------------------------</span>
974c6dfe  2021-05-30 07:53:06  sb          src-id-400,tgt-id-403  /mnt/400
dec9a904  2021-05-30 07:53:11  sb          src-id-398,tgt-id-401  /mn4y.solidbackup-sb01.401
74421868  2021-05-30 07:56:15  sb          src-id-399,tgt-id-402  /mn4y.solidbackup-sb02.402
d6892a3f  2021-05-30 07:56:15  sb          src-id-400,tgt-id-403  /mnt/400
dc20861e  2021-05-30 07:56:21  sb          src-id-398,tgt-id-401  /mn4y.solidbackup-sb01.401
<span class="nt">--------------------------------------------------------------------------------------------</span>
5 snapshots
</code></pre></div></div>

<h3 id="rinse--reapeat">Rinse &amp; reapeat</h3>

<p>After a backup finishes, unmount any (SolidBackup) filesystem mounts and log out of the Target(s) to be ready for the next resync (that is, the next run of SolidSync) for which our SolidBackup VM must not be attached to the Target volumes. You could run this at the end of your backup. Or simply reboot the VM after backup.sh is done.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">&gt;</span><span class="w"> </span><span class="n">sudo</span><span class="w"> </span><span class="nx">umount</span><span class="w"> </span><span class="nx">/mnt/</span><span class="o">*</span><span class="w"> </span><span class="c"># to unmount all SolidBackup Targets</span><span class="w">
</span><span class="err">&gt;</span><span class="w"> </span><span class="p">[</span><span class="n">array</span><span class="p">]</span><span class="nv">$logins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">Get-Item</span><span class="w"> </span><span class="nx">01</span><span class="o">*.</span><span class="nf">json</span><span class="p">)</span><span class="o">.</span><span class="nf">Name</span><span class="w">
</span><span class="err">&gt;</span><span class="w"> </span><span class="kr">foreach</span><span class="w"> </span><span class="p">(</span><span class="nv">$l</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="nv">$logins</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">ansible-playbook</span><span class="w"> </span><span class="o">.</span><span class="nx">/01-iscsi-login.yaml</span><span class="w"> </span><span class="nt">-e</span><span class="w"> </span><span class="err">@</span><span class="nv">$l</span><span class="w"> </span><span class="nt">-e</span><span class="w"> </span><span class="s2">"login=no"</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Next time we need to run backup, if nothing has changed in terms of volume and backup configuration we could simply rerun SolidSync and after it’s done apply the same Ansible playbooks and run the same backup script (backup.sh). Everything can be unattended and you just need to get your Ansible and Restic logs.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">&gt;</span><span class="w"> </span><span class="p">[</span><span class="n">array</span><span class="p">]</span><span class="nv">$logins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">Get-Item</span><span class="w"> </span><span class="nx">01</span><span class="o">*.</span><span class="nf">json</span><span class="p">)</span><span class="o">.</span><span class="nf">Name</span><span class="w">
</span><span class="err">&gt;</span><span class="w"> </span><span class="p">[</span><span class="n">array</span><span class="p">]</span><span class="nv">$mounts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">Get-Item</span><span class="w"> </span><span class="nx">02</span><span class="o">*.</span><span class="nf">json</span><span class="p">)</span><span class="o">.</span><span class="nf">Name</span><span class="w">
</span><span class="err">&gt;</span><span class="w"> </span><span class="kr">foreach</span><span class="w"> </span><span class="p">(</span><span class="nv">$l</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="nv">$logins</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">ansible-playbook</span><span class="w"> </span><span class="o">.</span><span class="nx">/01-iscsi-login.yaml</span><span class="w"> </span><span class="nt">-e</span><span class="w"> </span><span class="err">@</span><span class="nv">$l</span><span class="w"> </span><span class="nt">-e</span><span class="w"> </span><span class="s2">"login=yes"</span><span class="p">}</span><span class="w">
</span><span class="err">&gt;</span><span class="w"> </span><span class="kr">foreach</span><span class="w"> </span><span class="p">(</span><span class="nv">$m</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="nv">$mounts</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">ansible-playbook</span><span class="w"> </span><span class="o">.</span><span class="nx">/02-fs-mount.yaml</span><span class="w"> </span><span class="nt">-e</span><span class="w"> </span><span class="err">@</span><span class="nv">$m</span><span class="w"> </span><span class="nt">-e</span><span class="w"> </span><span class="s2">"state=mounted"</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>If volumes have been added or removed, we’d have to remove old JSON and YAML files and potentially rerun SolidBackup. But this won’t happen every week unless you have a large environment.</p>

<p>This way, apart from SolidSync (results of which can be easily validated by doing a binary diff between Src and Tgt) the rest is <em>completely</em> up to Ansible (easy to monitor, secure and audit) and Restic (quite manageable as well).</p>

<h3 id="why-not-one-big-script-that-does-it-all">Why not one big script that does it all</h3>

<p>I could continue to run Restic directly from SolidBackup, but with the workflow exported in Ansible-compatible playbook configuration format and the backup jobs in a Restic script, you don’t have to worry (as much) about SolidBackup errors - it’s a fairly minimalistic script that can’t easily hide its mistakes.</p>

<p>Don’t forget that you can deploy one SolidSync/SolidBackup per VM, or per Group, and execute them on behalf of different stakeholders, so that each individual or team “sees” only own volumes, and uses its own encrypted backup repoository!</p>

<p>The source code has been <a href="https://github.com/scaleoutsean/solidbackup">posted</a> to Github.</p>

<h2 id="demo">Demo</h2>

<ul>
  <li>SolidSync &amp; SolidBackup (Restic version) <a href="https://youtu.be/y7cFBPqdN7s">demo</a> - 7m30s</li>
</ul>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#automation">automation</a>
       
    
  </span>
</div>
    

    
      <div class="related" data-pagefind-ignore>

    <h4>Possibly related - use live search at the top to find other content</h4>
    
    
    
    
    
    
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/03/17/monitoring-notifications-eseries-santricity-media-scan-progress.html">• Monitor progress and notify of E-Series media scan events</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/01/29/antivirus-scanning-for-on-premises-s3.html">• Scan NetApp StorageGRID S3 buckets for viruses and malware</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2024/01/24/kubernetes-keda-netapp-solidfire-eseries.html">• Kubernetes KEDA with NetApp SolidFire and E-Series</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2023/12/07/solidfire-rbac-for-json-rpc-api.html">• RBAC and delegation for SolidFire JSON-RPC API with Lua</a></h5>
          </div>
          
          
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
    
      
    
        
        
    
        
    
        
          <div class = "related-posts">
          <h5><a href="/2023/10/05/snapshots-and-consistency-groups-with-netapp-e-series.html">• Stand-alone and Consistency Group snapshots on NetApp E-Series</a></h5>
          </div>
          
          
            
    
    </div>

    

    
  </div><footer class= "footer">
    <p>2024-03-17 14:02 </p>
    <p>Copyright © 2024 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
