<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Cassandra with SolidFire and E-Series | Acting Technologist
      
    </title>
    <meta name="description" content="
     Notes on Cassandra with NetApp SolidFire and E-Series
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Cassandra with SolidFire and E-Series | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Cassandra with SolidFire and E-Series" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notes on Cassandra with NetApp SolidFire and E-Series" />
<meta property="og:description" content="Notes on Cassandra with NetApp SolidFire and E-Series" />
<link rel="canonical" href="https://scaleoutsean.github.io/2022/07/09/datastax-cassandra-with-netapp-solidfire-e-series.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2022/07/09/datastax-cassandra-with-netapp-solidfire-e-series.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-07-09T00:00:00+08:00" />
<script type="application/ld+json">
{"headline":"Cassandra with SolidFire and E-Series","dateModified":"2022-07-09T00:00:00+08:00","datePublished":"2022-07-09T00:00:00+08:00","url":"https://scaleoutsean.github.io/2022/07/09/datastax-cassandra-with-netapp-solidfire-e-series.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2022/07/09/datastax-cassandra-with-netapp-solidfire-e-series.html"},"description":"Notes on Cassandra with NetApp SolidFire and E-Series","author":{"@type":"Person","name":"scaleoutSean"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Cassandra with SolidFire and E-Series</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>09 Jul 2022</span> - <i class="far fa-clock"></i> 


  
  
    10 minute read
  

    </span>
  </div>
  
        <h2 id="introduction">Introduction</h2>

<p>Apache Cassandra is an open-source NoSQL distributed database.</p>

<p>DataStax has a commercial, value-added bundle based on Cassandra called <a href="https://www.datastax.com/products/datastax-enterprise">DataStax Enterprise</a> and a cloud service <a href="https://www.datastax.com/products/datastax-astra">AstraDB</a> which provides <a href="https://www.datastax.com/products/datastax-astra/features#zero-lock-in">zero lock-in</a> guarantee (users can always fall back to open-source Cassandra).</p>

<p>A while ago NetApp released a Technical Report <a href="https://www.netapp.com/media/10513-tr-4635.pdf">TR-4635</a> (“NetApp SolidFire with Cassandra”) which in my opinion isn’t useful. For example, it mentions Cassandra’s LCS, STCS and DTCS (which we can read about in TFM), but it offers no SolidFire-specific insights related to the actual effect of these compaction strategies and how SolidFire users should lay out volumes or configure QoS to get most out of each approach (or minimize downsides of each approach). And by now the TR is grossly outdated - for example for specific workloads DTCS is now recommended over TWCS.</p>

<p>I’ll use this page to write down some notes around running Apache Cassandra (and DataStax Enterprise) on NetApp SolidFire and E-Series.</p>

<h2 id="cassandra-workload">Cassandra workload</h2>

<p>Like with most other scale-out NoSQL databases, write I/O requests are large and sequential. See the official DataStax, Cassandra and Instaclustr pages for additional insights.</p>

<p>What you see below is volume IO statistics from SolidFire (Demo VM) running a simple Cassandra workload (which split Cassandra data among two volumes; more on that below). I/O isn’t high because it’s all small VMs, but we can see that writes are sequential.</p>

<p><img src="/assets/images/cassandra-01-insert-io.png" alt="Cassandra workload" /></p>

<ul>
  <li>Memory-based tables are flushed to disk once they grow beyond certain size <a href="https://community.datastax.com/questions/5457/off-heap-memory.html">which can be several GBs</a>; SolidFire would probably benefit from a smaller value to keep writes bursts smaller (say, 0.5-1.0 GiB)</li>
  <li>Database compaction runs at different times but more importantly it creates “churn” because it re-writes and combines existing SSTables into new SSTables which amplifies I/O (reads old data, performs new writes)</li>
</ul>

<p>Factors that impact I/O characteristics:</p>

<ul>
  <li>Workload, obviously, especially in terms of inserts (write workload)</li>
  <li>Workflows and application design - how applications create and delete data can influence other factors from this list, even if data format and content are the same</li>
  <li>Compaction strategy - some modes amplify write workload more than others; they have benefits but also “cost” in terms of extra storage throughput</li>
  <li>Replication factor - Cassandra usually recommends 3 (RF=3), but with protected storage (such as E-Series and SolidFire) RF2 is good enough</li>
  <li>Type of data - more vs. less compressible impacts storage efficiency on SolidFire and required storage capacity in general</li>
</ul>

<h2 id="solidfire-specific-notes">SolidFire-specific notes</h2>

<h3 id="performance">Performance</h3>

<p>SolidFire has no RAID; it uses an RF2-like data protection schema called Double Helix.</p>

<p>Some of the good things about SolidFire clusters is they scale out and there are no volume groups to manage and schedule (you just create a volume and SolidFire will host it on the right cluster node and spread its data around the cluster). But it also isn’t the greatest approach for heavy write-intensive workloads: if the application uses RF2 or RF3 in addition to being heavy on writes, then you hit the limits sooner and need to add more nodes which increases the cost.</p>

<p>That is why - in general - we’d use SolidFire for small to medium Cassandra workloads, where application-side write I/O goes up to 1 GB/s (with current SolidFire models H610).</p>

<h3 id="compaction-strategies">Compaction strategies</h3>

<p>You can read about them in the Cassandra documentation; these should be set according to workload requirements, not according to what’s better for SolidFire (what’s better is less data churn, but if your sizing leads you the conclusion that SolidFire would be too expensive to host the workload, then don’t use SolidFire)</p>

<h3 id="compression">Compression</h3>

<p>Each SolidFire cluster has <em>global</em> always-on efficiencies, both compression and deduplication. If you compress data on Cassandra, you may or may not find SolidFire efficiencies helpful - it really depends.</p>

<p>I ran two simple experiments on a single node Cassandra 4 database:</p>

<ul>
  <li>Two-column numeric KV table with Cassandra RF1 <em>without</em> compression: SolidFire compressed <strong>1.38x</strong> (account storage efficiency; i.e. 38% savings)</li>
  <li>Text/float/int table with Cassandra <strong>RF2 and LZ4 compression</strong>: SolidFire compressed <strong>1.27x</strong> (account efficiency)
    <ul>
      <li>I’ve made several edits to this efficiency factor, from 1.7x all the way to 1.27x; the reason is when I was writing this post I was running a low-I/O benchmark with 10 million records and published the post before it was completed. Compression was fairly consistent 10 hours into the benchmark, but after it was finished (27 hours), savings from compression eventually dropped to 1.27x</li>
    </ul>
  </li>
  <li>In both cases, SolidFire deduplication didn’t save any space</li>
</ul>

<p>Cassandra benchmarking and testing is tricky so while it seems possible to get savings even with compression and RF2 or RF3, you should test your workload to estimate savings with confidence. As mentioned earlier, all volumes on SolidFire belong to the same global pool so regardless of volume placement, efficiencies are always cluster-global.</p>

<p><strong>NOTE:</strong> remember to use <code class="language-plaintext highlighter-rouge">discard</code> on SolidFire mount points, to release de-allocated filesystem space and rethin volumes. That won’t improve performance, but it will save usable disk space on the cluster. Without <code class="language-plaintext highlighter-rouge">discard</code> (or periodic <code class="language-plaintext highlighter-rouge">fstrim</code>) your volumes will always look full although they aren’t, and SolidFire won’t be able allocate that unclaimed space to other volumes in the cluster.</p>

<h3 id="volume-layout-and-qos">Volume layout and QoS</h3>

<p>I haven’t done any performance testing yet, but I’d consider splitting commit log and data, simply in order to have two device queues.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/dev/sdb 2086912  114032  1972880  6% /var/lib/cassandra/commitlog
/dev/sdc 2086912   77780  2009132  4% /var/lib/cassandra/data
</code></pre></div></div>

<p>Then give each disk a high Min QoS, but if you’re short on IOPS, Cassandra commit log volume may benefit from higher Min QoS than data volume.</p>

<p>I’d set Max QoS and Burst QoS to high values because they don’t “cost” anything in terms of performance reservation on SolidFire - only Min QoS is guaranteed while Max and Burst are “best effort”.</p>

<p>This can be confirmed in practical testing.</p>

<h3 id="rack-awareness">Rack awareness</h3>

<p>SolidFire requires at least four nodes per cluster, so completely independent storage would require RF2 on Cassandra and two SolidFire clusters (each with 4 or more nodes).</p>

<p>SolidFire clusters with 6 or more nodes can be deployed with “AZ-like” redundancy where each of SolidFire’s Double Helix copies is placed in a different node group (called Protection Domain or PD). If we place all nodes from a PD in the same rack, we can spread the cluster across several racks and get rack protection with one SolidFire cluster.</p>

<p><img src="/assets/images/solidfire-protection-domains-and-availability-zones.png" alt="Cassandra with RF2 and SolidFire PDs" /></p>

<p>What’s the difference between a PD and AZ? SolidFire PD doesn’t concern itself with rack awareness - any client must be able to connect to any of the PDs, i.e. it’s one big L2 network and some spine-switch hopping will always be involved. If you want to know more about PDs, see <a href="/2021/07/06/solidfire-protection-domains-data-path.html">this post</a>.</p>

<h2 id="e-series-specific-notes">E-Series-specific notes</h2>

<h3 id="performance-and-compaction">Performance and compaction</h3>

<p>E-Series arrays are designed for low latency, high throughput and high IOPS (with NVMe media), so when considering compaction, we have to be relatively less concerned about its IO impact (compared to SolidFire, for example, which internally uses RF2 and therefore amplifies writes).</p>

<p>EF300 delivers close to 10 GB/s write performance and EF600 close to 20 GB/s, and each array can scale to hundreds of TBs, making E-Series great for Cassandra deployments of any size and performance. Use whatever compaction strategy is best and just make sure you size appropriately.</p>

<h3 id="compression-1">Compression</h3>

<p>E-Series has no compression and deduplication, so when considering compression we should simply configure compression based on recommendations from the Cassandra documentation.</p>

<h3 id="storage-and-volume-layout">Storage and volume layout</h3>

<p>I don’t have any test results to give these with confidence, but I’d start with:</p>

<ul>
  <li>RAID 1 or RAID 10 or DDP on SSD for Cassandra commit log - not because we need SSDs here, but SSDs have higher throughput than HDDs and take up fewer slots</li>
  <li>DDP or RAID 6 (HDD or SSD) for Cassandra data</li>
</ul>

<p>EF600 and EF300 can fit up to 24 NVMe disks (1.92 TB to 15.3 TB) in controller shelf, so if you have up to few hundred TB of data you may be better off with all 24 disks in a DDP pool.</p>

<h3 id="rack-awareness-1">Rack awareness</h3>

<p>E-Series has no logical availability zones inside of a single array.</p>

<p>While we can use Volume Groups to <em>segregate volume performance</em> between types of volumes based on workload and/or Cassandra nodes, for <em>rack redundancy</em> with NoSQL we usually use multiple arrays: if we use Cassandra with Replication Factor 2, deploying a pair of EF300 or EF600 in different racks would protect Cassandra from rack failures or downtime due to scheduled rack maintenance and at the same time keep storage overhead lower than with RF3 + JBOD.</p>

<h2 id="backup-and-restore">Backup and restore</h2>

<p>If you can take Cassandra offline, it’s easy to back it up on both SolidFire and E-Series. If you can’t, you probably want to use logical (application-aware) backup and restore, rather than storage or filesystem snapshots.</p>

<p>Instaclustr Esop and <a href="https://github.com/instaclustr/icarus">Icarus</a> can protect Cassandra data by taking and exporting application-aware snapshots to S3 or dumping them to a local filesystem.</p>

<p>In the former case, backups are self-contained so we can restore them anywhere - including to the cloud - and in the latter case we can leverage E-Series volumes or even NFS mounts (and if NFS happens to be on ONTAP, we could snapshot those backups and tier their cold data to S3).</p>

<p>Here’s what I got when I used Esop to snapshot and export Cassandra 4:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># dir -lat /tmp/7cd65d40-6fe2-460d-8a82-c7a91608ca24/datacenter1/rack1/</span>
total 16
drwxr-xr-x 4 root root 4096 Jul  8 12:10 <span class="nb">.</span>
drwxr-xr-x 2 root root 4096 Jul  8 12:10 manifests
drwxr-xr-x 6 root root 4096 Jul  8 12:10 data
drwxr-xr-x 3 root root 4096 Jul  8 12:10 ..

<span class="c"># dir -lat /tmp/7cd65d40-6fe2-460d-8a82-c7a91608ca24/datacenter1/rack1/manifests/autosnap-1657282244-f4f11ad3-0e58-320b-ab27-e95101fe70f0-1657282249777.json </span>
<span class="nt">-rw-r--r--</span> 1 root root 89210 Jul  8 12:10 /tmp/7cd65d40-6fe2-460d-8a82-c7a91608ca24/datacenter1/rack1/manifests/autosnap-1657282244-f4f11ad3-0e58-320b-ab27-e95101fe70f0-1657282249777.json

<span class="c"># du -sh /tmp/7cd65d40-6fe2-460d-8a82-c7a91608ca24/datacenter1/rack1/data/</span>
127M	/tmp/7cd65d40-6fe2-460d-8a82-c7a91608ca24/datacenter1/rack1/data/
</code></pre></div></div>

<p>Sometimes people will tell you that NoSQL database backups aren’t necessary when RF &gt;1 (and possibly cross-cluster replication) is available and used.</p>

<p>I don’t have a strong opinion on that - if your Cassandra is self-contained or you simply must have backups (compliance requirement), go ahead and back it up. If its records are inter-dependent with data on other systems and it doesn’t make sense protecting or restoring its data out of sync with the rest of your data systems, then having Cassandra backups taken at different times from the rest probably won’t be very useful.</p>

<p>For example, we don’t take backups of Cassandra databases running inside of NetApp StorageGRID and we don’t backup internal SolidFire cluster databases because in both cases there is a ton of other data that would have to be backed up at the same point in time to make restores useful.</p>

<h2 id="future-work">Future work</h2>

<p>The above takes care of the basics.</p>

<p>For now I don’t plan to investigate SolidFire efficiencies with Cassandra because it’s highly data-dependent and additional synthetic experiments may be relevant to some, but won’t be relevant to most, while E-Series users can take advantage of only Cassandra compression. General Cassandra compression recommendations are good enough, and we know that SolidFire compression likely saves some space as well.</p>

<p>I’m interested in real-life performance testing on E-Series as well as data protection, so my next post on Cassandra will probably be about E-Series, while data protection may come later after I see what NetApp does with Instaclustr Esop and Icarus.</p>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#analytics">analytics</a>
      &nbsp; 
    
      <a href="
      /categories/#storage">storage</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2023/07/28/thanos-with-minio-eseries-or-ontap-s3.html">Thanos with different S3 backends - StorageGRID, ONTAP S3 and MinIO on E-Series</a></li>
      
        <li><a href="/2022/08/09/nomad-beegfs-minio-s3.html">Simple S3 service endpoint for BeeGFS using Hashicorp Nomad and stand-alone MinIO</a></li>
      
        <li><a href="/2022/03/06/elastic-elk-stack-on-netapp.html">Elasticsearch 8 with NetApp storage</a></li>
      
        <li><a href="/2020/12/31/beegfs-on-netapp-hci-and-ef-series.html">BeeGFS on NetApp HCI with EF280 for high-speed file access from Virtual Machines</a></li>
      
        <li><a href="/2020/12/31/virtualized-splunk-on-netapp-hci-and-ef-series.html">Virtualized Splunk on NetApp HCI and EF Series iSCSI storage</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2024-10-10 22:20 </p>
    <p>Copyright © 2024 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
