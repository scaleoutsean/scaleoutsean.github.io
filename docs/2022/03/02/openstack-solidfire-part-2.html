<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Kubernetes with Cinder CSI Plugin on Openstack Yoga/Xena with SolidFire 12.3 - Part 2 | Acting Technologist
      
    </title>
    <meta name="description" content="
     Kubernetes Cinder CSI Plugin on Openstack Xena or Yoga with SolidFire - Part 2
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Kubernetes with Cinder CSI Plugin on Openstack Yoga/Xena with SolidFire 12.3 - Part 2 | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Kubernetes with Cinder CSI Plugin on Openstack Yoga/Xena with SolidFire 12.3 - Part 2" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Kubernetes Cinder CSI Plugin on Openstack Xena or Yoga with SolidFire - Part 2" />
<meta property="og:description" content="Kubernetes Cinder CSI Plugin on Openstack Xena or Yoga with SolidFire - Part 2" />
<link rel="canonical" href="https://scaleoutsean.github.io/2022/03/02/openstack-solidfire-part-2.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2022/03/02/openstack-solidfire-part-2.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-03-02T00:00:00+08:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"scaleoutSean"},"description":"Kubernetes Cinder CSI Plugin on Openstack Xena or Yoga with SolidFire - Part 2","@type":"BlogPosting","headline":"Kubernetes with Cinder CSI Plugin on Openstack Yoga/Xena with SolidFire 12.3 - Part 2","dateModified":"2022-03-02T00:00:00+08:00","datePublished":"2022-03-02T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2022/03/02/openstack-solidfire-part-2.html"},"url":"https://scaleoutsean.github.io/2022/03/02/openstack-solidfire-part-2.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Kubernetes with Cinder CSI Plugin on Openstack Yoga/Xena with SolidFire 12.3 - Part 2</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>02 Mar 2022</span> - <i class="far fa-clock"></i> 


  
  
    16 minute read
  

    </span>
  </div>
  
        <p><strong>NOTICE:</strong> all credentials and tokens on this page are samples, not leaked.</p>

<p><strong>Posts in “Kubernetes with Cinder CSI Plugin on Openstack Yoga/Xena with SolidFire 12.3” series</strong></p>

<ul>
  <li><a href="/2022/02/22/openstack-solidfire.html">Kubernetes with Cinder CSI Plugin on Openstack Yoga/Xena with SolidFire 12.3 - Part 1</a></li>
  <li>(this post) Kubernetes with Cinder CSI Plugin on Openstack Yoga/Xena with SolidFire 12.3 - Part 2</li>
</ul>

<p><strong>Table of Content for Part 2</strong></p>

<!-- TOC -->

<ul>
  <li><a href="#current-status">Current status</a></li>
  <li><a href="#next-steps">Next steps</a></li>
  <li><a href="#deploy-vms-for-kubernetes">Deploy VMs for Kubernetes</a></li>
  <li><a href="#install-and-configure-kubernetes">Install and configure Kubernetes</a></li>
  <li><a href="#install-and-configure-cinder-csi">Install and configure Cinder CSI</a>
    <ul>
      <li><a href="#cloud-provider-openstack">Cloud Provider Openstack</a></li>
      <li><a href="#cinder-csi">Cinder CSI</a></li>
    </ul>
  </li>
  <li><a href="#create-pvs-using-cinder-csi-from-within-kubernetes">Create PVs using Cinder CSI from within Kubernetes</a></li>
  <li><a href="#other-notes">Other notes</a></li>
  <li><a href="#closing-thoughts">Closing thoughts</a>
    <ul>
      <li><a href="#cinder-csi-1">Cinder CSI</a></li>
      <li><a href="#switching-back-and-forth">Switching back and forth</a></li>
      <li><a href="#getting-support">Getting support</a></li>
      <li><a href="#single-pane-storage-provisioning-for-vms-and-containers">Single pane storage provisioning for VMs and containers</a></li>
    </ul>
  </li>
  <li><a href="#video-walk-through">Video walk-through</a></li>
  <li><a href="#appendix-a---map-kubernetes-pvc-and-pv-to-openstack-volume-name-to-solidfire-volume-name">Appendix A - Map Kubernetes PVC and PV to Openstack Volume Name to SolidFire Volume Name</a></li>
  <li><a href="#appendix-b---install-configure-and-use-solidfire-cli">Appendix B - Install, configure and use SolidFire CLI</a></li>
</ul>

<!-- /TOC -->

<p>Let’s review what happened in Part 1 (current status) and start with these activities from Part 2!</p>

<h2 id="current-status">Current status</h2>

<p>In <a href="/2022/02/22/openstack-solidfire.html">Part 1</a> we installed a SolidFire Demo VM (which customers can download and use for free), Openstack Yoga (also a VM), and confirmed that SolidFire Cinder driver works with Nova and SolidFire.</p>

<p>I re-provisioned Openstack for Part 2 because I needed more resources for Kubernetes. When I provisioned Openstack VM for Part 2 my configuration did not change a lot - I still had one interface for workload/management (management network is not isolated as it would be in production) and another for iSCSI traffic to SolidFire.</p>

<p>External, iSCSI and external bridge on my Openstack VM (the rest is not shown):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:0c:29:ef:b9:bb brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.119/24 brd 192.168.1.255 scope global ens160
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:feef:b9bb/64 scope link 
       valid_lft forever preferred_lft forever
3: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:0c:29:ef:b9:c5 brd ff:ff:ff:ff:ff:ff
    inet 192.168.103.119/24 brd 192.168.103.255 scope global ens192
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:feef:b9c5/64 scope link 
       valid_lft forever preferred_lft forever
13: br-ex: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000
    link/ether 96:2d:88:42:dd:49 brd ff:ff:ff:ff:ff:ff
    inet 172.24.4.1/24 scope global br-ex
       valid_lft forever preferred_lft forever
    inet6 fe80::942d:88ff:fe42:dd49/64 scope link 
       valid_lft forever preferred_lft forever
</code></pre></div></div>

<p>Openstack itself had its usual networks (Private, Shared, Public) leveraging Neutron/OVS.</p>

<p><img src="/assets/images/openstack-solidfire-cinder-openstack-networks.png" alt="Openstack Networks" /></p>

<h2 id="next-steps">Next steps</h2>

<p>In order to make use of SolidFire Cinder driver from within Kubernetes, we need to do the following:</p>

<ul>
  <li>Deploy VMs for Kubernetes</li>
  <li>Install and configure Kubernetes</li>
  <li>Install and configure Cloud Provider Openstack and Cinder CSI plugin</li>
</ul>

<h2 id="deploy-vms-for-kubernetes">Deploy VMs for Kubernetes</h2>

<p>Similar to SolidFire and Openstack itself, we can save hardware resources by provisioning just one fat VM with all Kubernetes services.</p>

<p>To be honest, I didn’t expect this would work, but it did. But I confess I wasted 2-3 hours on dealing with the stupid OS images…. Eventually I settled for Debian 10, as you will notice in the screenshots or video demo.</p>

<p>I used that image to create a Kubernetes VM on Private Openstack network, and attach to it a Floating IP on “Public” network (meaning, an IP on Bridge <code class="language-plaintext highlighter-rouge">br-ex</code> that was connected to my default NIC on Openstack VM (ens160)). It doesn’t have to be done that way, but in the case you wonder…</p>

<p><img src="/assets/images/openstack-solidfire-cinder-instance-networks.png" alt="Kubernetes VM" /></p>

<p>One step that I skipped in this test, but couldn’t in production was Load Balancer. Because the VM’s “Public” network isn’t really public-public (it’s only available on Openstack bridge interface, but cannot be accessed from the outside), this wouldn’t work without a way to get ingress traffic in. But it was good enough for my purpose as I wasn’t interested in load balancing and external access - I only wanted to examine Cinder CSI.</p>

<p>If you plan to test with ingress, you’d need to consider that when creating VM interfaces. Check the Openstack documentation for various network topologies they recommend.</p>

<p>Internally, my Kubernetes VM had just one NIC on private network. I also installed containerd.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1442 qdisc pfifo_fast state UP group default qlen 1000
    link/ether fa:16:3e:4a:b0:00 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.47/26 brd 10.0.0.63 scope global dynamic eth0
       valid_lft 42347sec preferred_lft 42347sec
    inet6 fe80::f816:3eff:fe4a:b000/64 scope link 
       valid_lft forever preferred_lft forever
3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:4e:8f:15:6d brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:4eff:fe8f:156d/64 scope link 
       valid_lft forever preferred_lft forever
</code></pre></div></div>

<h2 id="install-and-configure-kubernetes">Install and configure Kubernetes</h2>

<p>I followed manual installation steps from Kubernetes.io - install kubectl and other required packages, run kubeadm to create a cluster, install Flannel, etc.</p>

<p>After I was done with these, I got additional interfaces (and later some veth* interfaces as well). This isn’t a recipe, obviously, but just to say I kept it simple and probably using just one node saved me from problems.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>6: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1392 qdisc noqueue state UNKNOWN group default 
    link/ether 86:e7:8d:47:70:44 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.0/32 scope global flannel.1
       valid_lft forever preferred_lft forever
    inet6 fe80::84e7:8dff:fe47:7044/64 scope link 
       valid_lft forever preferred_lft forever
7: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1392 qdisc noqueue state UP group default qlen 1000
    link/ether 72:c7:e6:63:21:34 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/24 brd 10.244.0.255 scope global cni0
       valid_lft forever preferred_lft forever
    inet6 fe80::70c7:e6ff:fe63:2134/64 scope link 
       valid_lft forever preferred_lft forever
</code></pre></div></div>

<p>The only problem I had was that default DNS client configuration (127.0.0.1) didn’t work in VM, so <code class="language-plaintext highlighter-rouge">kubeadm init</code> failed. I added an external DNS server from my LAN to resolv.conf.</p>

<h2 id="install-and-configure-cinder-csi">Install and configure Cinder CSI</h2>

<p>Next step was Cinder CSI. I expected to get stuck and never finish, especially after - while still working on Part 1 - I looked at <a href="https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/developers-guide.md">TFM</a>. This is required, that is required, you should pick a supported Kubernetes release (this sounded especially troublesome considering that I had a yet-to-be-released Yoga version of Openstack and latest Kubernetes (v1.23.4))… I was shocked when I got it to work!</p>

<h3 id="cloud-provider-openstack">Cloud Provider Openstack</h3>

<p>Long story short, to get started we need <a href="https://github.com/kubernetes//blob/master/docs/developers-guide.md">Cloud Provider Openstack</a> and for that to work you <a href="https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/developers-guide.md#prerequisites">must</a> configure the (Kubernetes) cluster with external cloud controller manager.</p>

<p>What that does is it lets Kubernetes link to Openstack, and then CSI Plugin from Cloud Provider Openstack can talk to Openstack and - among other things - tell its Cinder driver to do stuff.</p>

<p>I installed Cloud Provider Openstack without any fancy steps. I simply followed <a href="https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/openstack-cloud-controller-manager/using-openstack-cloud-controller-manager.md#steps">the mandatory steps</a> and avoided any optional stuff. As mentioned earlier, I skipped the load balancer section.</p>

<h3 id="cinder-csi">Cinder CSI</h3>

<p>The offical documentation for this part is <a href="https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/cinder-csi-plugin/using-cinder-csi-plugin.md#csi-compatibility">here</a>.</p>

<p>Again, I used the KISS principle and didn’t do any fancy steps from this page - no ca-cert, no <code class="language-plaintext highlighter-rouge">ignore-volume-az</code>, no nothing.</p>

<p>I had issues with one of the pods (openstack-cloud-controller-manager-r9gtk) constantly crashing, probably due to insufficient resources. To fix that I added leader-elect-lease-duration=60s and leader-elect-renew-deadline=30s to /etc/kubernetes/manifests/kube-controller-manager.yaml and restarted. I can’t say if that’s what fixed it, but after that all pods were <code class="language-plaintext highlighter-rouge">Running</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>debian@kubernetes-solidfire:~$ kubectl get pods -n kube-system
NAME                                           READY   STATUS    RESTARTS      AGE
coredns-64897985d-j9bqp                        1/1     Running   0             15h
coredns-64897985d-rwb2v                        1/1     Running   0             15h
csi-cinder-controllerplugin-689c55c9fc-xrrq9   6/6     Running   0             15h
csi-cinder-nodeplugin-dwdbp                    3/3     Running   0             15h
etcd-kubernetes-solidfire                      1/1     Running   1             15h
kube-apiserver-kubernetes-solidfire            1/1     Running   0             15h
kube-controller-manager-kubernetes-solidfire   1/1     Running   0             15h
kube-flannel-ds-p7bsn                          1/1     Running   0             15h
kube-proxy-kz9l4                               1/1     Running   0             15h
kube-scheduler-kubernetes-solidfire            1/1     Running   1             15h
openstack-cloud-controller-manager-r9gtk       1/1     Running   8 (15h ago)   15h

debian@kubernetes-solidfire:~$ kubectl get csidrivers.storage.k8s.io
NAME                       ATTACHREQUIRED   PODINFOONMOUNT   STORAGECAPACITY   TOKENREQUESTS   REQUIRESREPUBLISH   MODES                  AGE
cinder.csi.openstack.org   true             true             false             &lt;unset&gt;         false               Persistent,Ephemeral   15h

debian@kubernetes-solidfire:~$ kubectl get sc
NAME                            PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
csi-sc-cinderplugin             cinder.csi.openstack.org   Delete          Immediate           false                  15h
csi-sc-cinderplugin-solidfire   cinder.csi.openstack.org   Delete          Immediate           false                  4h2m
</code></pre></div></div>

<p>Above you can see in the above output two Storage Classes, one non-SolidFire and another SolidFire. This is beacuse I wanted to be able to use both LVM (default, non-SolidFire) and SolidFire for comparison purposes.</p>

<p>Two things to note:</p>

<ul>
  <li>Note that the <a href="https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/cinder-csi-plugin/features.md#topology">topology</a> stuff is enabled by default but it didn’t bother me (probably because I didn’t have any topology settings in my single node Openstack cluster). I also didn’t set any AZ in Cinder, so ignore-volume-az wasn’t necessary in Cinder CSI either. If you had SolidFire Protection Domains (which resemble AZs), you still wouldn’t use any topology for storage because in Protection Domains any client can connect to any SolidFire node - there’s no AZ-awareness in SolidFire volume scheduling (at least not in v12.3 and before). Maybe you could use topology for Nova, but iSCSI connections would still be all over the place.</li>
  <li>When I created a SolidFire-aware Storage Class, I set it to use Openstack Volume Type <code class="language-plaintext highlighter-rouge">solidfire-lo</code> which is one of two Volume Types (one low, one high performance) that I created in OpenStack for Cinder configuration (see Part 1 or the demo videos if you can’t figure it out)</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">csi-sc-cinderplugin-solidfire</span>
<span class="na">parameters</span><span class="pi">:</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">solidfire-lo</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">cinder.csi.openstack.org</span>
<span class="na">reclaimPolicy</span><span class="pi">:</span> <span class="s">Delete</span>
<span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">Immediate</span>
</code></pre></div></div>

<h2 id="create-pvs-using-cinder-csi-from-within-kubernetes">Create PVs using Cinder CSI from within Kubernetes</h2>

<p>Now we just create a PVC and check Openstack or SolidFire to see if SolidFire Cinder driver has succeeded to create a volume.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">csi-pvc-cinderplugin-sf</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">3Gi</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">csi-sc-cinderplugin-solidfire</span>
</code></pre></div></div>

<p>Below we can see two PVCs. The first is on LVM (local VM disk coming from LVM driver which could be using SolidFire storage (provisioned to Openstack hosts) as well, but in this case was not), the second is on SolidFire provisioned by SolidFire Cinder driver.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get pvc
NAME                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                    AGE
csi-pvc-cinderplugin      Bound    pvc-8f073942-12ab-44c5-9627-83923ff76e5b   1Gi        RWO            csi-sc-cinderplugin             14h
csi-pvc-cinderplugin-sf   Bound    pvc-013f9605-f759-44d0-be60-ac2edacab947   1Gi        RWO            csi-sc-cinderplugin-solidfire   6s
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">pvc-013f9605...</code> is the SolidFire volume created for PVC <code class="language-plaintext highlighter-rouge">csi-pvc-cinderplugin-sf</code>.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                             STORAGECLASS                    REASON   AGE
pvc-013f9605-f759-44d0-be60-ac2edacab947   1Gi        RWO            Delete           Bound    default/csi-pvc-cinderplugin-sf   csi-sc-cinderplugin-solidfire            7s
pvc-8f073942-12ab-44c5-9627-83923ff76e5b   1Gi        RWO            Delete           Bound    default/csi-pvc-cinderplugin      csi-sc-cinderplugin                      14h
</code></pre></div></div>

<p>I tried to take a snapshot of all Kubernetes volumes from Openstack, that worked. I assume that’s like crash-consistent snapshot done on SolidFire or from Element Plug-in for vCenter, without cooperation from pods or VM.</p>

<p>Openstack Freezer requires additional services to be in place so I didn’t test backup. This would be equivalent to quiesced filesystem backup for VMs.</p>

<p>For Kubernetes PVs we’d probably use Velero, but I didn’t want to look for trouble. I <a href="/2021/02/08/use-velero-with-netapp-solidfire-and-trident-csi.html">tried it before</a> and because it has a CSI and non-CSI version, I think there’s a fair chance at least one of them can work.</p>

<p>Cinder CSI has a snapshotter which I installed but did not have time to evaluate for this article. It’d be interesting in the context of Velero or Kasten K10, for example, but that’s few additional hours of experimenting and would have to be another PoC.</p>

<p>Screenshot of a (different) Cinder volume created by Cinder CSI:</p>

<p><img src="/assets/images/openstack-solidfire-cinder-volume-pvc.png" alt="Kubernetes PVC created by Cinder CSI" /></p>

<h2 id="other-notes">Other notes</h2>

<p>In Openstack, Cinder CSI volumes (PVs) are named after PVCs, which is great. But in SolidFire the volume name is different from the volume name in Openstack - it uses unique Volume <strong>ID</strong> from Openstack which is presumably safer but not as convenient.</p>

<p>This screenshot shows a Volume Name <code class="language-plaintext highlighter-rouge">pvc-8e2...</code> assigned to Volume ID <code class="language-plaintext highlighter-rouge">dc9...</code>.</p>

<p><img src="/assets/images/openstack-solidfire-cinder-to-solidfire-volume-name-mapping.png" alt="SolidFire volumes are named after Openstack's Volume Unique ID, not Cinder CSI's PVC Name" /></p>

<p>SolidFire would have its Volume Name shown as <code class="language-plaintext highlighter-rouge">UUID-dc9...</code>.</p>

<p>In order to map a SolidFire volume to Openstack volume (or vice versa) we need to use a script to get a list of Cinder volumes, filter out non-SolidFire volumes, and map Openstack Volume Unique IDs to SolidFire Name to create a Openstack Name to SolidFire Name mapping.</p>

<h2 id="closing-thoughts">Closing thoughts</h2>

<h3 id="cinder-csi-1">Cinder CSI</h3>

<p>Cinder CSI is a very interesting and useful addition to Openstack feature set.</p>

<p>Compared to using NetApp Trident from Kubernetes - which you certainly could do - Openstack and Cinder CSI gives you a single pane of management for both VM and Kubernetes storage at the price of having a slightly more complex storage provisioning stack. But the complexity in storage provisioning may be more than offset by having a single provisioner for both VMs and containers.</p>

<p>Cinder CSI also allows you to better manage security, because Openstack - similarly to vSphere - act as an intermediate between Kubernetes and storage, so all automated storage activity (VMs, containers) is recorded in Cinder logs.</p>

<p>In terms of other features the Cinder CSI approach is currently slightly richer than Astra Trident because (see Part 1) you get PV retyping and site fail-over, both of which are not available in <code class="language-plaintext highlighter-rouge">solidfire-san</code> driver in Astra Trident v21.01 or earlier. Cinder CSI users may also be able to leverage Openstack’s backup and restore for data protection.</p>

<h3 id="switching-back-and-forth">Switching back and forth</h3>

<p>Trident CSI supports volume import (which I used and it works) and so does Cinder, but I haven’t tested it.</p>

<p>This could be verified and then it would become relatively easy to import volumes created with the other CSI plugin and do so in-place which requires seconds.</p>

<p>This lowers the risk of using Cinder CSI as moving volumes from the control of Openstack SolidFire admin to Trident SolidFire admin only requires a change in storage account ownership of the volume and in-place import.</p>

<h3 id="getting-support">Getting support</h3>

<p>Technical support would likely be one of key questions for Cinder CSI users.</p>

<p>I do not know what NetApp’s position on this is, but I assume that if you use SolidFire Cinder driver in supported Openstack distribution, it’s supposed to work and be supported because Cinder CSI plugin does not use any SolidFire Cinder driver features that aren’t supported on Openstack.</p>

<p>The rest is up to Cloud Provider Openstack and Cinder CSI plugin, so if you can get support for that from your Openstack vendor, you could have a fully supported Openstack &amp; Kubernetes solution.</p>

<p>OpenShift 4.9, for example, <a href="https://docs.openshift.com/container-platform/4.9/storage/container_storage_interface/persistent-storage-csi-cinder.html">supports</a> Cinder CSI as a Technology Preview feature and <a href="https://docs.openshift.com/container-platform/4.9/storage/container_storage_interface/persistent-storage-csi-cinder.html#persistent-storage-csi-cinder_persistent-storage-csi-cinder">here</a> you can find how to make Openstack Cinder CSI the default storage class. I didn’t take that option because my SolidFire Demo VM has very limited capacity and performance resources.</p>

<h3 id="single-pane-storage-provisioning-for-vms-and-containers">Single pane storage provisioning for VMs and containers</h3>

<p>Another way to get to VM &amp; K8s nirvana is to do the opposite - run VMs on Kubernetes. I suspect that approach is currently less mature than the Openstack &amp; Cinder CSI approach, but it may gain traction faster.</p>

<p>At this moment Cinder CSI seems like a safer choice, but don’t forget that you can use both approaches at the same time. You could create one SolidFire cluster admin for Openstack and another for Trident on stand-alone (bare metal) or virtualized (on Openstack) Kubernetes.</p>

<p>Before trying Cinder CSI in production I would recommend to try it in real-life scenarios with multi-node Openstack clusters to see how it handles failures and other unusual situations.</p>

<h2 id="video-walk-through">Video walk-through</h2>

<p>The video shows setup and use of Cinder CSI, not the entire installation procedure which would take a long time. See Part 1 for details on SolidFire Cinder driver configuration details.</p>

<ul>
  <li><a href="https://rumble.com/vw96mj-using-cinder-csi-with-openstack-yoga-and-solidfire-12.3.html">Kubernetes, Cinder CSI, Openstack Yoga/Xena and SolidFire 12.3</a> - 4m45s</li>
</ul>

<h2 id="appendix-a---map-kubernetes-pvc-and-pv-to-openstack-volume-name-to-solidfire-volume-name">Appendix A - Map Kubernetes PVC and PV to Openstack Volume Name to SolidFire Volume Name</h2>

<p>Kubernetes:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get pvc
NAME                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                    AGE
csi-pvc-cinderplugin-sf   Bound    pvc-562922ba-216f-4224-87bf-e2d634e84fd7   3Gi        RWO            csi-sc-cinderplugin-solidfire   21s

<span class="nv">$ </span>kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                             STORAGECLASS                    REASON   AGE
pvc-562922ba-216f-4224-87bf-e2d634e84fd7   3Gi        RWO            Delete           Bound    default/csi-pvc-cinderplugin-sf   csi-sc-cinderplugin-solidfire            22s
</code></pre></div></div>

<p>Openstack (Cinder):</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>cinder list
+--------------------------------------+--------+------------------------------------------+------+----------------+--------------+----------+--------------------------------------+
| ID                                   | Status | Name                                     | Size | Consumes Quota | Volume Type  | Bootable | Attached to                          |
+--------------------------------------+--------+------------------------------------------+------+----------------+--------------+----------+--------------------------------------+
| 5e85816f-bda2-41be-a3d1-b3aecc993fc6 | <span class="k">in</span><span class="nt">-use</span> | pvc-562922ba-216f-4224-87bf-e2d634e84fd7 | 3    | True           | solidfire-lo | <span class="nb">false</span>    | 2233d97e-be53-43d4-86ed-9dd58b0aa9b0 |
| 8148810b-51c4-4349-ba40-8f46ac0eaab5 | <span class="k">in</span><span class="nt">-use</span> |                                          | 10   | True           | lvmdriver-1  | <span class="nb">true</span>     | 2233d97e-be53-43d4-86ed-9dd58b0aa9b0 |
+--------------------------------------+--------+------------------------------------------+------+----------------+--------------+----------+--------------------------------------+
</code></pre></div></div>

<p>Notice how Cinder Volume Name (first volume above) matches PVC name from Kubernetes, but SolidFire Name maps to Cinder Volume ID (5e85816f-bda2-41be-a3d1-b3aecc993fc6) prefixed with the string “UUID-“.</p>

<p>Using the SolidFire Python CLI, get volume details - such as SolidFire Volume ID, size, QoS, etc - for that volume like this:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sfcli volume list <span class="nt">--volumename</span> UUID-5e85816f-bda2-41be-a3d1-b3aecc993fc6
</code></pre></div></div>

<p>Appendix B (below) has detailed output of <code class="language-plaintext highlighter-rouge">sfcli volume list</code> command for this volume.</p>

<p>Basic steps for a script that could be used to eliminate manual steps:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># from Kubernetes CLI </span>
<span class="c"># we grep for SF CS - csi-sc-cinderplugin-solidfire - but this assumes just 1 PV</span>
<span class="nv">kube_name</span><span class="o">=</span><span class="sb">`</span>kubectl get pv | <span class="nb">grep </span>csi-sc-cinderplugin-solidfire | <span class="nb">awk</span> <span class="s1">'{print $1}'</span><span class="sb">`</span>
<span class="c"># from Openstack CLI</span>
<span class="nv">pvc</span><span class="o">=</span><span class="s2">"pvc-562922ba-216f-4224-87bf-e2d634e84fd7"</span>
<span class="nv">cinder_id</span><span class="o">=</span><span class="sb">`</span>cinder list | <span class="nb">grep</span> <span class="k">${</span><span class="nv">pvc</span><span class="k">}</span> | <span class="nb">awk</span> <span class="s1">'{print $2}'</span><span class="sb">`</span>
<span class="c"># from SolidFire CLI</span>
<span class="nv">sf_name</span><span class="o">=</span><span class="s2">"UUID-"</span><span class="k">${</span><span class="nv">cinder_id</span><span class="k">}</span>
sfcli volume list <span class="nt">--volumename</span> <span class="s2">"UUID-"</span>+<span class="nv">$cinder_id</span>
</code></pre></div></div>

<p>For multiple PVs it’s easier to handle that using the APIs (Kubernetes, OpenStack, and SolidFire’s with SolidFire Python SDK), but SolidFire CLI you can try <code class="language-plaintext highlighter-rouge">jq</code> to get just the details you want:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>sfcli volume list <span class="nt">--volumename</span> <span class="nv">$sf_name</span> | jq <span class="s1">'.volumes | .[] | {id: .volume_id, name: .name}'</span>
<span class="o">{</span>
  <span class="s2">"id"</span>: 111,
  <span class="s2">"name"</span>: <span class="s2">"UUID-5e85816f-bda2-41be-a3d1-b3aecc993fc6"</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Maybe even Ansible could be helpful for creating nice reports of Kubernetes-Openstack-SolidFire volume mappings.</p>

<p>Another approach could use log forwarding to Elastic where it should be possible to cross-reference the details from Kubernetes PVC, Openstack Volume Name/ID and SolidFire Name and other properties.</p>

<h2 id="appendix-b---install-configure-and-use-solidfire-cli">Appendix B - Install, configure and use SolidFire CLI</h2>

<p>Because Cinder and other Openstack stuff is Python-focused, let’s install SolidFire CLI and get volume info with it. I installed SolidFire CLI as Openstack user, but it could be installed on any major OS that runs Python 3 and can reach SolidFire MVIP.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip3 <span class="nb">install</span> <span class="nt">--user</span> solidfire-cli
</code></pre></div></div>

<p>Modify and source PATH (<code class="language-plaintext highlighter-rouge">PATH="$PATH:~/.local/bin"</code>) to sfcli module:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vim .bashrc 
<span class="nv">$ </span><span class="nb">source</span> .bashrc 
</code></pre></div></div>

<p>Now we can create a connection to SolidFire MVIP 192.168.1.34 (my username/password are admin/admin) and name it “DR” (or whatever you like).</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sfcli connection push <span class="nt">--mvip</span> 192.168.1.34 <span class="nt">--username</span> admin <span class="nt">--password</span> admin <span class="nt">--name</span> <span class="s2">"dr"</span>
</code></pre></div></div>

<p>List volume details for <code class="language-plaintext highlighter-rouge">UUID-</code> + <code class="language-plaintext highlighter-rouge">${OPENSTACK_CINDER_VOLUME_ID}</code> (obtained from Cinder above):</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>stack@aio:~<span class="nv">$ </span>sfcli volume list <span class="nt">--volumename</span> UUID-5e85816f-bda2-41be-a3d1-b3aecc993fc6
<span class="o">{</span>
    <span class="s2">"py/object"</span>: <span class="s2">"solidfire.models.ListVolumesResult"</span>,
    <span class="s2">"volumes"</span>: <span class="o">[</span>
        <span class="o">{</span>
            <span class="s2">"py/object"</span>: <span class="s2">"solidfire.models.Volume"</span>,
            <span class="s2">"access"</span>: <span class="o">{</span>
                <span class="s2">"py/object"</span>: <span class="s2">"solidfire.models.VolumeAccess"</span>,
                <span class="s2">"_value"</span>: <span class="s2">"readWrite"</span>
            <span class="o">}</span>,
            <span class="s2">"account_id"</span>: 54,
            <span class="s2">"attributes"</span>: <span class="o">{</span>
                <span class="s2">"attach_time"</span>: null,
                <span class="s2">"attached_to"</span>: <span class="s2">"2233d97e-be53-43d4-86ed-9dd58b0aa9b0"</span>,
                <span class="s2">"cinder-name"</span>: <span class="s2">"pvc-562922ba-216f-4224-87bf-e2d634e84fd7"</span>,
                <span class="s2">"created_at"</span>: <span class="s2">"2022-03-02T10:42:44+00:00"</span>,
                <span class="s2">"is_clone"</span>: <span class="nb">false</span>,
                <span class="s2">"uuid"</span>: <span class="s2">"5e85816f-bda2-41be-a3d1-b3aecc993fc6"</span>
            <span class="o">}</span>,
            <span class="s2">"block_size"</span>: 4096,
            <span class="s2">"create_time"</span>: <span class="s2">"2022-03-02T10:42:44Z"</span>,
            <span class="s2">"current_protection_scheme"</span>: <span class="o">{</span>
                <span class="s2">"py/object"</span>: <span class="s2">"solidfire.models.ProtectionScheme"</span>,
                <span class="s2">"_value"</span>: <span class="s2">"singleHelix"</span>
            <span class="o">}</span>,
            <span class="s2">"delete_time"</span>: <span class="s2">""</span>,
            <span class="s2">"enable512e"</span>: <span class="nb">true</span>,
            <span class="s2">"enable_snap_mirror_replication"</span>: <span class="nb">false</span>,
            <span class="s2">"fifo_size"</span>: 5,
            <span class="s2">"iqn"</span>: <span class="s2">"iqn.2010-01.com.solidfire:46z9.uuid-5e85816f-bda2-41be-a3d1-b3aecc993fc6.111"</span>,
            <span class="s2">"last_access_time"</span>: <span class="s2">"2022-03-02T10:42:47Z"</span>,
            <span class="s2">"last_access_time_io"</span>: null,
            <span class="s2">"min_fifo_size"</span>: 0,
            <span class="s2">"name"</span>: <span class="s2">"UUID-5e85816f-bda2-41be-a3d1-b3aecc993fc6"</span>,
            <span class="s2">"previous_protection_scheme"</span>: null,
            <span class="s2">"purge_time"</span>: <span class="s2">""</span>,
            <span class="s2">"qos"</span>: <span class="o">{</span>
                <span class="s2">"py/object"</span>: <span class="s2">"solidfire.models.VolumeQOS"</span>,
                <span class="s2">"burst_iops"</span>: 750,
                <span class="s2">"burst_time"</span>: 60,
                <span class="s2">"curve"</span>: <span class="o">{</span>
                    <span class="s2">"1048576"</span>: 15000,
                    <span class="s2">"131072"</span>: 1950,
                    <span class="s2">"16384"</span>: 270,
                    <span class="s2">"262144"</span>: 3900,
                    <span class="s2">"32768"</span>: 500,
                    <span class="s2">"4096"</span>: 100,
                    <span class="s2">"524288"</span>: 7600,
                    <span class="s2">"65536"</span>: 1000,
                    <span class="s2">"8192"</span>: 160
                <span class="o">}</span>,
                <span class="s2">"max_iops"</span>: 300,
                <span class="s2">"min_iops"</span>: 100
            <span class="o">}</span>,
            <span class="s2">"qos_policy_id"</span>: null,
            <span class="s2">"scsi_euidevice_id"</span>: <span class="s2">"34367a390000006ff47acc0100000000"</span>,
            <span class="s2">"scsi_naadevice_id"</span>: <span class="s2">"6f47acc10000000034367a390000006f"</span>,
            <span class="s2">"slice_count"</span>: 1,
            <span class="s2">"status"</span>: <span class="s2">"active"</span>,
            <span class="s2">"total_size"</span>: 3221225472,
            <span class="s2">"virtual_volume_id"</span>: null,
            <span class="s2">"volume_access_groups"</span>: <span class="o">[]</span>,
            <span class="s2">"volume_consistency_group_uuid"</span>: <span class="o">{</span>
                <span class="s2">"py/object"</span>: <span class="s2">"uuid.UUID"</span>,
                <span class="s2">"hex"</span>: <span class="s2">"b6674869a461487eaf202b6ab113615f"</span>
            <span class="o">}</span>,
            <span class="s2">"volume_id"</span>: 111,
            <span class="s2">"volume_pairs"</span>: <span class="o">[]</span>,
            <span class="s2">"volume_uuid"</span>: <span class="o">{</span>
                <span class="s2">"py/object"</span>: <span class="s2">"uuid.UUID"</span>,
                <span class="s2">"hex"</span>: <span class="s2">"160d37f190a44333bb2624733e35992d"</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">]</span>
<span class="o">}</span>
</code></pre></div></div>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#virtualization">virtualization</a>
      &nbsp; 
    
      <a href="
      /categories/#kubernetes">kubernetes</a>
      &nbsp; 
    
      <a href="
      /categories/#openstack">openstack</a>
      &nbsp; 
    
      <a href="
      /categories/#solidfire">solidfire</a>
      &nbsp; 
    
      <a href="
      /categories/#storage">storage</a>
       
    
  </span>
</div>
    

  

    
  </div><footer class= "footer">
    <p>2025-05-21 13:16 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
