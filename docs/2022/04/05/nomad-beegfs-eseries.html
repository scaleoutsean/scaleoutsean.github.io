<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Nomad batch jobs with BeeGFS and E-Series | Acting Technologist
      
    </title>
    <meta name="description" content="
     IO-intensive Nomad batch jobs on an E-Series-backed BeeGFS Host Volume
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Nomad batch jobs with BeeGFS and E-Series | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Nomad batch jobs with BeeGFS and E-Series" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="IO-intensive Nomad batch jobs on an E-Series-backed BeeGFS Host Volume" />
<meta property="og:description" content="IO-intensive Nomad batch jobs on an E-Series-backed BeeGFS Host Volume" />
<link rel="canonical" href="https://scaleoutsean.github.io/2022/04/05/nomad-beegfs-eseries.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2022/04/05/nomad-beegfs-eseries.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-04-05T00:00:00+08:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2022/04/05/nomad-beegfs-eseries.html"},"author":{"@type":"Person","name":"scaleoutSean"},"description":"IO-intensive Nomad batch jobs on an E-Series-backed BeeGFS Host Volume","@type":"BlogPosting","url":"https://scaleoutsean.github.io/2022/04/05/nomad-beegfs-eseries.html","headline":"Nomad batch jobs with BeeGFS and E-Series","dateModified":"2022-04-05T00:00:00+08:00","datePublished":"2022-04-05T00:00:00+08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Nomad batch jobs with BeeGFS and E-Series</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>05 Apr 2022</span> - <i class="far fa-clock"></i> 


  
  
    6 minute read
  

    </span>
  </div>
  
        <ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#setup">Setup</a></li>
  <li><a href="#generic-batch-job-with-io-to-parallel-filesystem">Generic batch job with I/O to parallel filesystem</a></li>
  <li><a href="#file-format-conversion">File format conversion</a></li>
  <li><a href="#summary">Summary</a></li>
  <li><a href="#demo">Demo</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>When I wrote about <a href="/2022/03/23/nomad-solidfire-hostpath-volumes.html">HashiCorp Nomad with NetApp SolidFire</a> last week I mentioned how BeeGFS CSI with NetApp E-Series is of to-do items.</p>

<p>This post isn’t about CSI, but an intermediate step.</p>

<p>Now, there are many batch job schedulers out there. Some are HPC-focused and extremely good for that use case.</p>

<p>But there are non-HPC use cases for BeeGFS, such as - for the sake of an example - data cleansing, video conversion and even backups (we could run <a href="/2022/04/03/restic-server-netapp-eseries.html">Restic backup</a> jobs for generic hosts and containers using Nomad).</p>

<p>Some folks must use workflows specific to their organization or solution, but sometimes they can be initiated from another system, and other times they’re still executed the old way (crontab-driven shell scripts?).</p>

<p>BeeGFS with E-Series provides extreme scale-out in terms of performance and number of files.</p>

<p>As noted in the first Nomad post, HashiCorp Nomad can schedule batch jobs, containers, VMs and more. It can also allocate desired resources to each job.</p>

<p>The other point I made is we don’t always need CSI storage (and I am not saying this because I haven’t done it yet!).</p>

<h2 id="setup">Setup</h2>

<p>These simple example is about running such jobs at a high speed. Normally we’d have multiple clients, but here I have just one.</p>

<ul>
  <li>BeeGFS cluster (VMs)
    <ul>
      <li>b1 - manager</li>
      <li>b2 - metadata server</li>
      <li>b3 - storage node 1</li>
      <li>b4 - storage node 2</li>
      <li>b5 - BeeGFS and Nomad client</li>
    </ul>
  </li>
  <li>Nomad servers (VM)
    <ul>
      <li>es1</li>
    </ul>
  </li>
  <li>Parallel filesystem
    <ul>
      <li>BeeGFS mounted at /mnt/beegfs on BeeGFS client (b5)</li>
    </ul>
  </li>
  <li>Block storage
    <ul>
      <li>NetApp E-Series 5760</li>
    </ul>
  </li>
</ul>

<p>On Nomad client with BeeGFS, configure Host Volume that points to a BeeGFS mount point or its subdirectory (e.g. /mnt/beegfs/nomad-mysql). beegfs-ctl gives us a view of our BeeGFS cluster.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>beegfs-ctl <span class="nt">--listnodes</span> <span class="nt">--nodetype</span><span class="o">=</span>meta
b2 <span class="o">[</span>ID: 1]
<span class="nv">$ </span><span class="nb">sudo </span>beegfs-ctl <span class="nt">--listnodes</span> <span class="nt">--nodetype</span><span class="o">=</span>storage
b3 <span class="o">[</span>ID: 3]
b4 <span class="o">[</span>ID: 4]
<span class="nv">$ </span>beegfs-ctl <span class="nt">--listnodes</span> <span class="nt">--nodetype</span><span class="o">=</span>client
A83C-624BAFAC-b5 <span class="o">[</span>ID: 101]
</code></pre></div></div>

<p>Visually:</p>

<p><img src="/assets/images/nomad-batch-beegfs-eseries.png" alt="Nomad with BeeGFS and E-Series" /></p>

<h2 id="generic-batch-job-with-io-to-parallel-filesystem">Generic batch job with I/O to parallel filesystem</h2>

<p>On Nomad server, create a batch task such as this:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    task <span class="s2">"script"</span><span class="o">{</span>
    driver <span class="o">=</span> <span class="s2">"raw_exec"</span>
    config <span class="o">{</span>
      <span class="nb">command</span> <span class="o">=</span> <span class="s2">"/usr/bin/fio"</span>
      args <span class="o">=</span> <span class="o">[</span><span class="s2">"/mnt/beegfs/nomad-mysql/fio.txt"</span><span class="o">]</span>
      <span class="o">}</span>
    <span class="o">}</span>
</code></pre></div></div>

<p>I currently have just one BeeGFS client, but with multiple BeeGFS/Nomad clients this job would be scheduled <em>to any</em> BeeGFS client with the same Host Volume. In fact - because BeeGFS is a <em>parallel</em> file system - you could schedule jobs on several clients at once (for example, N jobs that process 1/N-th of the input file each).</p>

<p>And - as demonstrated in the <a href="/2020/12/31/beegfs-on-netapp-hci-and-ef-series.html#performance">post about NetApp HCI with BeeGFS VMs on EF280 array</a> - this gives you the ability to run such jobs at multiple <a href="https://www.beegfs.io/c/beegfs-now-supports-nvidia-magnum-io-gpu/">GB/s per second per job</a>.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>nomad job run batch.nomad 
<span class="o">==&gt;</span> 2022-04-05T05:09:55Z: Monitoring evaluation <span class="s2">"17e84b74"</span>
    2022-04-05T05:09:55Z: Evaluation triggered by job <span class="s2">"batch"</span>
    2022-04-05T05:09:55Z: Allocation <span class="s2">"4293eab4"</span> created: node <span class="s2">"71a25827"</span>, group <span class="s2">"example"</span>
<span class="o">==&gt;</span> 2022-04-05T05:09:56Z: Monitoring evaluation <span class="s2">"17e84b74"</span>
    2022-04-05T05:09:56Z: Allocation <span class="s2">"4293eab4"</span> status changed: <span class="s2">"pending"</span> -&gt; <span class="s2">"running"</span> <span class="o">(</span>Tasks are running<span class="o">)</span>
    2022-04-05T05:09:56Z: Evaluation status changed: <span class="s2">"pending"</span> -&gt; <span class="s2">"complete"</span>
<span class="o">==&gt;</span> 2022-04-05T05:09:56Z: Evaluation <span class="s2">"17e84b74"</span> finished with status <span class="s2">"complete"</span>
</code></pre></div></div>

<p>It took 1 second to complete this job.</p>

<p>Job output is a 500 MiB file (rand-read.0.0). Although the workload was read-only, the file was created anew when the job executed.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo dir</span> <span class="nt">-lat</span> /mnt/beegfs/nomad-mysql/
total 512002
<span class="nt">-rw-r--r--</span> 1 nomad nomad 524288000 Apr  5 05:09 rand-read.0.0
drwxrwxr-x 2 nomad nomad         2 Apr  5 05:09 <span class="nb">.</span>
<span class="nt">-rw-r--r--</span> 1 root  root        202 Apr  5 04:39 fio.txt
drwxrwxrwx 3 root  root          7 Apr  5 03:33 ..
</code></pre></div></div>

<p>BeeGFS client (b5) with a successfully completed batch job:</p>

<p><img src="/assets/images/nomad-batch-beegfs-eseries-client.png" alt="BeeGFS/Nomad client" /></p>

<p>Job overview:</p>

<p><img src="/assets/images/nomad-batch-beegfs-eseries-job.png" alt="Completed batch job" /></p>

<h2 id="file-format-conversion">File format conversion</h2>

<p>Another example is video conversion - because recently somebody asked me about this. Our input is a video we want to convert to MP4.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ll
total 540906
drwxrwxr-x 2 nomad nomad         3 Apr  5 05:36 ./
drwxrwxrwx 3 root  root          7 Apr  5 03:33 ../
<span class="nt">-rw-r--r--</span> 1 root  root        202 Apr  5 04:39 fio.txt
<span class="nt">-rw-r--r--</span> 1 nomad nomad 524288000 Apr  5 05:09 rand-read.0.0
<span class="nt">-rw-r--r--</span> 1 nomad nomad  29597941 Mar 29 16:13 sample_1280x720_surfing_with_audio.m2v
</code></pre></div></div>

<p>When job gets allocated to b5, it consumes CPU (as expected), but very little IO (because it’s CPU-constrained).</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dstat <span class="nt">-tcn</span>
<span class="nt">----system----</span> <span class="nt">--total-cpu-usage--</span> <span class="nt">-net</span>/total-
     <span class="nb">time</span>     |usr sys idl wai stl| recv  send
05-04 05:39:46|  1   1  98   0   0|   0     0 
05-04 05:39:47|100   0   0   0   0|1034k  261k
05-04 05:39:48|100   0   0   0   0| 868B  514k
05-04 05:39:49|100   0   0   0   0| 516k  958B
05-04 05:39:50| 99   1   0   0   0| 517k  514k
05-04 05:39:51| 99   0   1   0   0| 163k  514k
05-04 05:39:52|100   0   0   0   0| 517k 2658B
05-04 05:39:53| 99   1   0   0   0| 804B  514k
05-04 05:39:54|100   0   0   0   0| 516k  760B
</code></pre></div></div>

<p>Because this BeeGFS filesystem uses storage devices on both storage nodes (b3,b4), each has 50% of that IO activity.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">----system----</span> <span class="nt">--total-cpu-usage--</span> <span class="nt">-net</span>/total- <span class="nt">-dsk</span>/total-
     <span class="nb">time</span>     |usr sys idl wai stl| recv  send| <span class="nb">read  </span>writ
05-04 05:39:33|  1   0  99   0   0| 130B  110B|   0     0 
05-04 05:39:34|  0   0  99   1   0|  66B  118B|   0    20k
05-04 05:39:35|  1   0  99   0   0|1406B  513k|   0     0 
05-04 05:39:36|  0   0 100   0   0| 514k  161k|   0     0 
05-04 05:39:37|  0   0 100   0   0| 130B  110B|   0     0 
05-04 05:39:38|  0   0 100   0   0| 434B  282B|   0     0 
05-04 05:39:39|  0   0 100   0   0| 514k  513k|   0     0 
05-04 05:39:40|  0   0 100   0   0| 345B  110B|   0    20k
</code></pre></div></div>

<p>Output (MP4 file sample_1280x720_surfing_with_audio.mp4):</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ll
total 547563
drwxrwxr-x 2 nomad nomad         3 Apr  5 05:39 ./
drwxrwxrwx 3 root  root          7 Apr  5 03:33 ../
<span class="nt">-rw-r--r--</span> 1 root  root        202 Apr  5 04:39 fio.txt
<span class="nt">-rw-r--r--</span> 1 nomad nomad 524288000 Apr  5 05:09 rand-read.0.0
<span class="nt">-rw-r--r--</span> 1 nomad nomad  29597941 Mar 29 16:13 sample_1280x720_surfing_with_audio.m2v
<span class="nt">-rw-r--r--</span> 1 nomad nomad   6815792 Apr  5 05:39 sample_1280x720_surfing_with_audio.mp4
</code></pre></div></div>

<p>I hard-coded video conversion parameters in the job (target resolution was smaller so the file name should have been sample_640x480…) - it’s not something to write home about but it worked for the purpose of this demonstration.</p>

<h2 id="summary">Summary</h2>

<p>Nomad makes it easy to schedule all sorts of jobs on various platforms. Some may even be jobs that run in (say) DB VMs and require complex steps that can benefit from other Nomad features such as the ability to integrate with Vault to avoid hard-coded passwords in your scripts.</p>

<p>If you have a workflow that can benefit from a better scheduler, you could dispatch jobs to Nomad which would schedule them for you.</p>

<p>You may be tempted to try Kubernetes and that’s fine, but from a job scheduling perspective all you need is a single binary (nomad) that runs as server and client depending on its role. The entire setup for a VM-based cluster (provision and configure VMs, BeeGFS, Nomad clients and servers) - can be done in less than 20 minutes.</p>

<p>BeeGFS with E-Series gives you the ability to access data from any client - whether it’s a VM, container, physical host - at a very high speed. Jobs in this post did not use Docker - I used the simplest approach, Nomad’s generic exec driver (which has “isolate” option for better security if you need it).</p>

<p>BeeGFS CSI - a CSI-compatible driver for BeeGFS maintained by NetApp - is our next stop on this journey. BeeGFS CSI doesn’t officially support Nomad (as of April 2022), but BeeGFS CSI driver should be able to work with Nomad CSI. More on that in next Nomad-related post. Until then, you may be interested in <a href="/2022/04/09/beegfs-csi-introduction.html">BeeGFS CSI with Kubernetes</a>.</p>

<h2 id="demo">Demo</h2>

<ul>
  <li><a href="https://rumble.com/vzrphv-hashicorp-nomad-batch-jobs-with-beegfs-and-netapp-e-series.html">IO-intensive batch jobs with HashiCorp Nomad, ThinkParQ BeeGFS, and NetApp E-Series</a> - 3m6s</li>
</ul>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#storage">storage</a>
      &nbsp; 
    
      <a href="
      /categories/#containers">containers</a>
      &nbsp; 
    
      <a href="
      /categories/#kubernetes">kubernetes</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2022/09/27/beegfs-csi-nomad-kubernetes.html">Speed of volume creation with BeeGFS CSI</a></li>
      
        <li><a href="/2022/04/24/nomad-batch-job-scale-out-parallel-filesystem-beegfs-e-netapp-series.html">Scaling out Nomad batch jobs with BeeGFS and NetApp E-Series</a></li>
      
        <li><a href="/2022/08/09/nomad-beegfs-minio-s3.html">Simple S3 service endpoint for BeeGFS using Hashicorp Nomad and stand-alone MinIO</a></li>
      
        <li><a href="/2022/06/14/batch-copy-files-beegfs.html">Copy files to or from BeeGFS before or after scheduled jobs</a></li>
      
        <li><a href="/2023/01/12/beegfs-eseries-hybrid-cloud-spot-ocean-spark.html">Burst on-prem GPU workloads from BeeGFS/E-Series clusters to Spot Ocean for Spark in the cloud</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2025-07-24 10:27 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
