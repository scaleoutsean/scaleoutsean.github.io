<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            S3 GO NATS! | Acting Technologist
      
    </title>
    <meta name="description" content="
     How many experts does it take ... never mind
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>S3 GO NATS! | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="S3 GO NATS!" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How many experts does it take … never mind" />
<meta property="og:description" content="How many experts does it take … never mind" />
<link rel="canonical" href="https://scaleoutsean.github.io/2025/07/23/s3-vector-search-02-diy.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2025/07/23/s3-vector-search-02-diy.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:image" content="https://scaleoutsean.github.io/assets/images/s3-go-nats.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-23T00:00:00+08:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"scaleoutSean"},"description":"How many experts does it take … never mind","@type":"BlogPosting","headline":"S3 GO NATS!","dateModified":"2025-07-23T00:00:00+08:00","datePublished":"2025-07-23T00:00:00+08:00","image":"https://scaleoutsean.github.io/assets/images/s3-go-nats.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2025/07/23/s3-vector-search-02-diy.html"},"url":"https://scaleoutsean.github.io/2025/07/23/s3-vector-search-02-diy.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">S3 GO NATS!</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>23 Jul 2025</span> - <i class="far fa-clock"></i> 


  
  
    11 minute read
  

    </span>
  </div>
  
        <ul>
  <li><a href="/2025/07/18/s3-vector-search-01-analysis.html">Part 1 - S3 vector search: S3 vector search - DIY vs AWS S3 Vectors</a></li>
  <li><strong>Part 2 - S3 vector search: S3 GO NATS!</strong> (this post)</li>
</ul>

<p>The first part was a rant against current approaches. This part attempts to demonstrate why not all but <em>many</em> S3 users shouldn’t use AWS S3 Vectors or their on-premises S3 vendor’s vector DB integration.</p>

<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#poor-mans-s3-vectors">Poor man’s S3 Vectors</a></li>
  <li><a href="#bring-your-own-vectors-with-s3-go-nats">Bring your own vectors with “S3 GO NATS”</a></li>
  <li><a href="#how-is-that-better">How is that better?</a>
    <ul>
      <li><a href="#versity-s3-gateway-and-beegfs-options">Versity S3 Gateway and BeeGFS options</a></li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a></li>
  <li><a href="#appendix-a-s3-go-nats-screenshots">Appendix A: S3-GO-NATS screenshots</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>Continuing from the rant in Part 1, this post aims to demonstrate:</p>

<ul>
  <li>how AWS S3 could have “solved” this better for S3 users</li>
  <li>how on-premises S3 vendors could do vector search right rather than redundantly productize stuff with weak value proposition</li>
</ul>

<p>As for AWS S3 Vectors, it could have been done</p>

<p>This took me a few evenings and a full (last) weekend to create.</p>

<p>In other words, in my book this doesn’t qualify as a “product” and shouldn’t be tightly tethered to another product or service (AWS S3 or on-premises S3 storage).</p>

<h2 id="poor-mans-s3-vectors">Poor man’s S3 Vectors</h2>

<p>This idea originated after I started looking various “stacks” that everyone is marketing these days, which was in the post about BeeGFS gRPC event notifications in version 8 (of BeeGFS). As I mentioned <a href="/2025/06/15/pipeline-with-beegfs-file-system-notifications-v2.html">here</a> and <a href="/2025/06/22/data-pipeline-with-beegfs-file-system-notifications-and-versity-s3-gateway.html">here</a>, that gives me a good tool to do “my own thing” in terms of building data pipelines that includes AI pipelines.</p>

<p>I spent free time in late June and early July working on another thing (<a href="/2025/07/07/firemox.html">Firemox</a>), so AWS S3 Vectors got released before I managed to do my own take on “vector search for on-prem S3 users”, but after I saw the announcement it also gave me the opportunity to reflect on S3 in general and their take on it.</p>

<p>One of the scenarios in S3-related data pipeline posts is creating and updating vector indices for directories and/or buckets.</p>

<p>I actually toyed with this idea last year in the post about <a href="/2024/02/23/storagegrid-notifications-kafka.html">StorageGRID Kafka notifications</a> when I observed that notifications don’t contain metadata or tags, but let’s move on.</p>

<h2 id="bring-your-own-vectors-with-s3-go-nats">Bring your own vectors with “S3 GO NATS”</h2>

<p>As I said in the first post, when it comes to vector search most on-premises S3 vendors spent half a decade totally asleep at the wheel and are now over-compensating with bloat and “solution stacks”.</p>

<p>When I started working with BeeGFS and Versity S3 Gateway, it didn’t take long to see it:</p>

<ul>
  <li>most S3 storage has Webhooks or some other notifications for object events (and now BeeGFS has great notifications for FS events as well - see those posts)</li>
  <li>most databases have Webhook support or at least examples of how a to use Webhooks with their database</li>
  <li>2 + 2 = …</li>
</ul>

<p>That doesn’t seem to equal “I need a $200K S3 vector search solution stack”, but it depends on whom you ask.</p>

<p>So over several evenings I had approximately 1.5 iterations on this 2+2=4 thing before I got to work on it.</p>

<p>Half-way through developing it I had to change some things so it took approximately 3 iterations to get here:</p>

<p><img src="/assets/images/s3-go-nats.png" alt="S3 Go NATS diagram" /></p>

<ul>
  <li>Step 1: configure Kafka (or Kafka-to-message store) notifications on your S3 storage</li>
  <li>Step 2: send them to some persistent storage (can be a DB or Kafka or message queue). I used the last one which is the same what I used with the S3 anti-virus posts, and why I call this “S3 GO NATS”</li>
  <li>Step 3: a dispatcher watches these and creates jobs per configuration file</li>
  <li>Step 4: index manager or manager<em>s</em> (if you want to completely prevent one index manager service from accessing buckets or indexes that belong to other users) watches index tasks, gets object metadata and tags, and triggers vectorizer jobs</li>
  <li>Step 5: I have “2.5 kinds” of these jobs (one for plain search, and 1.5 for vector search)
    <ul>
      <li>“Lite” vector embeddings are those where vectorizer service simply creates embeddings for object metadata and tags passed on to it by index manager service</li>
      <li>“Heavy” vector embeddings are those where vectorizer service <em>also</em> reads the object from S3 to create embeddings for it. This needs document segmentation, image analysis, etc.</li>
      <li>“Search-only” - <strong>without</strong> vector embeddings; this is done directly by index manager without dispatching to vectorizer</li>
      <li>When S3 event name is <code class="language-plaintext highlighter-rouge">s3:ObjectRemoved:*</code>, there’s no indexing - we then delete object from ElasticSearch indexes configured for the bucket</li>
    </ul>
  </li>
  <li>Step 6: index entries - whether it’s just search, or heavy embedings, or lite embeddings, or all three (depends on configuration, I can do all them, or even none) - are sent to <code class="language-plaintext highlighter-rouge">&lt;bucket&gt;_search</code> or <code class="language-plaintext highlighter-rouge">&lt;bucket&gt;_vector</code></li>
</ul>

<p>Obviously, none of this <em>has</em> to work this way. And I don’t think AWS S3 Vectors should work like this at all.</p>

<p>The point is that it <em>does</em> work, it took me just a few days to get it done <em>properly</em> (it not production-ready, but it doesn’t need a re-write or a change of architecture).</p>

<p>Containers and services as implemented so far:</p>

<ul>
  <li>HTTPS reverse proxy (Caddy)</li>
  <li>Persistent message store (3 NATS containers with filesystem-based message store; RF2; can be scaled out)</li>
  <li>DIY Webhook service (could be scaled-out for HA; scale-out is not needed here (I <a href="/2025/06/15/pipeline-with-beegfs-file-system-notifications-v2.html#appendix-a-batching-and-filtering">evaluated</a> that while working with BeeGFS file-system notifications)</li>
  <li>DIY Dispatcher service</li>
  <li>DIY API gateway which also runs watcher and vectorizer tasks (could be split in 3-4 services for scale-out)</li>
  <li>DIY CLI client (some are own, some S3 Vectors APIs, e.g. <code class="language-plaintext highlighter-rouge">CreateEmbeddings</code>, <code class="language-plaintext highlighter-rouge">PutVectors</code>)</li>
  <li>DIY utilities container with tools</li>
  <li>ElasticSearch 9 (1 container, can be scaled out)</li>
</ul>

<h2 id="how-is-that-better">How is that better?</h2>

<p>I don’t think Amazon S3 Vectors is bad or worse than my PoC, but it seems to me in the early 20s they’ve discovered that “regular” S3 simply can’t work the way they wanted it to work, so things like S3 Select are out, and bolt-on “sidecars” like S3 Tables and S3 Vectors are in. This is a problem.</p>

<p>In my own area of concern (say, NetApp StorageGRID or Versity S3 Gateway on BeeGFS), I can implement this (not even “poor man’s”) version that’s not so bad and works well enough - worse in some ways, and much better in others:</p>

<ul>
  <li><em>Consistent</em> AWS S3 Vectors API for hot and cold vectors
    <ul>
      <li>I implemented 2-3 S3 Vectors API methods in this PoC (more on that below). While AWS S3 Vectors users can use S3 Vectors APIs, once they expert data to OpenSearch Service they need to switch to OpenSearch API. My fake S3 Vectors API proxies selected S3 Vectors API to Elasticsearch, so your “hot” vector index data is already in Elasticsearch while cold can be tiered to S3 by Elasticsearch. And you can use Elasticsearch API as well - same data with two APIs</li>
    </ul>
  </li>
  <li>Front-end is Webhooks- or Kafka-based, so it’s easy to get notifications from any S3 service. My prototype receives StorageGRID Kafka notifications which use the standard AWS S3 SNS format, but its contents are slightly different between S3 vendors. The same approach can support Versity S3 Gateway notifications</li>
  <li>Back-end design is modular, so I could use OpenSearch or Qdrant or <em>whatever I like</em> (flat files, for example)</li>
  <li>It’s possible to overcome AWS S3 Vectors service limitations (which exist to not overload S3, and force you to export “hot” data to OpenSearch, or build your own indexer)</li>
</ul>

<p>Regarding the claim (see the first post in vector search series) that keeping cold S3 Vectors data costs much less than keeping cold vector indexes in OpenSearch: that’s obviously true, but these savings apply to cold vector data only and could be done with standard S3 APIs: store vector indexes in Parquet files on flash-based S3 storage instead of, or <em>in addition to</em>, using a non-serverless vector database service like OpenSearch or Qdrant.</p>

<p>If we want to stick to the AWS approach, we can store S3 Vectors’ “non-filterable metadata” as objects in regular S3 buckets. If we store non-filterable data in regular S3 buckets, we can access it with standard S3 clients and to make that easier, we can emulate the same S3 Vectors API. Now you may think: “you can access non-filterable data in S3 Vectors with standard S3 clients, too”, but I think that’s not the same:</p>

<ul>
  <li>S3 Vectors: S3 clients need to specifically store, and request, non-filterable metadata (maybe at a higher price compared to standard S3 storage, too). It’s an AWS S3 Vectors-only API.</li>
  <li>Regular S3 API: if you don’t code your application to AWS S3 Vectors API, you would use standard AWS S3 API and can get that extended data as any other S3 object. This works anywhere - StorageGRID, GCP Cloud Storage, Versity, etc.</li>
</ul>

<p>And this is even without trying to emulate AWS S3 Vectors API for “non-filterable metadata”, which is another option (I didn’t emulate that option in my PoC, because it seems like Amazon’s workaround, rather than something we should follow).</p>

<p>Regarding AWS S3 Vector service limits: they can be found <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-vectors-limitations.html">here</a>, if you’re curious. With a DIY approach you could easily work around all of them by changing whatever “limit” bothered you.</p>

<p>With AWS S3 Vectors you not only have to work within those limits, but also have to worry about OpenSearch limits (as long as they won’t let you export vector data elsewhere). Of course, you can read S3 Vectors directly and do it by yourself, but that’s exactly what I’ve been arguing for in these posts.</p>

<h3 id="versity-s3-gateway-and-beegfs-options">Versity S3 Gateway and BeeGFS options</h3>

<p>With Versity S3 Gateway on BeeGFS I can read and write that “metadata blob” (S3 Vectors’ “non-filterable metadata”) on file-system level - without ever downloading it over HTTPS.</p>

<p>If you wan <em>fast</em> access to vector data, GDS reads on BeeGFS are likely to be faster than OpenSearch or ElasticSearch.</p>

<p>Also with Versity S3 Gateway: we could use the BeeGFS file-system notifications feature explored in recent posts and trigger indexing, segmentation and embeddings for S3 PUTs on BeeGFS file-system level while completely avoid using S3 Vectors-like approach.</p>

<ul>
  <li>S3 PUT triggers BeeGFS file-system notification</li>
  <li>Job reads object metadata and tags from Versity S3 Gateway API, but the object itself is accessed via GDS/BeeGFS</li>
  <li>Indexes can be created in a database, or as Parquet files, etc.</li>
</ul>

<p>From the Versity S3 Gateway/BeeGFS <a href="/2025/06/22/data-pipeline-with-beegfs-file-system-notifications-and-versity-s3-gateway.html">post</a> related to anti-virus scanning:</p>

<p><img src="/assets/images/versity-s3-gw-av-scanner-dual-event-pipeline.png" alt="Vector indexing with Versity S3 GW and BeeGFS" /></p>

<p>If we replace “gRPC-driven AV scanning” with “gRPC-driven embeddings with Faiss”, we may be 90% done for your purpose). Look ma, no additional services!</p>

<h2 id="conclusion">Conclusion</h2>

<p>In Part 1 I talked about the struggling AWS S3 and the supposed need for various “solutions” or “stacks” that we see in AWS S3 Vectors (S3-side, cold vector search) and on-premises S3 storage-tethered database-side (hot vector search).</p>

<p>There’s <em>some</em> value in that, but these seem to be wrong:</p>

<ul>
  <li>AWS S3 Vectors: workarounds around S3 limitations and established vector database vendors’ defensive licenses</li>
  <li>On-premises S3 storage: technically bad over-reaction after years of “ignorance is bliss”</li>
</ul>

<p>As you can see from this post, I don’t think S3 users should automatically follow the S3 Vectors approach on S3 API-side, or buy an object store-tethered “solution” from their on-premises S3 storage vendor.</p>

<p>Both of these approaches leave a lot to be desired.</p>

<p>If vector search (and S3 search in general) is important, you should do it yourself and do it well. I wouldn’t tether it to storage or unnecessarily compromise.</p>

<p>It’s one of those potentially high-value services that aren’t hard to get right.</p>

<h2 id="appendix-a-s3-go-nats-screenshots">Appendix A: S3-GO-NATS screenshots</h2>

<p>You may open these in a new tab or window.</p>

<p>The first shows S3 Go NATS in action: events are coming in through Webhook service, they land to a bucket-specific “topic”, dispatcher service reads them and sends them to a “job queue topic” where watcher service decides processes them accordingly (as per the first diagram in this post).</p>

<p><img src="/assets/images/s3-go-nats-elasticsearch-9-01.png" alt="S3 Go NATS in action" /></p>

<p>I chose to use ElasticSearch - which is roughly comparable to the sole AWS S3 Vectors’ export target (AWS OpenSearch Service).</p>

<p>This screenshot shows a regular ElasticSearch search index (<code class="language-plaintext highlighter-rouge">&lt;bucket&gt;_search</code>).</p>

<p><img src="/assets/images/s3-go-nats-elasticsearch-9-02-search.png" alt="S3 Go NATS in action" /></p>

<p>This screenshot shows a vector index, named <code class="language-plaintext highlighter-rouge">&lt;bucket&gt;_vector</code>.</p>

<p><img src="/assets/images/s3-go-nats-elasticsearch-9-03-vectors.png" alt="S3 Go NATS in action" /></p>

<p>I’ve since added <code class="language-plaintext highlighter-rouge">bucket_name</code> to index fields and a configuration option (default: off) to add S3 metadata and tags in this index. That is off by default as I don’t want to bloat this already bloated index.</p>

<p>But if someone’s use case involves searching both indexes, including S3 metadata and tags to it may be worth it.</p>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#storage">storage</a>
      &nbsp; 
    
      <a href="
      /categories/#ai">ai</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2025/07/18/s3-vector-search-01-analysis.html">S3 vector search - DIY vs AWS S3 Vectors</a></li>
      
        <li><a href="/2023/07/20/storagegrid-and-elaticsearches.html">StorageGRID and Elasticsearches</a></li>
      
        <li><a href="/2025/05/17/beegfs-v8-netapp-e-series-indexing-tiering-workflows.html">ThinkParQ BeeGFS v8 with NetApp E-Series</a></li>
      
        <li><a href="/2023/08/01/fscrawler-filesystem-analytics-elasticsearch.html">FSCrawler for basic filesystem analytics in Elasticsearch</a></li>
      
        <li><a href="/2021/02/27/storagegrid-s3-as-vertica-communal-storage.html">NetApp StorageGRID object store for Vertica EON Mode</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2025-07-23 17:50 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
