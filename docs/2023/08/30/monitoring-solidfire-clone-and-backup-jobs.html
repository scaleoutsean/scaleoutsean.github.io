<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Use SolidFire API to monitor clone and backup jobs for profit and pleasure | Acting Technologist
      
    </title>
    <meta name="description" content="
     Use SolidFire ListSyncJobs and ListBulkVolumeJobs to monitor clone and backup jobs
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Use SolidFire API to monitor clone and backup jobs for profit and pleasure | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Use SolidFire API to monitor clone and backup jobs for profit and pleasure" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en" />
<meta name="description" content="Use SolidFire ListSyncJobs and ListBulkVolumeJobs to monitor clone and backup jobs" />
<meta property="og:description" content="Use SolidFire ListSyncJobs and ListBulkVolumeJobs to monitor clone and backup jobs" />
<link rel="canonical" href="https://scaleoutsean.github.io/2023/08/30/monitoring-solidfire-clone-and-backup-jobs.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2023/08/30/monitoring-solidfire-clone-and-backup-jobs.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-08-30T00:00:00+08:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2023/08/30/monitoring-solidfire-clone-and-backup-jobs.html"},"author":{"@type":"Person","name":"scaleoutSean"},"description":"Use SolidFire ListSyncJobs and ListBulkVolumeJobs to monitor clone and backup jobs","@type":"BlogPosting","url":"https://scaleoutsean.github.io/2023/08/30/monitoring-solidfire-clone-and-backup-jobs.html","headline":"Use SolidFire API to monitor clone and backup jobs for profit and pleasure","dateModified":"2023-08-30T00:00:00+08:00","datePublished":"2023-08-30T00:00:00+08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Use SolidFire API to monitor clone and backup jobs for profit and pleasure</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>30 Aug 2023</span> - <i class="far fa-clock"></i> 


  
  
    16 minute read
  

    </span>
  </div>
  
        <ul>
  <li><a href="#problem">Problem</a></li>
  <li><a href="#api-methods">API methods</a>
    <ul>
      <li><a href="#finding-solidfire-api-limits">Finding SolidFire API limits</a></li>
      <li><a href="#clone-jobs">Clone jobs</a>
        <ul>
          <li><a href="#slice-sync-jobs">Slice sync jobs</a></li>
          <li><a href="#clone-sync-jobs">Clone sync jobs</a></li>
          <li><a href="#remote-sync-jobs">Remote sync jobs</a></li>
        </ul>
      </li>
      <li><a href="#bulk-backup-restore-jobs">Bulk (backup, restore) jobs</a></li>
    </ul>
  </li>
  <li><a href="#opportunities-for-improvements-and-integrations">Opportunities for improvements and integrations</a>
    <ul>
      <li><a href="#faster-access-to-volume-clones">Faster access to volume clones</a></li>
      <li><a href="#faster-multiple-clones-from-a-single-volume">Faster multiple clones from a single volume</a></li>
      <li><a href="#auto-adjust-qos-on-volumes-involved-in-bulk-jobs">Auto-adjust QoS on volumes involved in bulk jobs</a></li>
      <li><a href="#get-available-bulk-job-slots">Get available bulk job slots</a></li>
      <li><a href="#monitoring-and-resubmission-of-bulk-jobs">Monitoring and resubmission of bulk jobs</a></li>
    </ul>
  </li>
  <li><a href="#note-on-async-job-results">Note on async job results</a></li>
  <li><a href="#demo">Demo</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="problem">Problem</h2>

<p>Not many scripts for the SolidFire API have been published on Github since NetApp acquired SolidFire, but I’ve always wished there were some clever examples of the use of certain API methods that are reasonably popular, but may be hard for beginners.</p>

<p>I mean mostly API calls related to backup/restore to S3 and clone.</p>

<p>Over the years I wrote several scripts and even entire (small) workflows that use these - whether it’s parallel backup to S3 or volume cloning-based backup - and published them on Github.</p>

<p>But while the code more or less worked, it wasn’t pretty and easy to use. At the same time, I don’t get any queries for it, so it’s not something that I may necessarily revisit (as far as scripts are concerned).</p>

<p>Still, I’ve found some time to revisit the APIs involved, so I’ll use some time to summarize that and maybe get to write some code in the future.</p>

<h2 id="api-methods">API methods</h2>

<h3 id="finding-solidfire-api-limits">Finding SolidFire API limits</h3>

<p>As we use the API we need to mind the limits.</p>

<p>When you login with PowerShell you’ll see them right there. Or use <code class="language-plaintext highlighter-rouge">Get-SFLimits</code> (PowerShell). Relevant limits for SolidFire Demo VM:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">/home/sean</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-SFLimits</span><span class="w">
</span><span class="o">...</span><span class="w">
</span><span class="n">BulkVolumeJobsPerNodeMax</span><span class="w">               </span><span class="p">:</span><span class="w"> </span><span class="nx">10</span><span class="w">
</span><span class="n">BulkVolumeJobsPerVolumeMax</span><span class="w">             </span><span class="p">:</span><span class="w"> </span><span class="nx">10</span><span class="w">
</span><span class="n">CloneJobsPerVolumeMax</span><span class="w">                  </span><span class="p">:</span><span class="w"> </span><span class="nx">1</span><span class="w">
</span><span class="o">...</span><span class="w">
</span></code></pre></div></div>

<h3 id="clone-jobs">Clone jobs</h3>

<p>The SolidFire API calls these “sync jobs”. As we can see from TFM, <a href="https://docs.netapp.com/us-en/element-software/api/reference_element_api_listsyncjobs.html">ListSyncJobs</a> can spit out different kinds of sync jobs.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="w">
    </span><span class="nl">"result"</span><span class="p">:{</span><span class="w">
      </span><span class="nl">"syncJobs"</span><span class="p">:[</span><span class="w">
        </span><span class="p">{</span><span class="w">
           </span><span class="nl">"bytesPerSecond"</span><span class="p">:</span><span class="mf">275314.8834458956</span><span class="p">,</span><span class="w">
           </span><span class="nl">"currentBytes"</span><span class="p">:</span><span class="mi">178257920</span><span class="p">,</span><span class="w">
           </span><span class="nl">"dstServiceID"</span><span class="p">:</span><span class="mi">36</span><span class="p">,</span><span class="w">
           </span><span class="nl">"elapsedTime"</span><span class="p">:</span><span class="mf">289.4568382049871</span><span class="p">,</span><span class="w">
           </span><span class="nl">"percentComplete"</span><span class="p">:</span><span class="mf">8.900523560209423</span><span class="p">,</span><span class="w">
           </span><span class="nl">"remainingTime"</span><span class="p">:</span><span class="mf">2962.675921065957</span><span class="p">,</span><span class="w">
           </span><span class="nl">"sliceID"</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span><span class="w">
           </span><span class="nl">"srcServiceID"</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span><span class="w">
           </span><span class="nl">"stage"</span><span class="p">:</span><span class="s2">"whole"</span><span class="p">,</span><span class="w">
           </span><span class="nl">"totalBytes"</span><span class="p">:</span><span class="mi">2002780160</span><span class="p">,</span><span class="w">
           </span><span class="nl">"type"</span><span class="p">:</span><span class="s2">"slice"</span><span class="w">
       </span><span class="p">},</span><span class="w">
       </span><span class="p">{</span><span class="w">
           </span><span class="nl">"bytesPerSecond"</span><span class="p">:</span><span class="mf">305461.3198607744</span><span class="p">,</span><span class="w">
           </span><span class="nl">"cloneID"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="w">
           </span><span class="nl">"currentBytes"</span><span class="p">:</span><span class="mi">81788928</span><span class="p">,</span><span class="w">
           </span><span class="nl">"dstServiceID"</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span><span class="w">
           </span><span class="nl">"dstVolumeID"</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span><span class="w">
           </span><span class="nl">"elapsedTime"</span><span class="p">:</span><span class="mf">291.7847648200743</span><span class="p">,</span><span class="w">
           </span><span class="nl">"nodeID"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="w">
           </span><span class="nl">"percentComplete"</span><span class="p">:</span><span class="mf">8.167539267015707</span><span class="p">,</span><span class="w">
           </span><span class="nl">"remainingTime"</span><span class="p">:</span><span class="mf">3280.708270981153</span><span class="p">,</span><span class="w">
           </span><span class="nl">"sliceID"</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span><span class="w">
           </span><span class="nl">"srcServiceID"</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span><span class="w">
           </span><span class="nl">"srcVolumeID"</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span><span class="w">
           </span><span class="nl">"stage"</span><span class="p">:</span><span class="s2">"whole"</span><span class="p">,</span><span class="w">
           </span><span class="nl">"totalBytes"</span><span class="p">:</span><span class="mi">1001390080</span><span class="p">,</span><span class="w">
           </span><span class="nl">"type"</span><span class="p">:</span><span class="s2">"clone"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
           </span><span class="nl">"blocksPerSecond"</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="w">
           </span><span class="nl">"branchType"</span><span class="p">:</span><span class="w"> </span><span class="s2">"snapshot"</span><span class="p">,</span><span class="w">
           </span><span class="nl">"dstServiceID"</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span><span class="w">
           </span><span class="nl">"dstVolumeID"</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="w">
           </span><span class="nl">"elapsedTime"</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="w">
           </span><span class="nl">"percentComplete"</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="w">
           </span><span class="nl">"remainingTime"</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="w">
           </span><span class="nl">"sliceID"</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="w">
           </span><span class="nl">"stage"</span><span class="p">:</span><span class="s2">"metadata"</span><span class="p">,</span><span class="w">
           </span><span class="nl">"type"</span><span class="p">:</span><span class="s2">"remote"</span><span class="w">
       </span><span class="p">}</span><span class="w">
     </span><span class="p">]</span><span class="w">
   </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>
<h4 id="slice-sync-jobs">Slice sync jobs</h4>

<p>Slice is volume metadata.</p>

<p>I’m not sure why slice service would be singled out like this. I am not aware of a way to directly initiate a slice sync job.</p>

<p>My guess is this type of sync jobs happen automatically in situations like Disk 0 failure on a node, cluster expansion or reduction, in-cluster workload rebalancing (volume flipping), and such.</p>

<p>While this may be interesting to some monitoring use cases, it’s usually enough to watch for SolidFire alerts which tell you when there’s something to do and go away when/if the problem goes away.</p>

<p>As an example, a slice sync job may be running for a while after a node has been added to the cluster and some volumes are automatically moved to the new node, as well as backup slice data is replicated (synced) to it. But there’s nothing we need to do about it - slice data sync will complete and the system alert will automatically disappear.</p>

<h4 id="clone-sync-jobs">Clone sync jobs</h4>

<p>This one is interesting and should help us watch the progress of volume clone jobs.</p>

<p>Comments on some of the keys:</p>

<ul>
  <li>bytesPerSecond: can help us estimate time-to-completion, although remainingTime (below) is already calculated for us</li>
  <li>dstVolumeID: new volume ID, can help us set a different QoS on it later or use that volume ID for other purposes</li>
  <li>percentComplete: can be sent to some database for monitoring purposes</li>
  <li>remainingTime: just an estimate, which may be more precise than our own estimate</li>
  <li><code class="language-plaintext highlighter-rouge">"type":"clone"</code> - we’d look for this to get a list of all clone job objects</li>
</ul>

<h4 id="remote-sync-jobs">Remote sync jobs</h4>

<p>Remote sync jobs likely involve volume or snapshot replication to a remote SolidFire cluster, which doesn’t interest me that much.</p>

<p>It is useful, of course, especially in DR scenarios where there’s no 3rd party code to do that for you (such as vSphere SRA). But even if you need to failover, you can check a volume’s status to see if it’s in sync or not - it’s not necessary to look at the progress just for that. Then if a volume is in sync, we can break replication, make the destination read-write, and fail over.</p>

<h3 id="bulk-backup-restore-jobs">Bulk (backup, restore) jobs</h3>

<p><a href="https://docs.netapp.com/us-en/element-software/api/reference_element_api_listbulkvolumejobs.html">ListBulkVolumeJobs</a> coughs up information about bulk volume read or write operations.</p>

<p>Those are mainly backup and restore jobs (I don’t know of any other kind). bulkVolumeJobs is a list, here with just one element.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
    </span><span class="nl">"result"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"bulkVolumeJobs"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
            </span><span class="p">{</span><span class="w">
                </span><span class="nl">"attributes"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
                    </span><span class="nl">"blocksPerTransfer"</span><span class="p">:</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"firstPendingLba"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"nLbas"</span><span class="p">:</span><span class="w"> </span><span class="mi">244140</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"nextLba"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"pendingLbas"</span><span class="p">:</span><span class="w"> </span><span class="s2">"[]"</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"percentComplete"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"startLba"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w">
                </span><span class="p">},</span><span class="w">
                </span><span class="nl">"bulkVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">25</span><span class="p">,</span><span class="w">
                </span><span class="nl">"createTime"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2023-09-02T15:15:32Z"</span><span class="p">,</span><span class="w">
                </span><span class="nl">"elapsedTime"</span><span class="p">:</span><span class="w"> </span><span class="mi">11</span><span class="p">,</span><span class="w">
                </span><span class="nl">"format"</span><span class="p">:</span><span class="w"> </span><span class="s2">"native"</span><span class="p">,</span><span class="w">
                </span><span class="nl">"key"</span><span class="p">:</span><span class="w"> </span><span class="s2">"f5075f5a4e23e108484492b0492409e3"</span><span class="p">,</span><span class="w">
                </span><span class="nl">"percentComplete"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
                </span><span class="nl">"remainingTime"</span><span class="p">:</span><span class="w"> </span><span class="mi">1089</span><span class="p">,</span><span class="w">
                </span><span class="nl">"script"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bv_internal.py"</span><span class="p">,</span><span class="w">
                </span><span class="nl">"srcVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">27</span><span class="p">,</span><span class="w">
                </span><span class="nl">"status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"running"</span><span class="p">,</span><span class="w">
                </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"read"</span><span class="w">
            </span><span class="p">}</span><span class="w">
        </span><span class="p">]</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>What do we have here?</p>

<ul>
  <li>bulkVolumeID: auto-incrementing counter for bulk jobs (25th job since this cluster was created)</li>
  <li><code class="language-plaintext highlighter-rouge">"format": "native"</code>: compressed and in-volume deduplicated data, rather than “uncompressed” (produced by raw “dd”-like reads which is another option which creates extremely bloated backups of the same size as the volume itself, including zeroed out empty space - this is for maximum portability to any destination)</li>
  <li>key: this is key that returned for async job tracking when we create a job</li>
  <li>percentComplete: self-explanatory</li>
  <li>remainingTime: (estimated) time remaining in seconds</li>
  <li>snapshotID: when backup is done on a volume snapshot, this will be a non-zero integer of the snapshot ID</li>
  <li>srcVolumeID: source volume ID (could be derived from snapshot ID, but it would take an extra call, so it’s sometimes convenient to know if even if we’re backing up from snapshot)</li>
  <li>status: running (the <a href="https://github.com/NetAppDocs/element-software/issues/206">sloppily written documentation doesn’t even list that one</a>)</li>
  <li>type: read (read means backup, write means restore)</li>
</ul>

<h2 id="opportunities-for-improvements-and-integrations">Opportunities for improvements and integrations</h2>

<p>These are some use cases or integrations I couldn’t or didn’t do myself that I’d like to see made available in permissive open source scripts.</p>

<h3 id="faster-access-to-volume-clones">Faster access to volume clones</h3>

<p>One ask I’ve heard, but not from customers I worked with (otherwise I would have tried to find out more and solve it) is the time gap between cloning a volume and using it.</p>

<p>Now, SolidFire metadata is in a slice database file, so clones can’t be instant. It takes time to copy the slice file and clone jobs are asynchronous.</p>

<p>As we can see from that second ListSyncJobs item, there may be ways to use that API method to make our workflows smarter.</p>

<p>Whether that’s actually possible or not, it depends. Let’s say we have 4 SolidFire nodes and 20 volumes to clone. Lets say the maximum clone jobs per node is two.</p>

<ul>
  <li>a naive approach would be to run clone jobs in batches of two: run two, wait until they’re done (or worse, “sleep” for a generic amount of time such as 600 seconds), then run next two</li>
  <li>a smarter approach would be to find the number of jobs running on the node and dispatch the next job - if any - that we know would land on this node (how do we know that? We find where the volume would is Primary; see the source of scripts I mention, or other posts on this topic)</li>
  <li>there’s a feature that lets you <a href="https://docs.netapp.com/us-en/element-software/storage/task_data_protection_clone_multiple_volumes.html">clone multiple volumes</a>; not sure how this works - I wonder what the maximum number of volumes that ca be selected is, and whether the scheduler is “smart”</li>
  <li>CopyVolume API method lets you simplify other operations, although it doesn’t make volume cloning operation itself faster (see below)</li>
  <li>if we keep an eye on percentComplete of clone jobs, we can minimize generic wait situations (“sleep 600”) and chain operations together</li>
</ul>

<p>By the way, I tried the clone multiple volumes feature: it works fine but only up to 10 volumes at a time!</p>

<p><img src="/assets/images/solidfire-clone-volumes-group.png" alt="SolidFire clone multiple volumes feature" /></p>

<p>Note the error says “snapshots”, which I’m sure is a bug because technically yes, temporary snapshots are taken in order to clone volumes, but I wasn’t cloning snapshots. Anyway, no more than 10 at a time on my SolidFire Demo VM. The limit may be different on real SolidFire multi-node clusters.</p>

<p>Another weird detail is that <a href="https://docs.netapp.com/us-en/element-software/api/reference_element_api_clonemultiplevolumes.html">CloneMultipleVolumes</a> is a thing… I had no idea (or maybe I’d forgotten). For the sake of completeness, here’s what it returns:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
  </span><span class="nl">"result"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"asyncHandle"</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span><span class="w">
    </span><span class="nl">"groupCloneID"</span><span class="p">:</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w">
    </span><span class="nl">"members"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
     </span><span class="p">{</span><span class="w">
      </span><span class="nl">"srcVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w">
      </span><span class="nl">"volumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">29</span><span class="w">
     </span><span class="p">},</span><span class="w">
     </span><span class="p">{</span><span class="w">
      </span><span class="nl">"srcVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">18</span><span class="p">,</span><span class="w">
      </span><span class="nl">"volumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">30</span><span class="w">
     </span><span class="p">},</span><span class="w">
     </span><span class="p">{</span><span class="w">
      </span><span class="nl">"srcVolumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="p">,</span><span class="w">
      </span><span class="nl">"volumeID"</span><span class="p">:</span><span class="w"> </span><span class="mi">31</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Although there’s a 10 volume limit (on my Demo VM; it may be higher on actual production clusters), this is less naive than creating clones one by one.</p>

<p>But its benefit is mostly related to saving time required to issue clone requests (as the alternative is to issue multiple individual requests to clone a volume). I wonder if the 10 volume limit is such because that’s the worst case for this API method (10 clone jobs could land all on the same storage node). Too bad there’s no option to clone one volume 10 times.</p>

<h3 id="faster-multiple-clones-from-a-single-volume">Faster multiple clones from a single volume</h3>

<p>Another situation is where there’s one volume that needs to be cloned many (e.g. 20) times.</p>

<p>On my Demo VM that limit is very low: CloneJobsPerVolumeMax is 1. It seems it’d take a loop that runs 20 times to get 20 clones from a “gold” volume with source code!</p>

<p>We know that’s not true, though.</p>

<ul>
  <li>there’s <a href="https://docs.netapp.com/us-en/element-software/api/reference_element_api_copyvolume.html">CopyVolume</a> which I use in SolidBackup: if the 20 clones don’t have to be destroyed, then they can be dismounted and copied into from the gold volume. Workload-wise it’s still 20 full clone operations, but there’s less to do in general, including client-side (no need to rescan iSCSI and login, you can simply mount the clone)</li>
  <li>on production systems the limit is not one concurrent clone, so we can clone 1 to 1, then 2 to 2 (running total 2), then 4 to 4 (running total 8), etc. until we reach 10 clones</li>
  <li>once we get to 10 clones, we can use CloneMultipleVolumes to clone those 10 to 20</li>
  <li>we could use other methods such as client-side copy: create 20 empty volumes, mount all 21, then initiate 20 rsync jobs to copy data from 1 to 20 volumes. These wouldn’t be exact byte-for-byte clones, but they’d be sufficiently alike for most software applications</li>
  <li>when volume or host performance isn’t a concern, we can use client-side software to clone data without doing anything on SolidFire</li>
</ul>

<p>Some of these approaches (CopyVolume, for example) would be useful for large volumes with many files, because filesystem-side copying could take longer. Example: Android source code can take <a href="https://source.android.com/docs/setup/start/requirements">250 GB</a> of disk space (for starters):</p>

<blockquote>
  <p>At least 250GB of free disk space to check out the code and an extra 150 GB to build it.</p>
</blockquote>

<p>In other cases - many small volumes with low performance - it may be better to use ZFS because you still get deduplication on SolidFire, but fast volume cloning due to it being a simple local command on the iSCSI client. Example: Web development, containers.</p>

<p>We can’t know which approach would be significantly better and whether implementing it would make sense, but it is possible to do a PoC and see for ourselves.</p>

<p><strong>Update</strong> (2023/09/16)</p>

<p>I found some time to download a recent copy of the Android source code to a 400GB SolidFire volume.</p>

<p><img src="/assets/images/solidfire-clone-01-dir-list.png" alt="Directory listing of Android source code" /></p>

<p>Then I used PoweShell cmdlets to clone it.</p>

<p><img src="/assets/images/solidfire-clone-02-clone-job.png" alt="Clone job on volume with 143GiB data" /></p>

<p>Here’s how long it took.</p>

<p><img src="/assets/images/solidfire-clone-03-clone-job.png" alt="Clone job details" /></p>

<p>You may open images in another tab (or see a demo at the bottom), but if you can’t see it clearly as-is:</p>
<ul>
  <li>Begin: 04:30:07</li>
  <li>Finish: 04:30:14</li>
</ul>

<p>So, it takes around 10 seconds to clone 150G of in-volume data.</p>

<p>On this (physical) SolidFire system we could expect something like:</p>

<ul>
  <li>1 to 1: 8s</li>
  <li>2 to 2: 8s</li>
  <li>4 to 4: 8s</li>
  <li>TOTAL: 8 clones in &lt;30s</li>
</ul>

<p>Also consider that first build jobs could start in 15-20s as several clones would be ready.</p>

<h3 id="auto-adjust-qos-on-volumes-involved-in-bulk-jobs">Auto-adjust QoS on volumes involved in bulk jobs</h3>

<ul>
  <li>Implement a higher Max QoS while remembering original QoS values</li>
  <li>Restore original QoS values after percentComplete for bulk job (backup or restore) hits 100%</li>
</ul>

<p>The script was written <a href="/2020/11/28/powershell-set-sfqosexception.html">in 2020</a>, but could be included in sophisticated backup/restore scripts.</p>

<h3 id="get-available-bulk-job-slots">Get available bulk job slots</h3>

<p>In the “backup to S3” scripts I wrote I watch the total number of bulk jobs per node, which is the main constraint that lets me maximize the use of bulk job slots.</p>

<p>It would be nice to have a way to get “bulk job slots available” per node. With that it would be very easy to write backup jobs in own language or using own tool, and just use the slot information to find out when to fire the next job.</p>

<p>Because a SolidFire volume may or may not be Primary on the node where there’s an empty bulk job slot, this API would be called with VolumeID and would determine the node on which the volume is Primary, and then check if the maximum number of job slots minus the number of jobs running is larger than zero.</p>

<h3 id="monitoring-and-resubmission-of-bulk-jobs">Monitoring and resubmission of bulk jobs</h3>

<p>When we backup hundreds of volumes every day, some jobs are expected to time out or otherwise fail.</p>

<p>In my “backup-to-S3” scripts I think I only reported failed jobs at the end, but haven’t retried any. The reason is it’s tricky (how many times, for how long, etc.) and best left to professional software or professional programmers.</p>

<p>We could send job details and status updates to a place where such data could be used. Something like Elasticsearch, for example. Or we could query job status and save output as JSON files, leaving it for pickup to anyone who wants it. Then Operations could create service requests or retry on their own.</p>

<p>Retrying and rescheduling is tricky for many reasons, but also notice that a mere list of volume IDs (17, 28, 128) doesn’t have anything about which volume backup jobs should be retried, which should not, and so on.</p>

<p>We’d need a detailed backup job description format which specifies which volume IDs or groups should be retried, how many times, and for how long. And we’d also need a database to keep that data, and a way to update it without directly editing the file.</p>

<p>It’s easy to see how things get complicated quickly - some users would want to retry 3 times before 8am in <em>their</em> time zone, other 3 times the same day (local, not UTC, time!), etc. It seems smarter to just give up and let those with simple requirements write their own scripts!</p>

<p>I know there are open source schedule modules that can “solve” that, but I don’t think that solution would be intelligent out of the box: it would still require a lot of work to make it useful.</p>

<p>Job logging and monitoring would be reasonable things to to automate.</p>

<p>And it’s not hard, because I wrote a <a href="/2021/10/18/solidfire-syslog-filebeat-logstash-elk-stack.html">how-to</a> which is 80% of the recipe; we’d just have to create a polled API method based on ListBulkVolumeJobs. <a href="https://docs.netapp.com/us-en/element-software/api/reference_element_api_startbulkvolumeread.html">StartBulkVolumeRead</a> request - which has job params - would have to be sent to Elasticsearch so that we can correlate jobs with job updates from ListBulkVolumeJobs. <a href="https://docs.netapp.com/us-en/element-software/api/reference_element_api_updatebulkvolumestatus.html">UpdateBulkVolumeStatus</a> may need to be used to fetch to get final results, although I don’t recall I had to use this method.</p>

<p>Another approach would be to use SolidFire syslog (see that ELK how-to) to spot StartBulkVolumeRead requests in API logs, and then kick-off ListBulkVolumeJobs to keep an eye on them. Failed jobs could also be detected from API calls in syslog. An advantage of this approach is we can run our scripts without caring about sending script logs to Elasticsearch, but a disadvantage is we have to forward SolidFire log to Elasticsearch. Having a script that sends logs to Elasticsearch seems a bit more flexible, especially since it’s easy to modify it to be sent to another location if need be.</p>

<h2 id="note-on-async-job-results">Note on async job results</h2>

<p>I mention this in all API-related posts because it’s one of those frustrating gotchas: use <code class="language-plaintext highlighter-rouge">keepResult=true</code> in <a href="https://docs.netapp.com/us-en/element-software/api/reference_element_api_getasyncresult.html">GetAsyncResult</a> to keep the asynchronous result.</p>

<p>Otherwise, if a job finishes and you query it by the handle, you may get nothing in return.</p>

<p>I use that option in the first query immediately after the job has started. Then the next time I revisit same async handle, the result will still be available.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"method"</span><span class="p">:</span><span class="w"> </span><span class="s2">"GetAsyncResult"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"params"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"asyncHandle"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="mi">389</span><span class="p">,</span><span class="w">
      </span><span class="nl">"keepResult"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
</span><span class="p">},</span><span class="w">
</span><span class="nl">"id"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="demo">Demo</h2>

<ul>
  <li><a href="https://rumble.com/v3i2s18-solidfire-volume-clone-demo.html">Short demo of creating a clone from a volume with the Android source code</a> - 1m27s</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>As far as open source scripts that take advantage of clone and backup/restore APIs are concerned, there’s still some uncollected “low-hanging fruit” out there.</p>

<p>Rapid 1-to-1 and 1-to-many cloning is interesting, but it’s hard to build something random and say it’s useful. I’d like to have a concrete problem to solve before I try.</p>

<p>On the other hand, the problem with “backup to S3” in SolidFire is that (as I recently <a href="/2023/08/26/solidfire-backup-to-ontap-s3.html">wrote</a>) it hasn’t been improved, so if you want to backup to S3 it’s better to try something like SolidBackup or 3rd party (free or commercial) client-side backup software than the SolidFire backup-to-S3. The appeal of “backup to S3” is that as long as you have SolidFire and largely uniform and simple backup requirements, you’re a potential user of the feature.</p>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#solidfire">solidfire</a>
      &nbsp; 
    
      <a href="
      /categories/#automation">automation</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2023/10/05/snapshots-and-consistency-groups-with-netapp-e-series.html">Stand-alone and Consistency Group snapshots on NetApp E-Series</a></li>
      
        <li><a href="/2022/01/01/getting-solidfire-volume-details-python-powershell-api-cli.html">Getting SolidFire volume details with Powershell and Python</a></li>
      
        <li><a href="/2020/12/08/get-bearer-token-for-netapp-hci-hybrid-cloud-control-logs.html">Get NetApp Hybrid Cloud Control logs via the HCC API</a></li>
      
        <li><a href="/2021/06/22/solidfire-backup-and-cloning-with-per-storage-node-queues.html">Maximum parallelization of SolidFire Backup and Volume Copy/Clone jobs</a></li>
      
        <li><a href="/2023/04/01/using-solidfire-snapshot-attributes.html">Using snapshot attributes in SolidFire</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2025-07-30 20:26 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
