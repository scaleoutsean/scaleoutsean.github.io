<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Basic notes on h2o GPT from a storage perspective | Acting Technologist
      
    </title>
    <meta name="description" content="
     Very basic look at h2oGPT from a storage perspective
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Basic notes on h2o GPT from a storage perspective | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Basic notes on h2o GPT from a storage perspective" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en" />
<meta name="description" content="Very basic look at h2oGPT from a storage perspective" />
<meta property="og:description" content="Very basic look at h2oGPT from a storage perspective" />
<link rel="canonical" href="https://scaleoutsean.github.io/2023/08/04/h2o-storage-notes-h2ogpt.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2023/08/04/h2o-storage-notes-h2ogpt.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-08-04T00:00:00+08:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2023/08/04/h2o-storage-notes-h2ogpt.html"},"author":{"@type":"Person","name":"scaleoutSean"},"description":"Very basic look at h2oGPT from a storage perspective","@type":"BlogPosting","url":"https://scaleoutsean.github.io/2023/08/04/h2o-storage-notes-h2ogpt.html","headline":"Basic notes on h2o GPT from a storage perspective","dateModified":"2023-08-04T00:00:00+08:00","datePublished":"2023-08-04T00:00:00+08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Basic notes on h2o GPT from a storage perspective</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>04 Aug 2023</span> - <i class="far fa-clock"></i> 


  
  
    5 minute read
  

    </span>
  </div>
  
        <p>So… I don’t use Generative AI.</p>

<p>I used it a bit before it was popular (before ChatGPT 4.0 came out) to automate SolidFire CLI, saw how it works, and while it was interesting I didn’t see immediate use cases for it in my life.</p>

<p>Now Generative AIs are much more capable, but I still have no use for them.</p>

<p>I’ve been thinking about using them to assist me with PowerShell or Python scripts, but I still think it’s more valuable to spend some time on search engines and Stack Overflow and learn something in the process.</p>

<p>Still, that’s not to say Generative AIs are useless. I do follow the field fairly closely for an automation/storage guy, because there’s some chance I might use it for log analytics and programming one day.</p>

<h2 id="h2ogpt">h2oGPT</h2>

<p>The <a href="https://docs.h2o.ai/">H2O docs page</a> show the current Generative AI portfolio includes h2oGPT (open source, on Github) and H2O LLM Studio (proprietary UI and workflows; haven’t tried it).</p>

<p>As expected, h2oGPT needs some data.</p>

<p><img src="/assets/images/h2o-h2ogpt-01.png" alt="Feed data" /></p>

<p>Then we ask it questions, and it responds.</p>

<p><img src="/assets/images/h2o-h2ogpt-02.png" alt="Transient pod fails after restart" /></p>

<p>It worked for basic Q&amp;A, as you can see above, but (using the default <code class="language-plaintext highlighter-rouge">llama</code> model).</p>

<h2 id="getting-data-in">Getting data in</h2>

<p>This is main thing I’m interested in.</p>

<p><a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/getting-data-into-h2o.html">The docs</a> have the theory.</p>
<ul>
  <li>Local file system (works through the browser, can use NFS, SMB, BeeGFS and other paths that the client can access)</li>
  <li>Remote file &amp; S3 (http(s) URL; it’s weird that there’s “Remote” when it really means S3, but then there’s Swift, which is why I guess they have “Remote” as a separate option; nobody uses Swift, though… They should just call it Object Store.)</li>
  <li>HDFS data sources (including Alluxio about which I blogged before in the context of StorageGRID and ONTAP (S3) and ONTAP (NFS))</li>
</ul>

<p>This is how upload looks like from the Web UI in practice:</p>
<ul>
  <li>URL (for S3 I assume), or</li>
  <li>Paste text of own choosing (useful when you want to paste some text from a Web page), or</li>
  <li>Client-side upload (click on the area with “<code class="language-plaintext highlighter-rouge">- or -</code>”)</li>
</ul>

<p><img src="/assets/images/h2o-h2ogpt-03.png" alt="h2o document upload interface" /></p>

<p>Once a document has been uploaded, h2oGPT churns through it to learn from it. Multiple documents may be uploaded at once, but I haven’t tried it because it takes a while.</p>

<p><img src="/assets/images/h2o-h2ogpt-04-indexing.png" alt="h2o processing uploaded document" /></p>

<p>If you have a GPU and it’s enabled, it will get busy. It’s not just text indexing for full text search, as you might assume (<a href="/2023/08/01/fscrawler-filesystem-analytics-elasticsearch.html">incidentally</a>, I used that earlier this week) - GPU will be busy for a while.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fri Aug  4 10:50:51 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|<span class="o">=========================================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
|   0  NVIDIA GeForce RTX 2080 ...    Off | 00000000:2B:00.0  On |                  N/A |
| 30%   64C    P2             235W / 250W |   4245MiB /  8192MiB |     99%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|<span class="o">=======================================================================================</span>|
|    0   N/A  N/A    112270      C   python                                     3500MiB |
+---------------------------------------------------------------------------------------+
</code></pre></div></div>

<p>After digesting the <a href="https://docs.netapp.com/us-en/xcp/home.html">NetApp XCP</a> Reference Guide v1.9.2 (PDF) h2oGPT was able to answer a question about it: does XCP support NFS?</p>

<p><img src="/assets/images/h2o-h2ogpt-05-answer-based-on-xcp-reference-guide.png" alt="h2oGPT answers non-trivial question" /></p>

<p>Data is often imported with <a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/importing-data.html">scripts</a>, especially at scale required for Deep Learning, and that method is available as well. According to the H2O documentation, between 1,000 and 50,000 documents may be required for fine tuning of a model. So even if that’s the only thing that’s done in the environment, it may still be too much for doing it in the browser.</p>

<p>Starting with ONTAP 9.12.1, ONTAP has “multi-protocol S3” which lets us serve data from NFS or SMB shares using a subset of S3 APIs, which can come useful in organizations that ingest data via NFS or SMB but h2oGPT isn’t on the same network and cannot get to those shares via SMB or NFS. Such data shared over S3 can be downloaded via its S3 bucket/path URL without copying it to some intermediate system, or having a S3 gateway server (VM, container).</p>

<p>I have a brief demo of that <a href="https://rumble.com/v32fmic-brief-walk-through-over-ontap-native-and-multi-protocol-s3-services.html">here</a>.</p>

<h2 id="getting-data-out">Getting data out</h2>

<p>The docs give <a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/downloading-data.html">an example</a> of downloading data from the H2O cluster: saving model predictions for later.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">h2o</span>
<span class="n">h2o</span><span class="p">.</span><span class="nf">init</span><span class="p">()</span>
<span class="n">iris_hex</span> <span class="o">=</span> <span class="n">h2o</span><span class="p">.</span><span class="nf">import_file</span><span class="p">(</span><span class="sh">"</span><span class="s">http://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">h2o</span><span class="p">.</span><span class="nf">export_file</span><span class="p">(</span><span class="n">iris_hex</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/tmp/pred.csv</span><span class="sh">"</span><span class="p">,</span> <span class="n">force</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>

<p>I don’t know how one finds the URL to use, but I tried to wget the PDF file from the screenshot above, and it worked.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>wget http://localhost:7860/file//tmp/gradio/6c9784d309c6377a03591209500622c132ad6a29/192-Reference.pdf
<span class="nt">--2023-08-04</span> 11:06:44--  http://localhost:7860/file//tmp/gradio/6c9784d309c6377a03591209500622c132ad6a29/192-Reference.pdf
Resolving localhost <span class="o">(</span>localhost<span class="o">)</span>... 127.0.0.1
Connecting to localhost <span class="o">(</span>localhost<span class="o">)</span>|127.0.0.1|:7860... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3680392 <span class="o">(</span>3.5M<span class="o">)</span> <span class="o">[</span>application/pdf]
Saving to: ‘192-Reference.pdf’
...
</code></pre></div></div>

<p>I guess that’s how we find what we want to download. There’s a Document Selection tab where we can get that information easily.</p>

<p><img src="/assets/images/h2o-h2ogpt-06-document-collections.png" alt="h2oGPT document collection" /></p>

<h2 id="h2o-llm-studio">H2O LLM Studio</h2>

<p>H2O LLM Studio has additional data-related information.</p>

<p>By <a href="https://docs.h2o.ai/h2o-llmstudio/faqs#where-does-h2o-llm-studio-store-its-data">default</a> it uses two directories at the root path, <code class="language-plaintext highlighter-rouge">/data</code> and <code class="language-plaintext highlighter-rouge">/output</code>:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">data/dbs</code>: user database</li>
  <li><code class="language-plaintext highlighter-rouge">data/user</code>: uploaded datasets</li>
  <li><code class="language-plaintext highlighter-rouge">output/user</code>: experiments conducted in H2O LLM Studio are stored in this folder; one folder per experiment</li>
  <li><code class="language-plaintext highlighter-rouge">output/download</code>: data the user downloads within the app</li>
</ul>

<p>There’s this <a href="https://www.youtube.com/watch?v=nZzHFwaoMpU">2019 demo</a> which at 11 minute mark shows how a dataset can be added as a mount point.</p>

<p><img src="/assets/images/h2o-h2ogpt-07-add-dataset-button.png" alt="Click on add dataset button" /></p>

<p>Add a mount point (NFS, BeeGFS, etc.).</p>

<p><img src="/assets/images/h2o-h2ogpt-08-add-mountpoint.png" alt="Add a mount point" /></p>

<p>View dataset:</p>

<p><img src="/assets/images/h2o-h2ogpt-09-mountpoint.png" alt="View NFS based dataset" /></p>

<p>As the demo shows, it’s shared datasets can be accessed from multiple instances of H2O clusters, and shared filesystems can also be used to checkpoint (save state of a workload) in order to migrate or resume work later - even from a different cluster.</p>

<p>Obviously that’s a different product but it may be similar to H2O LLM Studio. I haven’t used these products, so contact H2O for latest product information.</p>

<h2 id="summary">Summary</h2>

<p>Getting data in and out of h2oGPT doesn’t seem difficult.</p>

<p>It would be interesting to know how one can do more advanced operations such as deleting or backing up documents, but we may need H2O LLM Studio for that. In fact <a href="https://docs.h2o.ai/h2o-llmstudio/guide/datasets/view-dataset">here</a> we can get a hint of how those more sophisticated document operations look like.</p>

<p>Unlike the experiment in this post, we would normally not want to use temporary in-container data collections, but we have enough knowledge to get started and an idea of what we don’t know.</p>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#storage">storage</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2023/11/28/postgres-pgvector-instacluster-eseries.html">Postgres, pgvector, E-Series and Instaclustr</a></li>
      
        <li><a href="/2023/11/22/genai-with-netapp-solidfire.html">NetApp SolidFire with GenAI and inferencing workloads</a></li>
      
        <li><a href="/2024/04/11/netapp-eseries-containerized-beegfs-nfs-s3-all-in-one.html">NetApp E-Series with containerized BeeGFS, NFS, S3</a></li>
      
        <li><a href="/2024/02/29/ubuntu-2404-lts-with-netapp-solidfire.html">Ubuntu 24.04 LTS with NetApp SolidFire</a></li>
      
        <li><a href="/2023/08/21/trident-new-stateful-set-delete-feature.html">StatefulSet PVC Retention with Trident and SolidFire</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2025-02-18 20:54 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
