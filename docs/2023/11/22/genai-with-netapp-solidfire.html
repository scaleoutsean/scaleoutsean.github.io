<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            NetApp SolidFire with GenAI and inferencing workloads | Acting Technologist
      
    </title>
    <meta name="description" content="
     Some ideas on how to make use of SolidFire in GenAI scenarios
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>NetApp SolidFire with GenAI and inferencing workloads | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="NetApp SolidFire with GenAI and inferencing workloads" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Some ideas on how to make use of SolidFire in GenAI scenarios" />
<meta property="og:description" content="Some ideas on how to make use of SolidFire in GenAI scenarios" />
<link rel="canonical" href="https://scaleoutsean.github.io/2023/11/22/genai-with-netapp-solidfire.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2023/11/22/genai-with-netapp-solidfire.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-11-22T00:00:00+08:00" />
<script type="application/ld+json">
{"headline":"NetApp SolidFire with GenAI and inferencing workloads","dateModified":"2023-11-22T00:00:00+08:00","datePublished":"2023-11-22T00:00:00+08:00","author":{"@type":"Person","name":"scaleoutSean"},"@type":"BlogPosting","url":"https://scaleoutsean.github.io/2023/11/22/genai-with-netapp-solidfire.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2023/11/22/genai-with-netapp-solidfire.html"},"description":"Some ideas on how to make use of SolidFire in GenAI scenarios","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">NetApp SolidFire with GenAI and inferencing workloads</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>22 Nov 2023</span> - <i class="far fa-clock"></i> 


  
  
    14 minute read
  

    </span>
  </div>
  
        <ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#inferencing-with-solidfire">Inferencing with SolidFire</a>
    <ul>
      <li><a href="#examples">Examples</a></li>
    </ul>
  </li>
  <li><a href="#making-use-of-iscsi">Making use of iSCSI</a>
    <ul>
      <li><a href="#share-data-with-parallel-file-system">Share data with Parallel File System</a></li>
      <li><a href="#use-solidfire-from-jupyter">Use SolidFire from Jupyter</a></li>
      <li><a href="#ready-to-clone-pvs-for-tools-applications-models">Ready-to-clone PVs for tools, applications, models</a></li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a></li>
  <li><a href="#appendix-a---volume-templates-and-fast-clones">Appendix A - volume templates and fast clones</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>As I’ve mentioned several times, SolidFire isn’t suitable for workloads with high disk performance requirements (meaning roughly 30K IOPS or 500 MB/s per volume).</p>

<p>You may be able to squeeze out more from a volume, and you can use various tricks like LVM to concatenate or stripe across multiple volumes, but I wouldn’t recommend it.</p>

<p>What works well? Let’s see…</p>

<h2 id="inferencing-with-solidfire">Inferencing with SolidFire</h2>

<p>Normally you won’t need huge performance for block devices running inferencing workloads.</p>

<p>Even for GenAI, unless you have a large amount of compute power. When I tried <a href="/2023/08/04/h2o-storage-notes-h2ogpt.html">H2O AI</a> I maxed out my GPU and disk IO was negligible.</p>

<p>In most cases you need Docker and Kubernetes support, for which SolidFire uses NetApp Trident.</p>

<p>NetApp HCI (and SolidFire) had inferencing documented in <a href="https://docs.netapp.com/us-en/hci-solutions/hciaiedge_use_cases.html">this solution</a>.</p>

<p>An example of NVIDIA Triton inference server deployment on Kubernetes is given <a href="https://docs.netapp.com/us-en/hci-solutions/hciaiedge_deploy_nvidia_triton_inference_server_automated_deployment.html">here</a>.</p>

<p>The inferencing deployment example above uses a PVC on an NFS share served by ONTAP Select (a VM version of ONTAP that used to ship with NetApp HCI).</p>

<p>Sure, that’s one way to do it and it works great for ReadWriteMany i.e. many pods can access the same NFS share on ONTAP Select which, when deployed with multiple SolidFire volumes, can spray IO request across all of them and get around the performance limit of a single volume mentioned above.</p>

<p>But not all SolidFire users have ONTAP, and not all use NFS.</p>

<p>Is there a role for iSCSI block devices provisioned directly by SolidFire?</p>

<h3 id="examples">Examples</h3>

<p>While doing unrelated research related to sizing for Deep Learning (not inferencing) I came across this example which illustrates how even Deep Learning on text data can be light on storage:</p>

<blockquote>
  <p>In this sample, you will use Intel® Distribution of Modin* to ingest and process U.S. census data from 1970 to 2010 in order to build a ridge regression-based model to find the relation between education and total income earned in the US.
Time to complete: 20 minutes</p>
</blockquote>

<p>Source: <a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics/End-to-end-Workloads/Census">Intel</a></p>

<p>I tried running several inferencing programs and the heaviest IO happened during container startup when container is loaded and the model which may be few GB large needs to be read from disk. Since this model is usually part of read-only container image and stored on local disk, it has no impact on SolidFire workload.</p>

<p>I also used <a href="https://huggingface.co/Helsinki-NLP">Helsinki-NLP</a> to translate small text files. Each job used 45% of RTX 2K GPU and the additional disk IO was barely measurable.</p>

<p>Medium-large and large GenAI workloads <a href="/2023/11/28/postgres-pgvector-instacluster-eseries.html">can</a> require a lot of IO, but one would need more than half a dozen big GPUs to get there.</p>

<h2 id="making-use-of-iscsi">Making use of iSCSI</h2>

<p>Let’s see about some other approaches:</p>

<ul>
  <li>Use SolidFire iSCSI to create parallel file system (permanent or “scratch” space)</li>
  <li>Use on-prem or cloud S3 storage if your application can natively support S3</li>
  <li>Mount S3 bucket and use it as local device - I’ve <a href="/2022/03/10/s3-select-vs-remote-csv-over-fuse.html">blogged</a> about goofys, s3fs, MountPoint S3 and other ways to do this</li>
</ul>

<p>Only the first of these three can make use of SolidFire, so I’ll skip the other two which aren’t directly related, although you could <a href="/2023/08/04/h2o-storage-notes-h2ogpt.html">download</a> S3 data to a PVC backed by SolidFire, if you wanted to keep data or get lower latency access for the duration of your work and the size wasn’t larger than SolidFire can handle.</p>

<h3 id="share-data-with-parallel-file-system">Share data with Parallel File System</h3>

<p>We can deploy BeeGFS or GPFS inside of VMs that use SolidFire iSCSI (pRDM, but VMDKs on VMFS work as well). Containers can use these filesystems’ CSI drivers for storage access. VMs can install BeeGFS or GPFS client to mount these filesystems. This can be deployed with Ansible on demand in less than 8 minutes (see this example <a href="/2020/12/31/beegfs-on-netapp-hci-and-ef-series.html#how-do-automation-and-virtualization-help">here</a>) and can be destroyed if you don’t intend to keep these filesystems for longer than jobs last.</p>

<p>You can also deploy BeeGFS in containers (see <a href="https://github.com/ThinkParQ/beegfs-containers/">here</a>) and use it “natively” from within each container. NetApp Trident CSI can be used to present iSCSI devices to containers using <a href="/2023/09/01/kubernetes-solidfire-block-volumemode.html">block volume mode</a> and then BeeGFS can be deployed. I haven’t tried this last step yet, but I don’t think it would fail.</p>

<p>This provides access to shared data without NFS or SMB shares. Of course, it still won’t be faster than SolidFire storage underneath it.</p>

<p>My notes on running BeeGFS in containers can be found <a href="/2023/12/02/containerized-beegfs-with-netapp-eseries.html">here</a>.</p>

<h3 id="use-solidfire-from-jupyter">Use SolidFire from Jupyter</h3>

<p>I’ve blogged about <a href="https://github.com/NetApp/netapp-dataops-toolkit">NetApp DataOps Toolkit</a> so I won’t repeat any of that, but you can check my archives or see the documentation: it’s a wrapper that makes some frequent data management operations simple.</p>

<p>It supports ONTAP and BeeGFS, but it could be expanded to work with SolidFire - we’d just need to add 3-4 functions (create volume, snapshot, clone). This could be a great approach for SolidFire users who also have ONTAP or BeeGFS. You could even go wild and add the SolidFire SnapMirror to ONTAP (to copy/backup SolidFire volumes to ONTAP, for example).</p>

<p>Otherwise it may be easier to simply include these SolidFire API methods and Trident CLI commands in <a href="/2022/03/29/manage-solidfire-jupyter-powershell.html">Jupyter to use with SolidFire</a>.</p>

<p>If you’re concerned about giving users’ access to the API, check out the <a href="/2022/02/14/middle-class-rbac-solidfire-ansible.html">RBAC</a> post. Maybe you can use Ansible to prevent accidents and control what users can do with volumes that don’t belong to them.</p>

<h3 id="ready-to-clone-pvs-for-tools-applications-models">Ready-to-clone PVs for tools, applications, models</h3>

<p>Why would one want to clone a SolidFire volume? For the same reason we clone Trident CSI volumes backed by ONTAP NFS shares - that lets you create dozens of clones without client-side copying, while saving space and time.</p>

<p>Tools and applications can be installed on a PVC that can be cloned and mounted when NVIDIA or other containers are started.</p>

<p>If users don’t write to these volumes, dozens of clones won’t take any extra data capacity on SolidFire.</p>

<p>People usually use RWX PVCs on NFS shares for this purpose and that does work very well (volumes don’t have to be cloned, for example), but NFS server must exist and be managed. If you don’t have other uses for NFS server, you don’t need to stand up one just to efficiently share applications (or even small amounts of static data) in containers.</p>

<p>One complaint I’ve heard about this idea from someone who got it from an end user is that cloning on-demand takes a long time.</p>

<p>That may be true if your jobs run for less than 100 seconds and the container is then destroyed. In that case waiting for 15 seconds for every job is significant. But you can see <a href="/2023/08/30/monitoring-solidfire-clone-and-backup-jobs.html#faster-multiple-clones-from-a-single-volume">here</a> that it’s not <em>that</em> slow.</p>

<p>Like I said I heard that from a colleague. If I had that problem, I would have come up with some tricks. It did take me a while, but my idea for this is pre-cloning.</p>

<p>Let’s say I have a PVC with scripts, utilities and AI models. I can setup a simple container that periodically ensures that this PVC has at least 5 unused clones and creates them when there’s less than that.</p>

<p>How to check if a PV is “unused”? It won’t have any iSCSI sessions, it will have certain volume attributes (in the SolidFire Volume API object), etc. I can also check all my PVCs from Trident CSI side and see if those “unused” volumes are known to Trident.</p>

<p>Then from Jupyter or my deployment script I simply pick one of those idle volumes and assign it to my storage account that uses Kubernetes, and use that volume in my container by importing it with Trident.</p>

<p>Before I needed 15 seconds to get this 100 GiB clone created. Now that’s done in advance and I need just 1 second to use it.</p>

<p>This approach can be made even less “expensive” by reverting discarded (unused) volumes to a snapshot created immediately after cloning, so that no new clone needs to be created. If I import a clone to Trident as “unmanaged” volume, once the container is destroyed I can restore the volume to the first snapshot and have it “as good as new” without making a new clone.</p>

<h2 id="conclusion">Conclusion</h2>

<p>GenAI and inferencing workloads often don’t need a lot of storage bandwidth or IOPS.</p>

<p>I’m not writing this because I want you to buy new SolidFire arrays (you can’t, it’s no longer sold).</p>

<p>I’m writing this because those who <em>already have it</em> may wonder if it makes sense to consider it for GenAI and inferencing and I think the answer is yes.</p>

<p>SolidFire users who keep most of their data in object stores may prefer to work with large data sets on external (S3) and use iSCSI for the rest.</p>

<p>In these situations SolidFire iSCSI storage can be used very effectively either by taking advantage of the SolidFire API from Jupyter or own scripts, or by using it with a parallel filesystem solution such as BeeGFS which provides shared data and can be used like a shared “scratch” space.</p>

<p>If data needs to be saved, we can use use one of the “S3 mount” approaches mentioned above. There are also specialized, <a href="https://docs.lakefs.io/quickstart/launch.html">AI-focused approaches</a> to do that, which could be used to save data to <a href="https://www.netapp.com/data-storage/storagegrid/">NetApp StorageGRID</a> or <a href="/2022/10/21/minio-performance-netapp-e-series.html">MinIO with E-Series</a>.</p>

<p>These approaches don’t <em>require</em> SolidFire, but SolidFire makes them easier to implement.</p>

<h2 id="appendix-a---volume-templates-and-fast-clones">Appendix A - volume templates and fast clones</h2>

<p>The <strong>first</strong> step is to prepare your “gold” template volume.</p>

<p>You can prepare this “gold” image by working “in reverse” or forwards.</p>

<p>In reverse: create an idling container with a solidfire-san PVC set to Retain the volume after container deletion. Enter the container, deploy packages and other data to the PVC path. Alternatively, build a Dockerfile with a startup script to automate that. Then stop the container and the volume will remain (as PVC was set to Retain). Now may clone or reassign to some other account not used by Kubernetes.</p>

<p>Or, starting from the storage side, create a new account for volume preparation, let’s say we name it “prepper”.</p>

<p>Get its Account ID (9), get available QoS policies.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">/home/sean</span><span class="err">&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">Get-SFAccount</span><span class="w"> </span><span class="nt">-Username</span><span class="w"> </span><span class="nx">prepper</span><span class="p">)</span><span class="o">.</span><span class="nf">AccountID</span><span class="w">                              
</span><span class="mi">9</span><span class="w">
</span><span class="n">PS</span><span class="w"> </span><span class="nx">/home/sean</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Get-SFQoSPolicy</span><span class="w">                                             

</span><span class="n">QosPolicyID</span><span class="w"> </span><span class="nx">Name</span><span class="w">   </span><span class="nx">VolumeIDs</span><span class="w">        </span><span class="nx">Qos</span><span class="w">
</span><span class="o">-----------</span><span class="w"> </span><span class="o">----</span><span class="w">   </span><span class="o">---------</span><span class="w">        </span><span class="o">---</span><span class="w">
          </span><span class="mi">1</span><span class="w"> </span><span class="n">basic</span><span class="w">  </span><span class="p">{</span><span class="mi">2</span><span class="p">}</span><span class="w">              </span><span class="p">{</span><span class="s2">"MinIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="s2">"MaxIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">800</span><span class="p">,</span><span class="w"> </span><span class="s2">"BurstIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="s2">"BurstTime"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">60</span><span class="p">}</span><span class="w">
          </span><span class="mi">2</span><span class="w"> </span><span class="n">backup</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">36</span><span class="p">,</span><span class="w"> </span><span class="mi">37</span><span class="p">,</span><span class="w"> </span><span class="mi">38</span><span class="err">…</span><span class="p">}</span><span class="w"> </span><span class="p">{</span><span class="s2">"MinIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="s2">"MaxIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1500</span><span class="p">,</span><span class="w"> </span><span class="s2">"BurstIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3000</span><span class="p">,</span><span class="w"> </span><span class="s2">"BurstTime"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">60</span><span class="p">}</span><span class="w">
          </span><span class="mi">3</span><span class="w"> </span><span class="n">tester</span><span class="w"> </span><span class="p">{}</span><span class="w">               </span><span class="p">{</span><span class="s2">"MinIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">200</span><span class="p">,</span><span class="w"> </span><span class="s2">"MaxIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">500</span><span class="p">,</span><span class="w"> </span><span class="s2">"BurstIOPS"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2000</span><span class="p">,</span><span class="w"> </span><span class="s2">"BurstTime"</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">60</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>

<p>Next, create a volume that uses one of these QoS policies.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">/home/sean</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">New-SFVolume</span><span class="w"> </span><span class="nt">-Name</span><span class="w"> </span><span class="nx">gold</span><span class="w"> </span><span class="nt">-AccountID</span><span class="w"> </span><span class="nx">9</span><span class="w"> </span><span class="nt">-TotalSize</span><span class="w"> </span><span class="nx">5</span><span class="w"> </span><span class="nt">-GiB</span><span class="w"> </span><span class="nt">-QoSPolicyID</span><span class="w"> </span><span class="nx">3</span><span class="w"> </span><span class="nt">-Enable512e</span><span class="w"> </span><span class="nv">$False</span><span class="w">

</span><span class="n">VolumeID</span><span class="w">                    </span><span class="p">:</span><span class="w"> </span><span class="nx">79</span><span class="w">
</span><span class="n">Name</span><span class="w">                        </span><span class="p">:</span><span class="w"> </span><span class="nx">gold</span><span class="w">
</span><span class="n">AccountID</span><span class="w">                   </span><span class="p">:</span><span class="w"> </span><span class="nx">9</span><span class="w">
</span><span class="n">CreateTime</span><span class="w">                  </span><span class="p">:</span><span class="w"> </span><span class="nx">2023-11-22T14:25:36Z</span><span class="w">
</span><span class="o">...</span><span class="w">
</span></code></pre></div></div>

<p>Prepare the volume by <a href="https://docs.netapp.com/us-en/trident-2307/trident-use/vol-import.html">importing it as an unmanaged</a> Trident volume, entering the container and deploying tools, models or applications to the PVC mount path. Then exit and remove the container.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tridentctl import volume backendName volumeName <span class="nt">-f</span> pvc-file.yaml <span class="nt">--no-manage</span>
</code></pre></div></div>

<p>The <strong>second</strong> step is to create a cron job or a simple service that watches if this volume has at least X - let’s say 5 - unused clones.</p>

<p>From the above we know our account ID is 9 and our volume ID 79. We’d clone the volume like this:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">New-SFClone</span><span class="w"> </span><span class="nt">-VolumeID</span><span class="w"> </span><span class="nx">79</span><span class="w"> </span><span class="nt">-NewAccountID</span><span class="w"> </span><span class="nx">9</span><span class="w"> </span><span class="nt">-Name</span><span class="w"> </span><span class="nx">RandomName</span><span class="w">
</span></code></pre></div></div>

<p>But rather than manually cloning it, we should simply create a “checker” as we need to do that anyway.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kr">While</span><span class="w"> </span><span class="p">(</span><span class="nv">$True</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="n">Start-Sleep</span><span class="w"> </span><span class="nx">10</span><span class="p">;</span><span class="w"> </span><span class="nv">$volQty</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">Get-SFVolume</span><span class="w"> </span><span class="nt">-AccountID</span><span class="w"> </span><span class="nx">9</span><span class="p">)</span><span class="o">.</span><span class="nf">AccountID</span><span class="p">)</span><span class="o">.</span><span class="nf">Count</span><span class="p">;</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="nv">$volQty</span><span class="w"> </span><span class="o">-le</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="n">New-SFClone</span><span class="w"> </span><span class="nt">-VolumeID</span><span class="w"> </span><span class="nx">79</span><span class="w"> </span><span class="nt">-NewAccountID</span><span class="w"> </span><span class="nx">9</span><span class="w"> </span><span class="nt">-Name</span><span class="w"> </span><span class="nx">UNIQ</span><span class="p">;</span><span class="w"> </span><span class="n">Write-host</span><span class="w"> </span><span class="s2">"Created!"</span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="p">{</span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"No need"</span><span class="p">}}</span><span class="w">
</span></code></pre></div></div>

<p>This above is simple but it works fine for demo purposes. Notes:</p>
<ul>
  <li>There should be a search condition to avoid volumes with the name “gold” or even “template*” for the situations where there are many gold template volumes</li>
  <li><code class="language-plaintext highlighter-rouge">-Name UNIQ</code> doesn’t create unique names. You need to randomize those names - use random digits, or whatever works for you. But as far as whether this works, it does. The last 3 volumes were created automatically</li>
  <li><em>If</em> unmanaged Kubernetes volumes needed to be “refreshed” we could watch for those as well, change their ownership to this account and restore them to their earliest snapshot. You’d need to create a snapshot immediately after creating the clone in this code above</li>
</ul>

<p><img src="/assets/images/solidfire-clone-precreation-01.png" alt="Pre-created clones" /></p>

<p>Now in step <strong>three</strong> executed before container provisioning I just need to look if I can find any unused volumes of the kind I need.</p>

<p>What if there’s 10 different “kinds” of clones owned by this account? Nothing. Find a way to differentiate between them. Team A can use volumes from Account ID 9, Team Z can use volumes from Account ID 10, so you could also create different template-making accounts for different teams.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">/home/sean</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$floater</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">@{</span><span class="w"> </span><span class="s2">"type"</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">;</span><span class="w"> </span><span class="s2">"dept"</span><span class="o">=</span><span class="s2">"team2"</span><span class="p">}</span><span class="w">                              

</span><span class="n">PS</span><span class="w"> </span><span class="nx">/home/sean</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">Set-SFVolume</span><span class="w"> </span><span class="nt">-VolumeID</span><span class="w"> </span><span class="nx">84</span><span class="w"> </span><span class="nt">-Attributes</span><span class="w"> </span><span class="nv">$floater</span><span class="w"> </span><span class="nt">-Confirm</span><span class="w"> </span><span class="nv">$False</span><span class="w">

</span><span class="n">VolumeID</span><span class="w">                    </span><span class="p">:</span><span class="w"> </span><span class="nx">84</span><span class="w">
</span><span class="n">Name</span><span class="w">                        </span><span class="p">:</span><span class="w"> </span><span class="nx">UNIQ</span><span class="w">
</span><span class="n">AccountID</span><span class="w">                   </span><span class="p">:</span><span class="w"> </span><span class="nx">9</span><span class="w">
</span><span class="n">CreateTime</span><span class="w">                  </span><span class="p">:</span><span class="w"> </span><span class="nx">2023-11-22T15:07:10Z</span><span class="w">
</span><span class="o">...</span><span class="w">
</span><span class="n">LastAccessTimeIO</span><span class="w">            </span><span class="p">:</span><span class="w"> 
</span><span class="n">SliceCount</span><span class="w">                  </span><span class="p">:</span><span class="w"> </span><span class="nx">1</span><span class="w">
</span><span class="n">TotalSize</span><span class="w">                   </span><span class="p">:</span><span class="w"> </span><span class="nx">5368709120</span><span class="w">
</span><span class="n">BlockSize</span><span class="w">                   </span><span class="p">:</span><span class="w"> </span><span class="nx">4096</span><span class="w">
</span><span class="n">VirtualVolumeID</span><span class="w">             </span><span class="p">:</span><span class="w"> 
</span><span class="n">Attributes</span><span class="w">                  </span><span class="p">:</span><span class="w"> </span><span class="p">{[</span><span class="n">dept</span><span class="p">,</span><span class="w"> </span><span class="n">team2</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">type</span><span class="p">,</span><span class="w"> </span><span class="n">cuda</span><span class="p">]}</span><span class="w">

</span></code></pre></div></div>

<p>That’s one of the ways to find my volume without using an external database. Now to find volumes from Team 2 I can check the value of that key.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">PS</span><span class="w"> </span><span class="nx">/home/sean</span><span class="err">&gt;</span><span class="w"> </span><span class="nv">$volLIst</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">Get-SFVolume</span><span class="w"> </span><span class="nt">-AccountID</span><span class="w"> </span><span class="nx">9</span><span class="p">)</span><span class="o">.</span><span class="nf">VolumeID</span><span class="w">

</span><span class="n">PS</span><span class="w"> </span><span class="nx">/home/sean</span><span class="err">&gt;</span><span class="w"> </span><span class="nx">foreach</span><span class="w"> </span><span class="p">(</span><span class="nv">$vol</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="nv">$volList</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nv">$volData</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Get-SFVolume</span><span class="w"> </span><span class="nt">-VolumeID</span><span class="w"> </span><span class="nv">$Vol</span><span class="p">;</span><span class="w"> </span><span class="nv">$volId</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$volData</span><span class="o">.</span><span class="nf">VolumeID</span><span class="p">;</span><span class="w"> </span><span class="nv">$volAttrs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$volData</span><span class="o">.</span><span class="nf">Attributes</span><span class="p">;</span><span class="w"> </span><span class="nv">$volName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">$volData</span><span class="o">.</span><span class="nf">Name</span><span class="p">;</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="nv">$volAttrs</span><span class="p">[</span><span class="s1">'dept'</span><span class="p">]</span><span class="w"> </span><span class="o">-eq</span><span class="w"> </span><span class="nv">$floater</span><span class="p">[</span><span class="s1">'dept'</span><span class="p">])</span><span class="w"> </span><span class="p">{</span><span class="n">Write-Host</span><span class="w"> </span><span class="s2">"Vol ID and name"</span><span class="p">,</span><span class="w"> </span><span class="nv">$volId</span><span class="p">,</span><span class="w"> </span><span class="nv">$volName</span><span class="p">}}</span><span class="w">
</span><span class="n">Vol</span><span class="w"> </span><span class="nx">ID</span><span class="w"> </span><span class="nx">and</span><span class="w"> </span><span class="nx">name</span><span class="w"> </span><span class="nx">84</span><span class="w"> </span><span class="nx">UNIQ</span><span class="w">

</span></code></pre></div></div>

<p>If multiple volumes are found, pick one or use additional criteria to find the right one. We should filter out (avoid) volumes with the name “gold” or “template*” if that’s what we used for template creation.</p>

<p>We could store this in SQLite and create a simple PowerSHell or Python API, but why complicate things?</p>

<p>One reason why you may not want to use volume attributes is if you’re afraid you may create a conflict with Trident itself. As explained in other posts on this blog, Trident sets and reads SolidFire volume attributes as well.</p>

<p><img src="/assets/images/solidfire-clone-precreation-02.png" alt="Pre-created clones" /></p>

<p>In my opinion this is safe - we just need to pick different keys, and as long as there’s no conflict with Trident keys, that’s okay. We set our attributes <em>before</em> the clone is used by Trident, and we can reset or update them after they’re abandoned by Trident - there’s no concurrent modification and key names are different. Also, if Trident uses <code class="language-plaintext highlighter-rouge">--no-manage</code>, maybe it won’t even set volume attributes to begin with (it’s been a while since I tried that).</p>

<p>Step <strong>five</strong>: compose a PVC YAML from a template and pick this volume name to import it to Kubernetes with Trident:</p>
<ul>
  <li>Remember to randomize volume names during clone creation (should have been done earlier, in step two)</li>
  <li>For Trident/Kubernetes to access and import a volume, the volume should be owned by the Kubernetes storage account, so remember to change account ID (Set-SFVolume -VolumeID 84 -AccountID 100) before running the Trident volume import step</li>
</ul>

<p>Depending on whether you import them with <code class="language-plaintext highlighter-rouge">--no-manage</code> and the PVC reclaim policy, you may want to delete the volume or “recycle” it by re-assigning it to the account “prepper” who can then automatically revert it to the first snapshot</p>


      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#storage">storage</a>
      &nbsp; 
    
      <a href="
      /categories/#solidfire">solidfire</a>
      &nbsp; 
    
      <a href="
      /categories/#ai">ai</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2023/11/28/postgres-pgvector-instacluster-eseries.html">Postgres, pgvector, E-Series and Instaclustr</a></li>
      
        <li><a href="/2024/07/02/solidfire-volume-attributes-from-trident-and-other-apps.html">Extract SolidFire volume attributes created by Trident or other apps</a></li>
      
        <li><a href="/2024/06/28/growing-solidfire-volumes-paired-for-replication.html">Increase size of SolidFire volumes paired for replication</a></li>
      
        <li><a href="/2024/05/04/netapp-solidfire-with-async-http.html">Access NetApp SolidFire API with Async IO</a></li>
      
        <li><a href="/2024/04/01/windows-server-2025-with-solidfire-part-two-sql-server-2022.html">Windows Server 2025 with NetApp SolidFire 12 iSCSI Part Two</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2024-07-02 23:15 </p>
    <p>Copyright © 2024 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
