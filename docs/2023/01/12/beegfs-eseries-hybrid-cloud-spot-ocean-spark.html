<!doctype html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
    <meta http-equiv="content-language" content="en">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="googlebot" content="noarchive">
    <meta name="googlebot" content="max-snippet:60">
    <meta name="googlebot" content="max-image-preview:small">
    <meta name="bingbot" content="noarchive">
    <meta name="bingbot" content="max-snippet:60">
    <meta name="bingbot" content="max-image-preview:small">
    <meta name="robots" content="noarchive">
    <meta name="robots" content="max-snippet:60">
    <meta name="google-site-verification" content="F6q7vIwQ2G0j8tk-KL9rAXOMLXMDMMUkEz4fRs1Nnnc" />
    <title>
        
            Burst on-prem GPU workloads from BeeGFS/E-Series clusters to Spot Ocean for Spark in the cloud | Acting Technologist
      
    </title>
    <meta name="description" content="
     Make BeeGFS on E-Series data available to GPU-enabled Analytics and Deep Learning workfloads with Spot Ocean for Spark
     ">

    <!-- LINK TO ATOM FEED FOR SEO -->
    <link rel="alternate" type="application/atom+xml" href="https://scaleoutsean.github.io/feed.xml" />

    <!-- FAVICON -->
    <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">

    <link href="/_pagefind/pagefind-ui.css" rel="stylesheet">
    <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script>
    <div id="search"></div>
    <script src="https://cdn.counter.dev/script.js" data-id="83dc700a-b821-4e57-9425-02b8336a9456" data-utcoffset="0"></script>
    <script>
        window.addEventListener('DOMContentLoaded', (event) => {
            new PagefindUI({ element: "#search" });
        });
    </script>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Burst on-prem GPU workloads from BeeGFS/E-Series clusters to Spot Ocean for Spark in the cloud | Acting Technologist</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Burst on-prem GPU workloads from BeeGFS/E-Series clusters to Spot Ocean for Spark in the cloud" />
<meta name="author" content="scaleoutSean" />
<meta property="og:locale" content="en" />
<meta name="description" content="Make BeeGFS on E-Series data available to GPU-enabled Analytics and Deep Learning workfloads with Spot Ocean for Spark" />
<meta property="og:description" content="Make BeeGFS on E-Series data available to GPU-enabled Analytics and Deep Learning workfloads with Spot Ocean for Spark" />
<link rel="canonical" href="https://scaleoutsean.github.io/2023/01/12/beegfs-eseries-hybrid-cloud-spot-ocean-spark.html" />
<meta property="og:url" content="https://scaleoutsean.github.io/2023/01/12/beegfs-eseries-hybrid-cloud-spot-ocean-spark.html" />
<meta property="og:site_name" content="Acting Technologist" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-01-12T00:00:00+08:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://scaleoutsean.github.io/2023/01/12/beegfs-eseries-hybrid-cloud-spot-ocean-spark.html"},"author":{"@type":"Person","name":"scaleoutSean"},"description":"Make BeeGFS on E-Series data available to GPU-enabled Analytics and Deep Learning workfloads with Spot Ocean for Spark","@type":"BlogPosting","url":"https://scaleoutsean.github.io/2023/01/12/beegfs-eseries-hybrid-cloud-spot-ocean-spark.html","headline":"Burst on-prem GPU workloads from BeeGFS/E-Series clusters to Spot Ocean for Spark in the cloud","dateModified":"2023-01-12T00:00:00+08:00","datePublished":"2023-01-12T00:00:00+08:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

<body>

  <div class="container">
    <header id="header">
	<div id = site_title>
		<a href="https://scaleoutsean.github.io/">
			<h2 style="font-size:1.8em;">Acting Technologist</h2>
		</a>
		
		<h3>
			civilizations are created by individuals
		</h3>
		
	</div>

	<div id="subheader">
		
		<nav class="pages">
<a href="/about.html">About</a>

<a href="/archive.html">Archive</a>

<a href="/categories/">Categories</a>

<a href="/projects.html">Projects</a>
</nav>
		
		
		<nav class="social">
			
  
    <a href="https://www.github.com/scaleoutsean" target="_blank" id="github"><i class="fab fa-github" aria-hidden="true"></i></a>
  
   

  
    <a href="https://twitter.com/scaleoutsean" target="_blank" id="twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  
   

  
  
    <a href="/feed.xml" target="_blank" id="rss"><i class="fas fa-rss" aria-hidden="true"></i></a>
   

		</nav>
		
	</div>
</header>


    <div class="post-container">
      <article id = "post">
        <h1 id = "post-title">Burst on-prem GPU workloads from BeeGFS/E-Series clusters to Spot Ocean for Spark in the cloud</h1>

  
  <div class = "post-info">
    <span>
        <i class="far fa-calendar" aria-hidden="true"></i> <span>12 Jan 2023</span> - <i class="far fa-clock"></i> 


  
  
    4 minute read
  

    </span>
  </div>
  
        <ul>
  <li><a href="#problem-statement">Problem statement</a></li>
  <li><a href="#data-replication">Data replication</a></li>
  <li><a href="#storage">Storage</a>
    <ul>
      <li><a href="#csi-drivers">CSI drivers</a></li>
    </ul>
  </li>
  <li><a href="#gpu-compute-nodes">GPU compute nodes</a></li>
  <li><a href="#performance-monitoring">Performance monitoring</a></li>
  <li><a href="#workflow">Workflow</a></li>
</ul>

<h2 id="problem-statement">Problem statement</h2>

<p>Enterprises with analytics, HPC and Deep Learning workloads that have high-bandwidth storage requirements use BeeGFS with NetApp E-Series.</p>

<p>For various reasons they may need to burst-to-cloud. Some of the main challenges in this process:</p>

<ul>
  <li>Data replication from on-premises BeeGFS to the cloud</li>
  <li>Storage performance in the cloud</li>
  <li>Cost of compute resources in the cloud</li>
</ul>

<h2 id="data-replication">Data replication</h2>

<p>For obvious resons (granularity) in this use case file and object replication are generally a better choice than volume replication.</p>

<p>To copy BeeGFS files to the cloud you may use a file sync tool of your choice: rsync, rclone, etc.</p>

<p>Alternatively, NetApp has a subscription (charged per hour) service called <a href="https://docs.netapp.com/us-en/cloud-manager-sync/concept-cloud-sync.html">Cloud Sync</a>.</p>

<p>I wrote about various ways to sync files and objects <a href="/2022/01/28/storagegrid-hybrid-cloud-processing-without-data-at-rest.html">here</a>. If you use Cloud Sync, automation is availble via the <a href="/2022/01/17/using-netapp-cloudsync-api.html">Cloud Sync API</a>.</p>

<p>Data replication <em>from</em> the cloud to on-premises is usually not a problem because we’re talking just about the results (few KB to few GB, perhaps). To avoid having to open enterprise firewall to incoming connections (or - even worse - use VPN), simply post your results to the cloud provider’s Object Store and download them from there using Cloud Sync or rclone.</p>

<h2 id="storage">Storage</h2>

<p>For Big Data anlaytics and DL/ML workloads it usually pays to use fast storage because that saves compute costs. Cloud GPUs aren’t extactly cheap, so if you use BeeGFS on-premises, you likely want to use it in the public cloud for similar workloads.</p>

<p>The creators of BeeGFS, ThinkParQ, have created BeeOND, a subscription service that’s based on BeeGFS running on hyperscaler hardware. Back in 2019 it was possible to get close to 100 GiB/s from such clusters (see <a href="https://techcommunity.microsoft.com/t5/azure-high-performance-computing/tuning-beegfs-and-beeond-on-azure-for-specific-i-o-patterns/ba-p/1015446">this example</a> from Azure).</p>

<p>Compared to ONTAP-based cloud storage, BeeOND is limited in terms of data management features: backup, snapshots, etc. If you need to protect your cloud data before BeeOND subscription is terminated, make a copy in the hyperscaler’s Object Storage.</p>

<h3 id="csi-drivers">CSI drivers</h3>

<ul>
  <li><a href="/2022/04/09/beegfs-csi-introduction.html">BeeGFS CSI</a> for BeeOND</li>
  <li><a href="/2022/04/09/beegfs-csi-introduction.html">NetApp Astra Trident CSI</a> for ONTAP-based cloud storage</li>
</ul>

<p>In the case you’d like to use both at the same time - that is BeeOND and for example Cloud Volumes ONTAP - that is possible. You can see how both are used in the same Kubernetes cluster in <a href="/2022/04/09/beegfs-csi-introduction.html#options-in-a-mixed-environment">this post</a>.</p>

<p>Why would we want to do that? Maybe you have cloud data that needs to be kept in the cloud between workloads and CVO is good for that. Then, when you need to run compute jobs, you can use DataOps Toolkit to <a href="/2022/01/28/storagegrid-hybrid-cloud-processing-without-data-at-rest.html#netapp-dataops-toolkit">copy data from CVO to BeeGFS (and back)</a>.</p>

<p>It is also possible to use multiple PVCs at the same time - read data from CVO and stage it to BeeOND, and write the result to a CVO volume.</p>

<h2 id="gpu-compute-nodes">GPU compute nodes</h2>

<p>We want to avoid unnecessary cost of GPU compute resources.</p>

<p>To do that we can use a <a href="https://spot.io">Spot.io</a> service called <a href="https://spot.io/products/ocean-apache-spark/">Spot Ocean for Spark</a>.</p>

<p><img src="/assets/images/spot-ocean-for-spark.png" alt="Spot Ocen for Spark" /></p>

<p>Spot doesn’t seem to build GPU clusters from scratch, but Spot allows you to <a href="https://docs.spot.io/ocean-spark/getting-started/create-cluster?id=import-an-existing-kubernetes-cluster-to-ocean-spark">import existing clusters to Spot</a> and let Spot control and manage them.</p>

<p>This means we can build a cluster with GPU-based worker nodes and tell Spot Ocean for Spark to use it.</p>

<p>The next question is whether containers used by Spot Ocean for Spark have CUDA? Spot Ocean Spark uses its own images. Or, to be perfectly correct, containers based on its <strong>base</strong> images (this distinction will come useful shortly).</p>

<p>At the time of writing this post, the images don’t seem to have CUDA libraries in them. Because we don’t have to use Spot images and can use custom Docker images <strong>based on</strong> Spot’s base images, we can easily start with those and create custom containers with CUDA drivers and libraries.</p>

<p>Here you can find <a href="https://docs.spot.io/ocean-spark/configure-spark-apps/package-spark-code">information about the official Spark official images</a> which can be used as base, and <a href="https://console.cloud.google.com/gcr/images/datamechanics/GLOBAL/spark?tag=platform">here is the list</a> of images.</p>

<h2 id="performance-monitoring">Performance monitoring</h2>

<p>For short-lived clusters I’d probably use hyperscaler’s monitoring and CLI tools built into BeeGFS. Why?</p>

<ul>
  <li>Cost optimization is done by Spot</li>
  <li>Cluster will be deleted anyway</li>
</ul>

<p>Alternatively, <a href="https://github.com/NetApp/eseries-perf-analyzer-plugin-beegfs">BeeGFS monitoring plugin</a> for Grafana which can run on-premises or be the free Grafana Cloud - both would connect to a small, cloud-based, long-running InfluxDB container that could be left running in the case bursting to cloud happens frequently enough.</p>

<h2 id="workflow">Workflow</h2>

<p>The entire workflow would look like this:</p>

<ul>
  <li>Preparation
    <ul>
      <li>Build images with CUDA version recommended by hyperscaler, and store them in private registry</li>
    </ul>
  </li>
  <li>Replication
    <ul>
      <li>Stand-up minimal BeeOND cluster</li>
      <li>Replicate data to BeeOND (or CVO/ANF/FSxN, if you want to use it alongside BeeOND)</li>
    </ul>
  </li>
  <li>Compute
    <ul>
      <li>Grow BeeOND cluster to enough nodes</li>
      <li>Stand up a Kubernetes cluster with GPU-based nodes and deploy BeeGFS CSI (and Trident, if required)</li>
      <li>Import the cluster to Spot Ocean for Spark</li>
      <li>Run Spark and other workloads</li>
    </ul>
  </li>
  <li>Terminate temporary environment
    <ul>
      <li>Copy results to Object Storage, or CVO/FSxN, or back to on-premises</li>
      <li>Scale down to zero or destroy Kubernetes cluster</li>
      <li>Destroy BeeGFS cluster</li>
    </ul>
  </li>
</ul>

<p>Users who burst to the cloud often could scale up and down rather than re-create clusters every time.</p>

      </article>
    </div>
    
      <div class="categories">
    <span><p>Categories:</p>
    
    
      <a href="
      /categories/#storage">storage</a>
      &nbsp; 
    
      <a href="
      /categories/#cloud">cloud</a>
       
    
  </span>
</div>
    

  
    <div>
      <h3>Related Posts</h3>
      <ul>
      
        <li><a href="/2022/04/05/nomad-beegfs-eseries.html">Nomad batch jobs with BeeGFS and E-Series</a></li>
      
        <li><a href="/2022/11/11/netapp-spot-instaclustr-eseries.html">On-prem Spot Instaclustr-managed clusters with NetApp E-Series storage</a></li>
      
        <li><a href="/2025/05/23/beegfs-data-pipeline.html">Data pipelines with ThinParQ BeeGFS and NetApp E-Series</a></li>
      
        <li><a href="/2023/11/30/elasticsearch-ilm-netapp-eseries.html">Snapshots and ILM with Elasticsearch 8</a></li>
      
        <li><a href="/2023/08/29/introduction-to-memphis-message-broker.html">Storage considerations for Memphis message broker</a></li>
      
      </ul>
    </div>
  

    
  </div><footer class= "footer">
    <p>2025-07-30 21:03 </p>
    <p>Copyright © 2025 scaleoutSean. Content is released under the CC BY license. Design: Alessio Franceschi</p>
</footer>

</body>
</html>
